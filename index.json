[{"location":"https://bytemode.github.io/reading/","text":"","title":"Go源码阅读"},{"location":"https://bytemode.github.io/server/","text":"","title":"服务器开发"},{"location":"https://bytemode.github.io/projects/","text":"","title":"我的项目"},{"location":"https://bytemode.github.io/interview/","text":"","title":"面试专题"},{"location":"https://bytemode.github.io/articles/","text":"","title":"分享文章"},{"location":"https://bytemode.github.io/other/","text":"","title":"其他"},{"location":"https://bytemode.github.io/","text":"","title":"Go Learn"},{"location":"https://bytemode.github.io/reading/67-2019-11-14-sql-pool-reading/","text":" Go 夜读第 67 期 Go database/sql 数据库连接池分析 本期 Go 夜读是由 POP 后端团队的邹文通给大家带来的 Go 标准包 database/sql 数据库连接池源码剖析。\n大纲  sql 连接池简介 连接池的工作原理 sql 包连接池源码分析 连接池使用 tips  Slides  https://docs.google.com/presentation/d/10kGjeHGbB0h0Cz8f58reXOyCdyWSOSKrr2160IFNla4/edit?usp=sharing  回看视频  https://www.bilibili.com/video/av75690189/ https://youtu.be/JKJ8ehtiqUM  参考资料  Go组件学习——database/sql数据库连接池你用对了吗 Go组件学习——手写连接池并没有那么简单 Chapter 8 Connection Pooling with Connector/J 彻底弄懂mysql（二）\u0026ndash;连接方式  观看视频   ","title":"第 67 期 Go database/sql 数据库连接池分析"},{"location":"https://bytemode.github.io/reading/66-2019-11-07-paper-reading-csp/","text":" Go 夜读第 66 期 Paper Reading CSP 理解顺序进程间通信 本期 Go 夜读是由 Go 夜读 SIG 核心小组成员欧长坤给大家带来的经典论文 CSP 的 Paper Reading。\nCSP 是什么？ 我们常常在讨论中提及 CSP，但鲜有人能真正说清楚 CSP 的演进历史，及其最核心的基本思想。我们已经对 Go 提供的并发原语足够熟悉了，是时候深入理解其背后的基础理论 —— 顺序进程间通信（Communicating Sequential Processes, CSP）了。本次分享我们针对 [Hoare 1978] 探讨 CSP 理论的原始设计（CSP 1978），主要围绕以下几个问题展开：\nTony Hoare 提出 CSP 的时代背景是什么？ - CSP 1978 理论到底有哪些值得我们研究的地方？ - CSP 1978 理论是否真的就是我们目前熟知的基于通道的同步方式？ - CSP 1978 理论的早期设计存在什么样的缺陷？\n大纲  CSP 1978 的诞生背景 CSP 1978 的主要内容及其结论 CSP 1978 理论中存在的设计缺陷 讨论与反思  分享 Slides  https://docs.google.com/presentation/d/1N5skL6vR9Wxk-I82AYs3dlsOsJkUAGJCsb5NGpXWpqo/edit?usp=sharing  回看视频  https://www.bilibili.com/video/av74891823/ https://youtu.be/Z8ZpWVuEx8c  参考资料  [Hoare 1978] Hoare, C. A. R. (1978). Communicating sequential processes. Communications of the ACM, 21(8), 666–677. [Ou 2019a] CSP1978 的 Go 语言实现 [Ou 2019b] 第 56 期 channel \u0026amp; select 源码分析 [Ou 2019c] 第 59 期 Real-world Go Concurrency Bugs  观看视频   ","title":"第 66 期 Paper Reading CSP 理解顺序进程间通信"},{"location":"https://bytemode.github.io/reading/65-2019-10-31-go-net/","text":" Go 夜读第 65 期 Go 原生网络模型 vs 异步 Reactor 模型 本期 Go 夜读是由 Go 夜读 SIG 核心小组邀请到潘建锋给大家分享 Go 原生网络模型 vs 异步 Reactor 模型，以下是本次分享的部分内容和 QA 。 \u0026gt;潘建锋，曾任职腾讯、现亚马逊在职。Go 语言业余爱好者，开源库 gnet 和 ants 作者。\n引子 我们都知道 Golang 基于 goroutine 构建了一个简洁而优秀的原生网络模型，让开发者能够用同步的模式去编写异步的逻辑：goroutine-per-connection 模式，极大地降低了开发者编写网络应用时的心智负担，而且借助于 Go Scheduler 对 goroutines 的高效调度，这个原生网络模型足以应对绝大部分的应用场景。\n然而，在工程性上能做到如此高的普适和兼容，给开发者提供如此简单易用的接口，其背后必然是基于非常复杂的封装，做了很多取舍，放弃了一些『极致』的概念和设计。事实上 Golang 的 netpoll 底层就是基于 epoll/kqueue/iocp 这些系统调用来做封装的，最终暴露出 goroutine-per-connection 这样的网络编程模式给开发者。\n在绝大部分应用场景下，我推荐大家还是遵循 Golang 的 best practices，以这种模式来构建自己的网络应用，然而，在某些极度需要提高性能、节省资源以及技术栈必须是原生 Go （不考虑 C/C++ 写中间层供 Go 调用）的场景下，我们可以考虑自己构建 Reactor 网络模型。那么，Reactor 模型相对原生模型有哪些优势和弊端呢？我开发了的一个基于事件驱动机制的实验性质的异步网络框架：gnet，其在性能和资源占用上都远超 Go 原生 net 包（少数特定的应用场景），通过解析这个框架和 Go 原生网络模型，我们来一一分析～～\n预备知识：epoll、非阻塞IO、IO多路复用, Linux IO模式及 select、poll、epoll详解\n分享 Slides  https://taohuawu.club/static_res/html/webslides/gnet/gnet.html  Q\u0026amp;A 总结 Q1: 为什么 gnet 会比 Go 原生的 net 包更快？ 答： Multi-Reactors 模型相较于 Go 原生模型在以下场景具有性能优势： 1. 高频创建新连接：我们从源码里可以知道 Go 模式下所有事件都是在一个 epoll 实例来管理的，接收新连接和 IO 读写；而在 Reactors 模式下，accept 新连接和 IO 读写分离，它们在各自独立的 goroutines 里用自己的 epoll 实例来管理网络事件。 2. 海量网络连接：Go net 处理网络请求的模式是 goroutine per connection，甚至是 multiple goroutines per connection，而 gnet 一般使用与机器 CPU 核心数相同的 goroutines 来处理网络请求，所以在海量网络连接的场景下 gnet 更节省系统资源，进而提高性能。 3. 时间窗口内连接总数大而活跃连接数少：这种场景下，Go 原生网络模型因为 goroutine per connection 模式，依然需要维持大量的 goroutines 去等待 IO 事件(保持 1:1 的关系)，Go scheduler 对大量 idle goroutines 的调度势必会损耗系统整体性能；而 gnet 模式下需要维护的仅仅是与 CPU 核心数相同的 goroutines，而且得益于 Reactors 模型和 epoll/kqueue，可以确保每个 goroutine 在大多数时间里都是在处理活跃连接。 4. 短连接场景：gnet 内部维护了一个内存池，在短连接这种场景下，可以大量复用内存，进一步节省资源和提高性能。\nQ2: Go netpoll 源码里的 waitRead 方法到底是起什么作用？ 答： 看源码：\n// func (fd *FD) Read(p []byte) (int, error) \tfor { n, err := syscall.Read(fd.Sysfd, p) if err != nil { n = 0 if err == syscall.EAGAIN \u0026amp;\u0026amp; fd.pd.pollable() { if err = fd.pd.waitRead(fd.isFile); err == nil { continue } } // On MacOS we can see EINTR here if the user \t// pressed ^Z. See issue #22838. \tif runtime.GOOS == \u0026#34;darwin\u0026#34; \u0026amp;\u0026amp; err == syscall.EINTR { continue } } ... // func netpollblock(pd *pollDesc, mode int32, waitio bool) bool  // need to recheck error states after setting gpp to WAIT \t// this is necessary because runtime_pollUnblock/runtime_pollSetDeadline/deadlineimpl \t// do the opposite: store to closing/rd/wd, membarrier, load of rg/wg \tif waitio || netpollcheckerr(pd, mode) == 0 { gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5) } 通过分析 conn.Read()，我们知道这个方法是同步的，但从源码我们可以看出，Go 使用的是非阻塞 IO，所以调用 syscall.Read 的时候并不会阻塞，所以实际上它是通过 waitRead 这个方法来实现阻塞的：netFD 的 Read 操作在系统调用Read后，当遇到 syscall.EAGAIN 时，waitRead 里面的 netpollblock 会调用 gopark 将当前读这个网络描述符的 goroutine 给 park 住，直到这个网络描述符上的读事件再次发生为止，唤醒 goroutine，waitRead 调用返回，回到外层的 for 循环继续执行。conn.Write 方法和 Read 的实现原理是一样的，都是在发生syscall.EAGAIN 错误的时候将当前 goroutine 给 park 住直到 socket 再次可写为止。\nQ3: Go 的网络模型有『惊群效应』吗？ 答：没有。 我们看下源码里是怎么初始化 listener 的 epoll 示例的：\nvar serverInit sync.Once func (pd *pollDesc) init(fd *FD) error { serverInit.Do(runtime_pollServerInit) ctx, errno := runtime_pollOpen(uintptr(fd.Sysfd)) if errno != 0 { if ctx != 0 { runtime_pollUnblock(ctx) runtime_pollClose(ctx) } return syscall.Errno(errno) } pd.runtimeCtx = ctx return nil } 这里用了 sync.Once 来确保初始化一次 epoll 实例，这就表示一个 listener 只持有一个 epoll 实例来管理网络连接，既然只有一个 epoll 实例，当然就不存在『惊群效应』了。\nQ4: Multiple Reactors + Goroutine-Pool Model 这个模式，把阻塞的任务放入Goroutine-Pool，但是如果 Response 依赖于阻塞任务返回的结果(比如依赖于一个http请求结果)，这种情况Goroutine-Pool 是不是意义不大了？ gnet 提供了异步写的 API: AsyncWrite，一般都是在 goroutine pool 里处理完阻塞逻辑之后直接调用这个方法把 response 写回 socket，总之，原则就是不能阻塞 eventloop goroutine，也就是 gnet.React 方法。\nQ5:   潘少说go-net原生的网络模型相当于单reactor的模型，每一个连接一个goroutine来处理，由go的调度器实现高并发，这样应该也能利用上多核CPU的吧？为什么性能比multi-reactors的方式差这么多？ multi-reactors的主reactor万一挂了，怎么办？（类似单点故障问题） multi-reactors + goroutine pool的模式下，subreactor负责输入输出，goroutine pool负责计算，若某个任务的数据量比较大，从subreactor到goroutine pool或从goroutine pool到subreactor的数据传输成本会不会很大？   答： 问题 1 参见上面第一个我回答的问题；问题 2 说的 Reactor 单点问题的确是存在的，因为 gnet 使用的是主从 Reactors 模式，main reactor 只有一个，所以的确存在这个潜在的问题，解决办法也有：使用多 acceptors，利用 SO_REUSEPORT 参数让内核帮你做 load balancing 避免惊群；至于问题 3 ：并不存在数据传输成本，从当前 eventloop goroutine 也就是 gnet.React 方法里一般是用 closure 闭包的方式提交任务到 goroutine pool 的，是引用方式。\nQ6: goroutine pool如何把数据送回到subreactor？ 当你在独立的 goroutine 里完成你的阻塞逻辑之后得到了 response 数据，直接调用 AsyncWrite:\nfunc (c *conn) AsyncWrite(buf []byte) { if encodedBuf, err := c.loop.svr.codec.Encode(buf); err == nil { _ = c.loop.poller.Trigger(func() error { if c.opened { c.write(encodedBuf) } return nil }) } } 通过 closure 的方式，写一个唤醒事件到 epoll，同时传一个 func() error 到任务队列，在 sub reactor 的那个 goroutine 里执行这个函数，把数据写回 client。\nQ7: 在等待传回的这段时间，subreactor是不是还是得阻塞着，无法处理其他请求 不会阻塞啊，此时 React 方法已经返回了，你的阻塞逻辑是提交到 goroutine pool 里处理，处理完直接调用 AsyncWrite 异步写回去了，方式就是我上面说的，写一个唤醒事件到 epoll，在 eventloop goroutine 里执行，所以不会有同步问题。\n回看视频  https://www.bilibili.com/video/av74598921 https://youtu.be/4QurJJHuxaQ  参考资料  A Million WebSockets and Go Going Infinite, handling 1M websockets connections in Go 百万 Go TCP 连接的思考: epoll方式减少资源占用 gnet: 一个轻量级且高性能的 Golang 网络库  观看视频   ","title":"第 65 期 Go 原生网络模型 vs 异步 Reactor 模型"},{"location":"https://bytemode.github.io/reading/64-2019-10-24-go-runtime/","text":" Go 夜读第 64 期深入浅出 Golang Runtime 内容简介 本次分享将会对 go runtime 的调度，内存分配，gc 做一些细节上的讲解，同时也需要参与者对 runtime 有一些初步了解。\n内容大纲  Golang Runtime 是什么，其发展历程； 调度的实质和关键数据结构，函数； 内存分配中 mspan, mheap, mcentral, mcache 等数据结构 Golang GC 发展，Golang 三色标记实现的一些细节，元信息，写屏障，1.5 与 1.12 GC 的区别； 一点优化思路与问题排查思路； 总结及 question； 平时我看 runtime 代码的一些方式；  分享嘉宾 郝以奋，yifhao, 腾讯 NOW 直播后台开发，负责 NOW 直播 CPP+JAVA 双栈 -\u0026gt; Golang 转型：框架协同建设，业务功能定制，Go Mod 引入，服务模板，RPC 协议 Go Mod 化，服务模板，Golang 培训，文档等。\n目前 NOW 直播后台有 300 多个 Go 服务。\n分享信息 时间：2019-10-17 21:00:00 ~ 23:10:00, UTC+8 分享 Slides：https://github.com/Frank-Hust/share\n回看视频  https://www.bilibili.com/video/av73297683 https://youtu.be/oFJL8S1dwsw  Q\u0026amp;A 总结 Q: 腾讯现在用go的多吗? 多, 至少 2000 人的级别了，对go的接受度挺高的，使用人数在迅速增加，当然大部分团队还是 cpp。\nQ: 腾讯 NOW 直播 go 开发占比多少？ 我们都是从其他语言转的，cpp，java-\u0026gt;golang，一开始就写 go 的比较少。基本上学习一下，一个星期就可以开始写线上 go 服务了。目前新服务都是 go。\nQ: 线程切换的开销 线程切换大概在几微秒级别，协程切换大概在百 ns 级别。\n线程切换过程: 1. 进入系统调用 2. 调度器本身代码执行 3. 线程上下文切换: PC, SP 等寄存器，栈，线程相关的一些局部变量，还涉及一些 cache miss 的情况； 4. 退出系统调用\n协程切换不需要进入和退出系统调用, 在进行上下文切换时也更轻量, 只需要切换几个寄存器, 协程 runtime.g 结构只有 40 多个字段, 而线程的 task struct 有大概 300 个字段.\n可参考进程/线程上下文切换会用掉你多少CPU？ https://zhuanlan.zhihu.com/p/79772089\n协程究竟比线程能省多少开销？ https://zhuanlan.zhihu.com/p/80037638\nQ: 为啥是边缘触发, 而不是水平触发的方式? 因为网络操作 ready 和未 ready 对于协程来说就是状态的切换。 socket fd ready 了, 阻塞之上的协程就从 waiting 变成 runnable。 操作时 socket fd 未 ready，那协程就从 running 变成 waiting。 假如采取水平触发，如果一个协程因为某个连接读而变成 waiting 状态，这个连接有数据后，与之关联的协程就变成 ready，这个协程一直没去读数据，那水平触发一直就会 poll 出来该 fd，没必要。\nQ: 内存什么时候释放? 内存释放分两步 没有存活对象的 span 被 GC 回收, 归还到 mheap 结构中，变成 free 的 page。 sysmon 协程会扫描，超过一段时间没有再被使用的 page(1.12 机制有改变), 通过 madvise 系统调用告诉操作系统，这些 page 对应的物理内存不再需要了，可以与虚拟内存解绑，给其他分配使用。\nQ: 0.1+13+0.3ms 三个时间的意思？ GCDEBUG=gctrace=1 会打印出 gc 相关的时间，这三个分别代表，gc 开始时第一个 stw 的 wall time, 并发标记的 wall time 以及 GC 标记结束阶段 stw 的 wall time。\nQ: []byte 于 string 的黑魔法 底层数据共享，减少数据拷贝。 https://jaycechant.info/2019/golang-unsafe-cast-between-string-and-bytes/\nQ: 之前说的 netpoll，被 gopark 挂起的 G 扔哪了，怎么找到对应的 G，然后又怎么扔给对应的 M 的 runQ 的？ 并没有扔哪里去，也没放在哪个队列。 一个协程因为某个网络 fd 的操作阻塞时，会把该 fd 添加到 epoll 中，使用以下系统调用。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64; } epoll_data_t; struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; go 在 epoll_event 中的 epoll_data_t 放了一个指针值，该指针指向一个包含 runtime.g 的结构体。 下次 epoll_wait 时，便可把该 epoll_data_t 也 poll 出来，相当于与该 fd 关联的上下文，也就可以找到阻塞其上的协程。\n不需要再放回对应的 M 的 runq 中，目前是通过 injectglist 放在全局的 runq 中。\n观看视频   ","title":"第 64 期深入浅出 Golang Runtime"},{"location":"https://bytemode.github.io/reading/63-2019-10-17-go-style-and-go-advices/","text":" Go 夜读第 63 期 Go 编码风格阅读与讨论 内容简介 本期主要是针对近期 uber-go/guide style 和 go-advices 的解读以及开发者讨论。\n内容大纲  Go CodeReview Comments Uber-go/style Go-advices  分享地址 2019-10-17 21:00:00 ~ 22:10:00, UTC+8\nhttps://zoom.us/j/6923842137\n分享 Slides https://docs.google.com/presentation/d/1MlzZJBK0Zq0VzJVC_AqSWmmlS4Of-8xY6NGZmfhKQXI/edit?usp=sharing\n进一步阅读的材料  Go CodeReviewComments uber-go/guide style go-advices  Go CodeReviewComments 翻译  Go Code Review Comments 译文（截止 2018 年 7 月 27 日）  Go 官方的建议已经涉及到非常方面：\n Gofmt Comment Sentences Contexts Copying Crypto Rand Declaring Empty Slices Doc Comments Don\u0026rsquo;t Panic Error Strings Examples Goroutine Lifetimes Handle Errors Imports Import Dot In-Band Errors Indent Error Flow Initialisms Interfaces Line Length Mixed Caps Named Result Parameters Naked Returns Package Comments Package Names Pass Values Receiver Names Receiver Type Synchronous Functions Useful Test Failures Variable Names  gofmt 不管你是用什么开发工具，都推荐一定要配置 goimports。\nContext  Context 应该在函数的第一个参数； 不要将 Context 加到结构体中，而应该加一个 ctx 参数； 不要创建自定义的 Context 类型； Context 是不可变的，所以可以将相同的 ctx 传递给调用共享相同截止日期，取消信号，凭证，父跟踪等；  虽然官方已经说明了，但是也还是有不少公司或者开源项目有自己的设计和实现。\nDeclaring Empty Slices var t[]string 比 t:= []string{} 更好\nImports 应该按系统库、内部库、第三方库分层分隔。\nIndent Error Flow if err != nil { // error handling... \treturn // or continue, etc. } // other codex, err := f() if err != nil { // error handling... \treturn } // use x... Variable Names  局部变量应该越精简越好； 不通用的或者全局变量，应该描述更清楚的命名；  Uber Go 风格指南翻译  Uber Go 风格指南 (译) by 徐旭 Uber Go 语言编程规范 by legendtkl 【重磅】Uber Go 语言代码风格指南 by Go 中国 Uber Go 语言编码规范 by TonyBai  上周刚出来，过了2天，就出现大量的翻译文章，也能够看出来 Go 语言虽然官方有 gofmt，以及 go vet 静态代码检测工具，但是也抵挡不住大家对于代码风格的热衷。 \u0026gt;也说明大家还希望将代码风格更统一，追求更好的代码。\nGo-advices  Code Concurrency Performance Modules Build Testing Tools Misc  代码方面  var foo time.Duration 比 var fooMillis int64 更好 检查 defer 中的 error 用 %+v 打印足够详细信息 小心 range map 中读取一个不存在的 key 不会 panic，建议：value, ok := map[“no_key”] 将 defer 移到顶部  Dave Cheney  Practical Go: Real world advice for writing maintainable Go programs 中文翻译版（2018 年）：https://www.flysnow.org/2018/12/04/golang-the-go-best-presentations.html  Q\u0026amp;A 总结  下划线开头 来声明 全局变量 \u0026gt;很少见，也不太适用。 为什么建议channel尽量不加buffer? \u0026gt;按需分配。 go.uber.org/atomic \u0026gt;库非常好，原子操作很方便。新增多种数据类型。 package_test 比 package 好？ \u0026gt;比较清晰，但是也有局限性，测试不了内部逻辑，类似于外部包调用。 go test 指定 -count 可以消除偶然因素导致的不稳定结果。 \u0026gt;-count=1 也可以消除 cache。 有没有认证或授权库的推荐？ \u0026gt;github 上搜索即可，一般可以根据 star 数量和活跃情况来评判。 也可以去 godoc.org 搜索，查看 imports 引入数据来评判。 https://github.com/dgrijalva/jwt-go  观看视频   ","title":"第 63 期 Go 编码风格阅读与讨论"},{"location":"https://bytemode.github.io/reading/62-2019-10-10-go-micro-part1/","text":" Go 夜读第 62 期 Go-Micro 微服务框架 Part 1 内容简介 介绍Go-Micro的设计及其重要组件\n内容大纲  什么是 Micro Micro 风格服务架构 Go-Micro 框架的设计 Go-Micro 主要的组件 Go-Micro 的插件化  分享地址 2019-10-10 21:00 ~ 22:00, UTC+8\nhttps://zoom.us/j/6923842137\n进一步阅读的材料  Micro 项目 Micro 文档 示例项目 PPT  请点击：https://github.com/developer-learning/reading-go/issues/457\nQ\u0026amp;A 总结  micro 是Restful吗？  答：go-micro并不是一个web框架，不过go-micro中有web模块可以提供restful风格服务。\n srv里面是包含client和server吗？  答：每一个服务都会有client和server，服务要能调用其它服务就需要一个client，能接收请求就需要server。\n 为什么异构service互相调用一定要经过proxy，rpc不应该是编码和transport约定好本身就支持异构调用吗？  答：micro proxy并不支持互调，它提供一个go-micro特性的代理，其它非go-micro风格的服务通过这个代理加入go-micro体系，便可以通过proxy被其它服务调用，可以是http、grpc等。\n我会在未来几天增加一篇专门介绍micro的文档在这里：micro proxy\n micro与k8s  答：这是一个常见的问题，micro会常与k8s、istio比较或联系，这是不公平的也是不合理的。主要在这么几个方面：\na) micro与k8s同时起步，或者说micro更早些，k8s的产生是基于容器技术的兴起，而容器需要管理与编排。K8s确实给大型服务集群提供了极好的运维平台，但是它在一定适度上并不是面向开发人员的工具，更多是面向运维人员的。\nb) 基于a，Micro是面向开发人员的微服务框架，如果人们用了K8s，那应该就不要用micro。\nc) 绝大部分开发者可以试问内心的需求：自己当下的服务运行需求，真的需要K8s吗？说句傲娇的话，如果不能看到micro的价值，那请不要使用micro，在K8s中使用micro，就像皇宫的大内总管，少了件最重要的东西。\n 为啥要 consul 换成 etcd  答：从4年的结合Consul经验来说，它工作得比较正常但并不尽如人意，它有太多功能我们用不到。consul更多是面向Hashicorp体系的服务，而Etcd则更纯粹是服务注册组件，是的，我们需要更纯粹的中间件。更多可以参考一篇不太细致的博文：deprecating-consul\n client 和server可以在一个go文件中吗？  答：可以，但是为什么要这么做哩？\n go-micro中如何使用链路追踪？  答：在go-micro中提供了装饰器Wrapper可以集成任何支持go语言的链路追踪插件。见：Tracing\n Go-Micro 设计初衷、目标以及未来发展方向？  答：Go-Micro 设计初衷是做一套面向开发人员的微服务框架，她要使用简单、扩展简单、管理简单。但是仍然有很长的路要走，从技术上讲，目标是要发展成Java界的Spring Cloud。\n关于未来的发展，一个技术终究是要赚钱的，Micro公司的开发与发展目标，详见与Network\n观看视频   ","title":"第 62 期 Go-Micro 微服务框架 Part 1"},{"location":"https://bytemode.github.io/reading/60-2019-09-19-ipfs-guide/","text":" Go 夜读第 60 期 IPFS 星际文件系统 背景介绍 传统的 HTTP 都是通过资源定位符来定位，在服务器关闭后，有些数据可能会永远丢失，而且如果某客户离服务器比较远，则可能延时较高。IPFS 提出使用基于内容寻址，只要拥有 hash 且网络上有人存储此数据，即可获得数据，同时自带 CDN 效果（热数据会自动分散）。\n内容简介 主要介绍一下 ipfs 的基本思想与使用，并分析源码结构以及粗略介绍相关兄弟项目（如 multiformats,filecoin 等)\n内容大纲  IPFS 的底层技术原理。 IPFS 源码概述。 超越 IPFS - 区块链存储简述。 Q\u0026amp;A。  分享地址 2019-09-19, 21:00 ~ 22:10, UTC+8\nhttps://zoom.us/j/6923842137\n进一步阅读的材料  IPFS paper 源码 PPT 预习资料  请点击：https://github.com/developer-learning/reading-go/issues/460\nQ\u0026amp;A 总结  IPFS 是如何组网的？ 答：IPFS 的底层网络库是 Libp2p，Libp2p 的路由算法是 S-KadDHT（分布式哈希表），只要能连接到网络中的几个节点，通过节点发现与交换，很容易就能进入到网络里，所以需要设置 bootstrap 节点作为连接种子。对于个人或公司想用 IPFS 组网，可以用 swarm.key 组建一个私网（需要指定一bootstrap），即可实现内部的 IPFS 网络。\n IPFS 如何实现模糊搜索？ 答：首先 IPFS 的 DAG 节点里面都是有一个 name 项，此外还有一些其他的信息可以解析，这样的话可以爬取这些元数据信息，用一些搜索引擎工具即可模糊搜索，开源实现：https://github.com/ipfs-search/ipfs-search，可以用来当做参考。\n IPFS 其他的相关资料。\n  中文资料，有一本《IPFS 原理与实践》，其次有一个 github 仓库：https://github.com/xipfs/IPFS-Internals，还有 IPFS 的各种命令解释：http://cw.hubwiz.com/card/c/ipfs/1/1/1/ 英文首先有官方文档：https://github.com/ipfs/specs，https://github.com/filecoin-project/specs，一个教程：https://flyingzumwalt.gitbooks.io/decentralized-web-primer 。\n观看视频   ","title":"第 60 期 IPFS 星际文件系统"},{"location":"https://bytemode.github.io/reading/59-2019-09-12-real-world-go-concurrency-bugs-in-paper-reading/","text":" Go 夜读第 59 期 Real-world Go Concurrency Bugs 内容简介 Go 语言鼓励其用户多使用基于消息传递的同步原语 channel，但也不排斥其用户使用基于内存共享的同步原语，提供了诸如 sync.Mutex 等互斥原语。在过去十年的时间里，Go 的实践者不断思考着这些问题：哪种同步原语更加优秀？究竟什么场景下应该使用何种同步原语？哪类同步原语能够更好的保证数据操纵的正确性？哪类同步原语对程序员的心智负担较大？何种同步原语更容易产生程序 Bug？channel 是一种反模式吗？什么类型的 Bug 能够更好的被 Bug 检测器发现？……\n[Tu et al., 2019] 调研了包括 Docker, Kubernetes, gRPC 等六款主流大型 Go 程序在演进过程中出现的 171 个与同步原语相关的 Bug，并给出了一些有趣的见解。本次分享将讨论 [Tu et al. 2019] 的研究论文。\n内容大纲  Go 常见的并发模式与论文的研究背景 论文的研究方法 Go 并发 Bug 的分类及部分主要结论  阻塞式 Bug 非阻塞式 Bug  Go 运行时死锁、数据竞争检测器对 Bug 的检测能力与算法原理（如果时间允许） 论文的结论、争议与我们的反思  分享地址 2019-09-12, 21:00 ~ 22:10, UTC+8\nhttps://zoom.us/j/6923842137\n进一步阅读的材料  [Ou, 2019a] Real-world Go Concurrency Bugs PPT  本次分享的 PPT: 这里  [Pike, 2012] Go Concurrency Patterns  Rob Pike 关于 「Go 并发模式」的 PPT  [Gerrand, 2013] Advanced Go Concurrency Patterns  Sameer Ajmani 关于 「Go 并发模式进阶」的 PPT  [Tu et al., 2019] Understanding Real-World Concurrency Bugs in Go  本次分享讨论的论文 论文作者的 PPT Bug Table 论文中对应的 GitHub 仓库：https://github.com/system-pclub/go-concurrency-bugs 与论文作者的一次面谈记录：https://www.jexia.com/en/blog/golang-error-proneness-message-passing/ Hacker News 对本文的讨论 https://news.ycombinator.com/item?id=19280927  [Utahn, 2019] Go channels are bad and you should feel bad  Reddit 对本文的讨论：https://www.reddit.com/r/golang/comments/48mnrp/go_channels_are_bad_and_you_should_feel_bad/  [Ou, 2019b] Go 夜读 第 56 期：channel \u0026amp; select 源码分析  请点击：https://github.com/developer-learning/reading-go/issues/464\nQA Q: 可以再详细说一下 lift 指标吗？\nA: 可以从两种不同的角度来思考这个指标。\n 借鉴 person 相关性系数（余弦相似性) |X·Y|/(|X|*|Y|) 借鉴 Bayes 公式 P(B|A) = P(AB)/P(A)  Lift(cause, fix) = 导致阻塞的 cause 且使用了 fix 进行修复的概率 除以 cause 的概率乘以 fix 的概率 = P(cause, fix) / (P(cause)P(fix)) = P(cause|fix)/P(cause) 接近 1 时，说明 fix 导致 cause 的概率接近 cause 自己的概率，即 P(cause|fix) 约等于 P(cause) 于是 fix 和 cause 独立 大于 1 时，说明 fix 导致 cause 的概率比 cause 自己的概率大，即 P(cause|fix) \u0026gt; P(cause) =\u0026gt; P(fix | cause) \u0026gt; P(fix)，即 cause 下 fix 的概率比 fix 本身的概率大，正相关 小于 1 时，同理，负相关   Q: 可以贴一下提到的两篇相关文献吗？\nA: 论文引用了两篇很硬核的形式化验证的论文：\n Julien Lange, Nicholas Ng, Bernardo Toninho, and Nobuko Yoshida. Fencing off go: Liveness and safety for channel-based programming. In Proceedings ofthe 44th ACMSIGPLANSymposium on Principles of Programming Languages (POPL ’17), Paris, France, January 2017.\n Julien Lange, Nicholas Ng, Bernardo Toninho, and Nobuko Yoshida. A static verification framework for message passing in go using be- havioural types. In IEEE/ACM40th International Conference on Software Engineering (ICSE ’18), Gothenburg, Sweden, June 2018.\n  Q: 作者还分享了其他语言的关于并发 Bug 的论文，比如 Rust。\nA: 地址在这里，但是思路完全一致，可以直接扫一眼结论。\nQ: 能否将 CSP 和 Actor 模型进行一下简单比较？\nA: CSP 和 Actor 的本质区别在于如何对消息传递进行建模。Actor 模型强调每个通信双方都有一个“信箱”，传递消息的发送方对将这个消息发给谁是很明确的，这种情况下 Actor 的信箱必须能够容纳不同类型的消息，而且理论上这个信箱的大小必须无穷大，很像你想要送一件礼物给别人，你会直接把礼物递给这个人，如果这个人不在，你就扔到他家的信箱里；CSP 需要有一个信道，因此对发送方而言，其实它并不知道这个消息的接收方是谁，更像是你朝大海扔了一个漂流瓶，大海这个信道根据洋流将这个漂流瓶传递给了其他正在观察监听大海的人。\nQ: 读论文的目标是什么？\nA: 我读论文主要有两个目标：1. 了解论文的研究方法，因为研究方法可能可以用在我未来的研究中；2. 了解论文的整体思路，因为论文很多，思路远比它们的结果对我未来自己的研究更重要。\nQ: 去哪儿找这类论文？\nA: 我们这次讨论的论文是我偶然在 Go 语言 GitHub 仓库的 Wiki 上看到的；一般情况下我会订阅 ArXiv，然后定期浏览新发出来的文章。\n观看视频   ","title":"第 59 期 Real-world Go Concurrency Bugs"},{"location":"https://bytemode.github.io/reading/58-2019-09-05-whats-new-in-go1.13/","text":" Go 夜读第 58 期 What\u0026rsquo;s new in Go 1.13？ 内容简介\n主要介绍了刚刚发布的 Go 1.13 Release 的内容。\n内容大纲 - Go modules - Toolchain - Runtime - CoreLibrary Improve Performance - Q\u0026amp;A\n分享地址 2019-09-05, 21:00 ~ 22:10, UTC+8\nhttps://zoom.us/j/6923842137\n进一步阅读的材料  https://golang.org/doc/go1.13 improve defer perfermance 30% goproxy.cn - 为中国 Go 语言开发者量身打造的模块代理  更多见：https://github.com/developer-learning/reading-go/issues/465\n观看视频   ","title":"第 58 期 What's new in Go 1.13？"},{"location":"https://bytemode.github.io/reading/57-2019-08-29-sync-semaphore/","text":" Go 夜读第 57 期 sync/semaphore 源码浅析 内容简介\n主要分析 golang.org/x/sync/semaphore 相关代码和 semaphore 部分使用场景。\n内容大纲 - semaphore 定义 - 源码分析 - Q\u0026amp;A\n分享地址 2019.08.29, 21:00 ~ 21:40, UTC+8\nhttps://zoom.us/j/6923842137\n进一步阅读的材料  semaphore 定义 源码 分享 PPT  补充资料  同步原语 结合 errgroup 使用 关于是否应该支持 resize 的讨论 semaphore 实现的 taskpool  更多见：https://github.com/developer-learning/reading-go/issues/456\n观看视频   ","title":"第 57 期 sync/semaphore 源码浅析"},{"location":"https://bytemode.github.io/reading/56-2019-08-22-channel-select-in-go/","text":" Go 夜读第 56 期 channel \u0026amp; select 源码分析 内容简介\nGo 语言除了提供传统的互斥量、同步组等同步原语之外，还受 CSP 理论的影响，提供了 channel 这一强有力的同步原语。本次分享将讨论 channel 及其相关的 select 语句的源码，并简要讨论 Go 语言同步原语中的性能差异与反思。\n内容大纲 - 同步原语概述 - channel/select 回顾 - channel 的结构设计 - channel 的初始化行为 - channel 的发送与接收过程及其性能优化 - channel 的回收 - select 的本质及其相关编译器优化\n分享地址 2019.08.22, 20:30 ~ 21:30, UTC+8\nhttps://zoom.us/j/6923842137\n进一步阅读的材料 [Ou, 2019] channel \u0026amp; select 源码分析 分享内容的 PPT [Ou, 2018] Go 源码研究 分享者写的一本 Go 源码分析 [Mullender and Cox, 2008] S. Mullender and R. Cox, Semaphores in Plan 9 影响 Go 语言信号量设计的一篇文章 [Drepper, 2003] U. Drepper, Futexes are Tricky 第一篇正确实现 Linux Futex 机制的文章 [Vyukov, 2014a] D. Vyukov, Go channels on steroids, January 2014 无锁式 channel 的设计提案 [Vyukov, 2014b] D. Vyukov, runtime: lock-free channels, October 2014 关于无锁式 channel 的讨论、早期实现与现状 [Hoare, 2015] C. A. R. Hoare, Communicating Sequential Processes. May 18, 2015 有关 CSP 理论的一切，与早期 1978 年的版本相比更为完善和严谨 [Creager, 2016] D. Creager, An oversimplified history of CSP, 2016 CSP 理论的极简史\n更多见：https://github.com/developer-learning/reading-go/issues/450\n本次分享的 Q\u0026amp;A 以及几个未在分享过程中进行回答的问题： Q: buffer 队列的顺序是先进后出吗？\nA: 不对，channel 中的 ring buffer 是一种先进先出 FIFO 的结构。\nQ: channel 也是基于共享内存实现的吗？\nA: 没错，从实现上来看，具体而言，channel 是基于对 buffer 这一共享内存的实体来实现的消息通信，每次对所共享内存区域的操作都需要使用互斥锁（个别 fast path 除外）。\nQ: 创建 channel 所申请的内存，在其被 close 后何时才会释放内存？\nA: 需要等待垃圾回收器的配合（GC）。举例来说，对于某个 channel 而言，所通信双方的 goroutine 均已进入 dead 状态，则垃圾回收器会将 channel 创建时申请的内存回收到待回收的内存池，在当下一次用户态代码申请内存时候，会按需对内存进行清理（内存分配器的工作原理）；由此可见：如果我们能够确信某个 channel 不会使其通信的 goroutine 发生阻塞，则不必将其关闭，因为垃圾回收器会帮我们进行处理。\nQ: 请问是否可以分享一下带中文注释的代码？\nA: 带中文注释的代码可以在这个仓库的 gosrc 文件夹下看到。\nQ: 能详细说明一下使用 channel 发送指针产生数据竞争的情况吗？\nA: 这个其实很好理解，若指针作为 channel 发送对象的数据，指针本身会被 channel 拷贝，但指针指向的数据本身并没有被拷贝，这时若两个 goroutine 对该数据进行读写，仍然会发生数据竞争；请参考此例 （使用 -race 选项来检测竞争情况）。因此，除非在明确理解代码不会发生竞争的情况下，一般不推荐向 channel 发送指针数据。\nQ: 分享的 PPT 的地址在哪儿？\nA: 链接在这里，此 PPT 允许评论，若发现任何错误，非常感谢能够指出其错误，以免误导其他读者。\nQ: 请问分享的视频链接是什么？\nA: 有两个渠道，YouTube, bilibili，bilibili 中视频声画不同步，可使用 B 站的播放器进行调整，或推荐使用 YouTube 观看。\nQ: Go 语言中所有类型都是不安全的吗？\nA: 这个问题不太完整，提问者应该是想说 Go 中的所有类型都不是并发安全的。这个观点不对，sync.Map 就是一个并发安全的类型（当然如果你不考虑标准库的话，那么内建类型中，channel 这个类型也是并发安全的类型）。\nQ: 如果 channel 发送的结构体太大，会不会有内存消耗过大的问题？\nA: 取决于你结构体本身的大小以及你所申请的 buffer 的大小。通常在创建一个 buffered channel 时，该 channel 消耗的内存就已经确定了，如果内存消耗太大，则会触发运行时错误。我们更应该关注的其实是使用 channel 发送大小较大的结构体产生的性能问题，因为消息发送过程中产生的内存拷贝其实是一件非常耗性能的操作。\nQ: select{} 的某个 case 发生阻塞则其他 case 也不会得到执行吗？\nA: 对的。包含多个 case 的 select 是随机触发的，且一次只有一个 case 得到执行。极端情况下，如果其中一个 case 发生永久阻塞，则另一个 case 永远不会得到执行。\nQ: select 中使用的 heap sort 如何保证每个 case 得到均等的执行概率呢？是否可能会存在一个 case 永远不会被执行到？\nA: 理论上确实是这样。但是代码里生成随机数的方法保证了是均匀分布，也就是说一个区间内的随机数，某个数一直不出现的概率是零，而且还可以考虑伪随机数的周期性，所以所有的 case 一定会被选择到，关于随机数生成的具体方法，参见 runtime.fastrand 函数。\nQ: lockorder 的作用是什么？具体锁是指锁什么？\nA: lockorder 是根据 pollorder 和 channel 内存地址的顺序进行堆排序得到的。 pollorder 是根据 random shuffle 算法得到的，而 channel 的内存地址其实是内存分配器决定的，考虑到用户态代码的随机性，因此堆排序得到的 lockorder 的结果也可以认为是随机的。lockorder 会按照其排序得到的锁的顺序，依次对不同的 channel 上锁，保护其 channel 不被操作。\nQ: buffer 较大的情况下为什么没有使用链表结构？\nA: 这个应该是考虑了缓存的局部性原理，数组具有天然的连续内存，如果 channel 在频繁的进行通信，使用数组自然能使用 CPU 缓存局部性的优势提高性能。\nQ: chansend 中的 fast path 是直接访问 qcount 的，为什么 chanrecv 中却使用了 atomic load 来读取 qcount 和 closed 字段呢？\nA: 这个这两个 fast path 其实有炫技的成分太高了，我们需要先理解这两个 fast path 才能理解为什么这里一个需要 atomic 操作而另一个不需要。\n首先，他们是针对 select 语句中非阻塞 channel 操作的的一种优化，也就是说要求不在 channel 上发生阻塞（能失败则立刻失败）。这时候我们要考虑关于 channel 的这样两个事实，如果 channel 没有被 close：\n 那么不能进行发送的条件只可能是： unbuffered channel 没有接收方（ dataqsiz 为空且接受队列为空时），要么 buffered channel 缓存已满（dataqsiz != 0 \u0026amp;\u0026amp; qcount == dataqsize） 那么不能进行接受的条件只可能是：unbuffered channel 没有发送方（ dataqsiz 为空且发送队列为空），要么 buffered channel 缓存为空（dataqsiz != 0 \u0026amp;\u0026amp; qcount == 0）  理解是否需要 atomic 操作的关键在于：atomic 操作保证了代码的内存顺序，是否发生指令重排。\n由于 channel 只能由未关闭状态转换为关闭状态，因此在 !block 的异步操作中，\n第一种情况下，channel 未关闭和 channel 不能进行发送之间的指令重排是能够保证代码的正确性的，因为：在不发生重排时，「不能进行发送」同样适用于 channel 已经 close。如果 closed 的操作被重排到不能进行发送之后，依然隐含着在判断「不能进行发送」这个条件时候 channel 仍然是未 closed 的。\n但第二种情况中，如果「不能进行接收」和 channel 未关闭发生重排，我们无法保证在观察 channel 未关闭之后，得到的 「不能进行接收」是 channel 尚未关闭得到的结果，这时原本应该得到「已关闭且 buf 空」的结论（chanrecv 应该返回 true, false），却得到了「未关闭且 buf 空」（返回值 false, false），从而报告错误的状态。因此必须使此处的 qcount 和 closed 的读取操作的顺序通过原子操作得到顺序保障。\n参考 1 首次引入 2 性能提升\nQ: 听说 cgo 性能不太好，是真的吗？\nA: 是的，至少我的经验的结论是 cgo 性能非常差。因为每次进入一个 cgo 调用相当于进入 system call，这时 goroutine 会被抢占，从而导致的结果就是可能会很久之后才被重新调度，如果此时我们需要一个密集的 cgo 调用循环，则性能会非常差。\nQ: 看到你即写 C++ 也研究 Go 源码，还做深度学习，能不能分享以下学习的经验？\nA: 老实说我已经很久没（正儿八经）写 C++ （的项目）了，写 C++ 那还是我本科时候的事情，那个时候对 C++ 的理解还是很流畅的，但现在已经感觉 C++ 对于我编程的心智负担太高了，在编写逻辑之外还需要考虑很多与之不相关的语言逻辑，大部分时间其实浪费在这上面了，时间稍长就容易忘记一些特性。加上我后来学了 Go ，就更不想用 C++ 了。另外，我读硕士的时候主要在研究机器学习，主要就是在写 python 脚本。所以我暂时也没什么比较系统的经验，如果非要回答的话，我的一个经验就是当（读源码）遇到问题之后硬着头皮走下去，当积累到一定程度之后在回过头去审视这些问题，就会发现一切都理所当然。\nQ: 你是怎么读 Go 源码的？\nA: 最开始的时，我选择了一个特定的版本，将想看的源码做了一个拷贝（主要是运行时的代码，刨去了 test、cgo、架构特定等代码），而后每当 Go 更新一个版本时，都用 GitHub Pull request 的 diff 功能，去看那些我关心的代码都发生了哪些改变。当需要我自身拷贝的代码时，其实会发现工作量并不是很大。刚接触 Go 源码的时候其实也是一脸懵，当时也并没有太多 Go 的编码经验，甚至连官方注释都看不太明白，后来硬着头皮看了一段时间，就慢慢的适应了。\nQ: 有没有什么比较好的英文的（Go 相关的）资料推荐？\nA: 其实我订阅的 Go 的信息并不多，主要原因还是信息量太多，平时太忙应付不过来，所以只订阅了几个比较知名的博客，比如 www.ardanlabs.com/blog, dave.cheney.net 和一些 medium 上比较大众的跟 Go 有关的 channel；我倒是经常在地铁或睡觉前听一个叫做 Go Time 的 Podcast，这个 Podcast 是有 Go 团队的成员参与的，很值得一听。另外再推荐一些与 Go 不是强相关的技术类书籍，参见 书籍推荐。\n观看视频   ","title":"第 56 期 channel \u0026 select 源码分析"},{"location":"https://bytemode.github.io/reading/55-2019-08-15-go-webassembly-guide/","text":" Go 夜读第 55 期 Go\u0026amp;WebAssembly 简介 WebAssembly 简介 WebAssembly 是一种新兴的网页虚拟机标准，它的设计目标包括：高可移植性、高安全性、高效率（包括载入效率和运行效率）、尽可能小的程序体积。\n根据 Ending 定律：⼀切可被编译为 WebAssembly 的，终将被编译为 WebAssembly。\n本次分享 Go\u0026amp;WebAssembly 相关的用法。\n分享时间 2019-08-15 21:00:00\n分享平台 zoom 在线直播 - https://zoom.us/j/6923842137\n更多讨论 FelixSeptem：补充一下 go 官方给的 wiki https://github.com/golang/go/wiki/WebAssembly 以及 WebAssembly 官网 https://webassembly.org/ 个人比较倾向于对于 https://github.com/gopherjs/gopherjs 来比较理解，相对于 go-\u0026gt;js (包括 react 等等) 的方案，WebAssembly 带来的异同是什么？\nchai2010 ：@FelixSeptem wasm 和 gopherjs 最大的差异：wasm 是官方支持，同时 wasm 是国际标准是其它语言认可的中间格式。\n以前虽然很多工具输出 js，那是因为没有 wasm 可以选择。 现在有了 wasm，大家肯定只支持 wasm 而逐渐弱化 js 的支持。 毕竟 wasm 虚拟机实现比 v8 简单多了，性能又可以秒杀 js。\nwasm 最大的潜力是在浏览器之外，甚至可以想象成一个轻量化的 Docker 环境。 我觉得这个才是 wasm 真正有意思的地方，wasm 对于 js 完全属于降维打击。\nchangkun：还没有在生产环境使用过 wasm。从给的马里奥的例子来看，go wasm 本质上是分发由 Go 编译好 .wasm，而 Go 端的本质就是提供了一些能够解释为 wasm 的 utils。不太清楚会不会在分享中提及这一本质。\n长远来看，这个 .wasm 文件在特性支持的情况下最终会包含完整的 Go 运行时， 但 go wasm 并没有明确在 web 场景下为什么一定需要它，当然不可否认它的确为兼容并移植 Go 代码来发展 web 应用带来了便捷，但前提是我们必须有足够多基础设施是基于 Go 的，但游戏并没有，非常希望看到一些能够说服用 Go 写 wasm 而不是其他语言（C/C++ 有着丰富的图形资产，而 Go 在这方面的积累为 0，甚至连马里奥的例子都是依赖一个 cgo 对 c sdl2 renderer 的封装）编译 wasm 的论点。\n参考资料  《Go\u0026amp;WebAssembly 简介》 PPT  《WebAssembly 标准入门》 图书  观看视频   ","title":"第 55 期 Go\u0026WebAssembly 简介"},{"location":"https://bytemode.github.io/reading/54-2019-08-14-tidb-sql-tools/","text":" Go 夜读第 54 期 TiDB SQL 兼容性测试工具简介 本次分享包含两方面内容：\n通过 MySQL yacc 文件生成 SQL Cases，并用于 TiDB 的兼容性测试的原理讲解。 TiDB Parser 兼容性社区活动介绍，手把手的演示如何参与本次社区活动。\n(彩蛋：Parser Working Group 成立了，有兴趣的小伙伴可以看视频然后扫描加入。)\n分享时间 2019-08-14 21:00:00\n分享平台 zoom 在线直播 - https://zoom.us/j/6923842137\n参考资料  三十分钟成为 Contributor | 提升 TiDB Parser 对 MySQL 8.0 语法的兼容性  观看视频   ","title":"第 54 期 Go 夜读之 TiDB SQL 兼容性测试工具简介"},{"location":"https://bytemode.github.io/reading/53-2019-08-01-build-in-delete-from-map-in-go/","text":" Go 夜读第 53 期 delete from map in go 突然有一个需求要删除 map 中的一些过滤数据。 \u0026gt;由此查阅了一些资料，然后促成此次分享。\nPPT： build-in func delete from map in go.pptx\n分享时间 2019-08-01 21:00:00\n分享平台 zoom 在线直播 - https://zoom.us/j/6923842137\n参考资料  https://stackoverflow.com/questions/1736014/delete-mapkey-in-go https://blog.cyeam.com/json/2017/11/02/go-map-delete https://blog.golang.org/go-maps-in-action https://gobyexample.com/maps https://stackoverflow.com/questions/23229975/is-it-safe-to-remove-selected-keys-from-map-within-a-range-loop https://www.cnblogs.com/qcrao-2018/p/10903807.html https://appdividend.com/2019/05/12/golang-maps-tutorial-with-examples-maps-in-go-explained/ https://www.jianshu.com/p/92e9efec8688 https://www.reddit.com/r/golang/comments/5tfx7i/why_delete_doesnt_return_a_bool/ https://www.liwenzhou.com/posts/Go/08_map/ https://github.com/EDDYCJY/blog/tree/master/map  观看视频   ","title":"第 53 期 Go 夜读之 build in func delete from map"},{"location":"https://bytemode.github.io/reading/52-2019-07-25-httprouter-guide/","text":" httprouter 简介 详细内容，可以查看 https://cch123.github.io/httprouter/\n观看视频   ","title":"第 52 期 Go 夜读之 httprouter 简介"},{"location":"https://bytemode.github.io/reading/51-2019-07-18-sync-errgroup/","text":" golang.org/x/sync/errgroup errgroup 唯一的坑是for循环里千万别忘了 i, x := i, x，以前用 waitgroup 的时候都是 go func 手动给闭包传参解决这个问题的，errgroup 的.Go没法这么干，犯了好几次错才改过来\u0026rdquo;\n观看视频   ","title":"第 51 期 Go 夜读之 sync/errgroup 源码阅读"},{"location":"https://bytemode.github.io/reading/50-2019-06-27-goland-practrice/","text":" GoLand Tips \u0026amp; Tricks 问答 21:01:08 From Shengyou Fan : 全程英文+中文翻译 21:04:11 From Hao : Shengyou , r u come from TW ? 21:04:50 From Shengyou Fan : Yes, I’m from TW 21:10:04 From lucas : ctrl + tab 对应 mac 是？ 21:10:12 From mai yang : presentation assistant 21:10:26 From Shengyou Fan : 也是 ctrl + tab 21:14:26 From Dominic : 这种 example 自己在document中定义的话 是代码块吗 21:27:37 From lucas : 有什么办法可以在terminal中快速打开一个文件吗？ 21:27:46 From 江金 饶 to mai yang (Privately) : open xxx 21:27:50 From mai yang to 江金 饶 (Privately) : opne xxx 21:27:59 From mai yang : open xxx 21:28:01 From Dominic : open on mac or start on win 21:28:03 From Hao : Mac, open file 21:28:08 From Zhongxuan的 iPhone : Open . 21:28:16 From lucas : 在ide中打开 21:28:33 From Hao : \u0026hellip;\u0026hellip;. 21:28:48 From mrj : 你把对应的文件关联到ide就行了 21:29:05 From lucas : ide中的terminal 应该是可以做到的 21:29:08 From lucas : 但是我没找到 21:29:47 From mai yang : 新版本 2019.1.3 好像不能 goland . 打开某个项目了，你们的可以吗？ 21:32:57 From kevin : 双击shift还是挺不错的 21:33:04 From Kevin Bai : command + shift + A 👍 21:34:21 From mai yang : 有快捷键冲突也是很麻烦。。。 21:35:47 From mai yang : 这是全新的一种开发方式。 21:40:17 From kevin : 这个就牛逼了 21:40:24 From zhaohe : 6666 21:40:29 From bruce : 一直都用 21:40:34 From tangyinpeng : 我原来不会用goland 21:40:45 From bruce : 我一直在用这个功能 21:40:48 From kevin : 还可以自动生成 21:42:20 From Dominic : 以前玩android studio的时候模板代码玩的很溜 超级提升生产力 →_→ 21:42:26 From mrj : 可视化编程 21:43:26 From mrj : ctrl+t 21:44:37 From kevin : 看来工具还是用的不够6啊 21:46:14 From Zhongxuan的 iPhone : 跟我用mac不太一样，有点难受 21:49:15 From tangyinpeng : 做笔记啊，兄弟们 21:49:42 From kevin : 看下今晚收获少 21:49:49 From kevin : 收获多少 21:50:17 From f430 w : 掌握快捷键效率杠杠的 21:53:47 From razil : alt+enter 大法好 21:55:34 From f430 w : 当然了ide快捷键用多了，不利于白板徒手写code，哈哈 21:55:51 From razil : 面试凉凉 21:56:23 From Kevin Bai : 想太多了，先听课吧 21:58:58 From tangyinpeng : 重构快捷键是哪个来着，对不住，刚刚分心了 21:59:15 From Dominic : ctrl alt shift T 21:59:19 From tangyinpeng : tk 21:59:22 From mai yang : ctrl+t 22:06:11 From bruce : 这个req太简单 22:06:15 From bruce : 用过。 22:06:45 From Kevin Bai : 下一步搞不好就有惊艳 22:07:03 From bruce : 嗯 22:08:28 From Dominic : 咦 单元测试可以用这个玩吗 22:12:58 From Kevin Bai : 最近刚知道这个share 22:16:40 From mai yang : Share 怎么用呢？ 22:22:09 From Kevin Bai : 会在 .idea 下生成一个 run configuration ，然后可以把share的功能传到git上 22:33:38 From mrj : 这个吊 22:45:30 From 陳明進 : 直接run test with cpu profile真的是有點屌 22:53:29 From mai yang : 厉害！ 22:54:13 From 陳明進 : 這跟chrome devTool學的吧\u0026hellip;. 22:56:38 From Dominic : thank u for this great presentation 22:56:53 From Kevin Bai : 多线程调试有什么建议 ？ 22:58:14 From Eiger : 我想问下go项目包管理最推荐的是用哪个啊 22:58:26 From Dominic : go module 22:58:28 From yongping zhao : 肯定mod呀 22:58:52 From Eiger : 但是国内经常要手动获取库版本再replace 22:59:13 From Dominic : goproxy 23:00:00 From Eiger : 有免费的代理吗还是需要自己在国外搭？个人使用 23:00:22 From Dominic : goproxy.io 开源的 23:00:24 From yongping zhao : go proxy。。搜这个关键字。 23:01:26 From yongping zhao : 多线程调试有什么建议 ？ 23:02:00 From mai yang : https://blog.jetbrains.com/cn 23:02:20 From mrj : ctrl+e 23:02:23 From mai yang : Double+shift\u2028alter+enter 23:04:52 From Kevin Bai : 👍 23:05:19 From mai yang : Productivity Guide 这个很好。 23:05:44 From mrj : windwos 的 terminal 不太好用 23:06:04 From Dominic : 我一般替换成 git bash 23:06:12 From Lewis : +1 23:06:57 From Hao : hi florin , could you please show us the go mod difference between cmd and goland IDE? 23:07:58 From Kevin Bai : 是 23:07:59 From Kevin Bai : debug 23:09:12 From Dominic : 👍 23:10:57 From Lewis : double Ctrl 具体怎么用的？一直没搞懂 23:11:13 From mrj : goland有什么内置的lint工具吗 23:11:17 From mai yang : 连续按两次 shift 23:11:25 From mai yang : Double shift 不是double ctrl 23:12:09 From Lewis : run everywhere 就是double ctrl 23:12:11 From Eiger : cmder 23:13:11 From mrj : wondful 23:13:14 From mai yang : 哦 23:13:25 From Lewis : 好像是去年底更新出来的吧 23:17:09 From Dominic : wow 23:17:17 From mai yang : 这个厉害了~ 23:17:22 From mrj : 牛逼 23:17:28 From yongping zhao : 666 23:17:51 From g : 666 23:18:42 From mrj : 还能直接下载 23:19:02 From lidedongsn : 人性化 23:19:06 From tianyi wang : 这个真不知道 23:19:33 From Lewis : download go sdk 我之前试了几次都加载不出来 23:19:51 From Lewis : 是国内网络环境都问题吗 23:19:52 From mrj : 可能是从golang.org download的 23:20:18 From tianyi wang : ha介绍代理了 23:21:50 From mrj : 私有仓库 这个问题之前还真遇到了 23:22:07 From mrj : goland 一直提示go list -m 找不到包 23:22:22 From Lewis : vgo设置里面的proxy历史记录可以删除吗？写错过一次，强迫症表示看着受不了 23:23:22 From tianyi wang : 对我也遇到过，go list -m一直到找不到goole.org的那几个包 23:24:55 From Kevin Bai : 这个实用 23:25:16 From Dominic : 类似 workspace 的概念 23:25:41 From bruce : 这个实用 23:25:51 From Lewis : 之前这样弄搞得改错项目文件过😂 23:27:13 From bruce : hehe 23:28:17 From mrj : 如果这个能图形化就好了 23:31:27 From mai yang : 运行出来的怎么结束掉呢？ 23:31:41 From mai yang : double ctrl 之后的进程，怎么中断掉？ 23:32:18 From mai yang : 必须点击终止键？不能快捷键 ctrl+c? 23:32:48 From mai yang : File watchers : golint goimports 23:33:02 From mai yang : gofmt 23:33:46 From Dominic : watcher 用多了 cpu 会爆吧😂 23:44:15 From tianyi wang : 有做rust的IDE的计划吗\n观看视频   ","title":"第 50 期 Go 夜读之 GoLand Tips \u0026 Tricks"},{"location":"https://bytemode.github.io/reading/49-2019-06-26-tidb-transaction-reading/","text":" TiDB Transaction 内容介绍 本次分享主要讲 TiDB 的事务执行过程和一些异常处理，涉及 TiDB 的 session 和 tikv 部分模块。\nPDF: Source code reading of TiDB Transaction .pdf\n推荐阅读  TiDB 源码阅读系列文章（十九）tikv-client（下） 三篇文章了解 TiDB 技术内幕 - 说存储 Transaction in TiDB Coprocessor in TiKV  视频回看  TiDB 源码学习之 Executor - YouTube TiDB 源码学习之 Executor - Bilibili  问题 21:17:34 From zq : 分享妹子用的是什么IDE 21:17:44 From mrj : goland 21:17:45 From Pure White : 左上角，goland 21:17:45 From tangyinpeng : goland 21:17:46 From Heng Long : goland 21:17:57 From zq : goland现在做得这么好看啦 21:18:05 From Heng Long : Meterial theme 21:18:07 From mrj : 下来主题 21:18:22 From lk : 有什么比较不错的主题吗？ 21:18:31 From Pure White : darcula 21:18:35 From mrj : 默认的就挺好的 21:20:04 From mai yang : 明天晚上将由 GoLand 布道师给我们分享 GoLand 的使用及技巧实践分享。 21:28:23 From HAITAO的 iPhone : 点查不带timestamp，直接读最新稳定版本么？ 21:28:32 From Wei Yao : 对 21:28:52 From liber xue : 双击shift 直接search 21:28:55 From Wei Yao : 最新 commited 版本 21:35:50 From HAITAO的 iPhone : 点查，实际会默认给一个当前最新的timestamp,根据这个ts，kv返回对应的版本值?还是不带任何ts，发给kv ？ 21:36:29 From Wei Yao : 用 maxTs 21:50:04 From openinx : A very nice talk. 22:05:22 From kzl : 获取完成之后，region扩容了，数据迁移走了怎么办？ 22:06:16 From jeff : 是说 region 分裂了吧。 22:06:33 From kzl : 对的 22:08:46 From ruiayLin : region信息就会过期 22:11:05 From jeff : 那提交的时候会重试吧 22:11:39 From hezhiyong : tidb不断缓存region 的信息会不会占用很大的内存 22:13:23 From jeff : 唔，这里应该只缓冲曾经用到的 region ，并不是集群中所有 region 22:13:52 From jeff : s/ 缓冲 / 缓存 /g 22:14:44 From jeff : 貌似讲到刚才数据 region 分裂后的场景了。 22:14:56 From Wei Yao : 会重试 22:26:54 From fj : 大神 tidb的事物隔离级别 能介绍下吗？- ̗̀(๑ᵔ⌔ᵔ๑) 22:29:35 From Tengjin Xie : snapshot isolation? 22:31:48 From Wei Yao : 比 mysql 的 rr 稍微高一点 22:33:41 From fj : 刚才 讲的tidb的隔离级别是？ 22:34:03 From Wei Yao : 你可以认为是 可重复读 22:34:11 From Wei Yao : 其实这是快照隔离级别\n观看视频   ","title":"第 49 期 TiDB 源码阅读之 Transaction"},{"location":"https://bytemode.github.io/reading/48-2019-06-19-tidb-compiler-reading/","text":" TiDB Compiler 内容介绍 本次分享主要讲 TiDB 的优化器框架以及具体的 SQL 执行优化原理 。主要涉及 TiDB 的 planner 模块。欢迎大家参加！\nPPT: TiDB Compiler.pdf\n推荐阅读  TiDB 源码阅读系列文章（七）基于规则的优化 TiDB 源码阅读系列文章（八）基于代价的优化 TiDB 源码阅读系列文章（二十一）基于规则的优化 II  视频回看  TiDB 源码学习之 Executor - YouTube TiDB 源码学习之 Executor - Bilibili  问题 22:13:46 From mai yang : rule 怎么对照文档帮助理解呢？ 22:16:31 From dqyuan : 怎么快速找到代码对应的pr？ 22:18:43 From Wei Yao : git blame 22:23:04 From kzl : Order by 是会下推到tikv吗？ 22:25:02 From Wei Yao : 除非 order by 带了 limit，要不然推下去没意义 22:25:25 From Wei Yao : 有一些情况，如果是 order by 一个索引，那就直接消除掉这个 排序操作了 22:26:07 From zhao : 有意义吧，推了之后 tidb端可以直接stream merge，不知道实现了没有 22:27:38 From Wei Yao : 是可以 stream merge, 但是现在 tidb 还没实现这个，因为优先级不是太高 22:30:42 From Wei Yao : stream merge 主要是可以节省一些内存，避免 order by 太多导致 tidb oom 22:30:56 From Heng Long : 嗯，会让 tikv 的压力变大 22:34:28 From hezhiyong : limit offset 分页性能不好 22:34:53 From hezhiyong : 有好变通改写方法没 22:35:52 From hezhiyong : limit offset 会有下推到tikv么 22:36:19 From Wei Yao : limit offset 没办法的，这个是全局的 offset 22:36:40 From Wei Yao : tikv 并不知道自己的 offset 在全局的 offset 是多少 22:37:05 From Wei Yao : 这个其他数据库其实也一样 22:37:37 From hezhiyong : 那就是这个数据就是要全拿到tidb层在来过滤 22:37:38 From hezhiyong : 是吧 22:39:27 From Hao’s iPad : 喝口水吧 22:45:35 From zhao : 这个skyline prune有相关的资料吗 22:45:41 From zhao : paper之类的 22:47:09 From Wei Yao : 我记得暂时还没有 public 22:47:20 From Wei Yao : skyline pruning 就是消除一些路径 23:04:22 From mai yang : 怎么快速找到代码对应的pr？git blame\u2029这个可以演示一下吗？ 23:06:42 From tangenta : github 上面看文件的时候有个选项是 blame，那里应该比较清晰 23:09:44 From mai yang : github 上面看文件的时候有个选项是 blame，那里应该比较清晰\u2028——\u2028这个不错，看到了。\n观看视频   ","title":"第 48 期 TiDB 源码阅读之 Compiler"},{"location":"https://bytemode.github.io/reading/47-2019-06-12-tidb-exector-reading/","text":" TiDB Executor 内容介绍 本次分享主要讲 TiDB 中 insert/update/delete/select, 以及 DDL 等是如何执行的，以及涉及到相关模块。大概会涉及以下模块：\n executor distsql ddl  PPT: TiDB Executor 源码阅读.pdf\n推荐阅读  Select 语句概览 INSERT 语句详解 DDL 源码解析  视频回看  TiDB 源码学习之 Executor - YouTube TiDB 源码学习之 Executor - Bilibili  PPT: https://github.com/developer-learning/reading-go/files/3281080/TiDB.Executor.pdf\n问题  表的信息是怎么存的呢\u2028 id的生成规则是什么\u2028 如果索引里面不保存handle_id，那怎么根据索引找到这行数据呢\u2028 索引字段很大会不会有问题，作为id的一部分的话 单条6m的限制是怎么计算出来的？还是压力测出来的？ ddl时，job放到tikv的队列，tikv是分布式的，job具体是放到哪个tikv上的呢？ 并行ddl 如何跑 tikv整体上可以看成一个kv store region这部分概念可以配合hbase去看看能更好的理解 难道own tidb server要遍历所有的tikv server上的queue，去取ddl的job？ tidb 的统计信息也是放一个表里面，每次parse 都会去拿这个信息，这样的话请求到一个region,这个表是不是很容易成为热点  观看视频   ","title":"第 47 期 TiDB 源码阅读之 Executor"},{"location":"https://bytemode.github.io/reading/46-2019-06-05-tidb-overview-reading/","text":" TiDB Source Code Overview 视频回看  TiDB 源码学习之 Source Code Overview - YouTube TiDB 源码学习之 Source Code Overview - Bilibili  意见反馈  【Go夜读】《TiDB Source Code Overview》反馈  chat 答疑 20:54:52 From mai yang : 大家好，欢迎大家前来参加 Go 夜读\u0026amp;TiDB 源码学习！ 21:22:34 From nange : Session 怎么初始化的？ 21:22:46 From ccong deng : 每个连接都是跟一个session对象对应么？ 21:22:48 From jeffery : session主要包含什么？ 21:22:59 From jeffery : 譬如： 21:23:01 From Wei Yao : 对，一个链接一个 session 21:23:09 From Wei Yao : 具体包含什么，可以大家自己去看了 21:23:17 From Wei Yao : 这个线上不可能所有都讲的 21:23:25 From jeffery : 好的，谢谢了 21:31:00 From Wei Yao : 大家如果对语法分析，词法分析感兴趣，可以去看看 yacc 跟 lex 21:31:10 From hezhiyong : parser 这一层不是使用mysql的parser吗 21:31:17 From Wei Yao : 不，我们自己写的 21:31:56 From hezhiyong : mysql 的语法解析是在那一步用到了？ 21:32:01 From tianyi wang : select coalesce（）中coalesce是在fields里面吗 21:32:10 From Wei Yao : 我们的语法解析就是兼容 mysql， 21:32:12 From window930030@gmail.com : SQL injection 有做嗎？ 21:32:27 From Wei Yao : SQL injection？SQL 注入？ 21:32:40 From Wei Yao : 我们不叫 sql 注入 21:32:55 From window930030@gmail.com : 恩？ 21:33:04 From Wei Yao : 我们会把 sql 变成算子，之后会去优化算子结构，下面会讲， 21:33:15 From window930030@gmail.com : 好的，謝謝。 21:34:55 From jeffery : 刚刚的意思：Visitor是选择节点 21:34:58 From jeffery : ？ 21:35:05 From Wei Yao : 不是 21:35:11 From Abner Zheng : 一种设计模式 21:35:13 From xietengjin : 遍历节点用的吧 21:35:14 From Wei Yao : visitor 是设计模式中的那个 visitor 模式 21:35:17 From Wei Yao : 对 21:35:19 From jacobz : 遍历树用的 21:35:23 From Fangfang Qi : 是遍历语法树的 21:35:27 From jeffery : 额，好的 21:35:28 From Wei Yao : 遍历 ast 树 21:37:03 From jeffery : 清楚 21:40:01 From jacobz : 是搞优化的那一堆？ 21:43:45 From lk : 递归遍历？ 21:44:05 From Wei Yao : 层级有限。 21:48:06 From Kathy : 其实这个时候是不是类似传统的通过运算符进栈出栈形成表达式 21:48:24 From Wei Yao : 对，表达式系统基本上都是这样 21:51:21 From Kathy : ScalarFunction能解决aggregation的函数的语句吗 21:55:24 From Chen Shuang : 能 21:55:55 From Chen Shuang : aggregation function 也是 scalar function. 21:57:23 From Kathy : 只要不涉及其他表的相关列的function是否都最后成为scalarFunction 21:57:33 From Kathy : 的表达式 21:58:40 From Chen Shuang : 只要是 function , 都会变成 scalarFunction 表达式 21:59:40 From Chen Shuang : select t1.a + t2.b from t1,t2; 其中 t1.a + t2.b 会build 成一个 scalarFunction 表达式 21:59:40 From Kathy : 多谢答复 22:00:28 From Chen Shuang : 不客气哈 22:06:26 From tianyi wang : select coalesce（）也会是scalarfunction? 22:06:53 From hezhiyong : 可以演示一下debug一条语句跑的代码吗 22:10:07 From jiangchen : 是的，能不能最好演示下。。每次next返回的是一部分子结果还是一部分最终的结果？ 22:11:33 From Kathy : 执行引擎的新特性可以说说吗？简单讲一下，就是parallel physical operator的实现等等 22:11:57 From Wei Yao : 执行引擎下周讲 22:12:05 From 慢摇哥哥 : 老师，Coprocessor是在哪一步分发的 22:12:06 From jeffery : 辛苦了，有一个基本的逻辑了 22:12:37 From Kathy : 好的 谢谢 22:12:42 From 达 黄 : 之前看了tidb源码解析的文章 配合着这个视频 印象更清楚了 22:13:32 From jeffery : 感觉姚老师像一位老教授在督导 22:14:02 From Wei Yao : ：） 22:15:40 From jeffery : 为什么这部分会单独出来？ 22:15:40 From nange : Distsql是什么好像没讲。 22:15:54 From tianyi wang : select coalesce（）会是scalarfunction还是单独的一部分呢? 22:18:53 From 熊浪 : 问下是每一个session都会解析一次sql么？如果一个sql在同一个session中多次执行是否有ast的共享？ 22:21:02 From hezhiyong : prepare 是要开启参数才可以的吧 22:21:36 From 熊浪 : 好的，和mysql是一样的。谢谢\nPPT: https://reading-go.slack.com/files/U8A45L223/FKA335THT/_reading-go__tidb_source_cdoe_overview.pdf\n观看视频   ","title":"第 46 期 TiDB 源码阅读之概览"},{"location":"https://bytemode.github.io/reading/45-2019-05-30-goim-reading/","text":" 观看视频   ","title":"第 45 期 goim 架构设计与源码分析"},{"location":"https://bytemode.github.io/reading/44-2019-05-29-go-map-reading/","text":" 观看视频   ","title":"第 44 期 Go map 源码阅读分析"},{"location":"https://bytemode.github.io/reading/43-2019-05-23-gomonkey-framework-design-and-practives/","text":" 观看视频   ","title":"第 43 期 gomonkey 框架设计与应用实践"},{"location":"https://bytemode.github.io/reading/42-2019-05-16-go-failpoint-design/","text":" 观看视频   ","title":"第 42 期 An Introduction to Failpoint Design"},{"location":"https://bytemode.github.io/reading/41-2019-05-12-golint-golangci-lint/","text":" 观看视频   ","title":"第 41 期 golint 及 golangci-lint 的介绍和使用"},{"location":"https://bytemode.github.io/reading/40-2019-04-27-atomic-value-in-go/","text":" 观看视频   ","title":"第 40 期 atomic.Value 的使用和源码分析"},{"location":"https://bytemode.github.io/reading/39-2019-04-18-init-function-in-go/","text":" 观看视频   ","title":"第 39 期 init function 使用分析"},{"location":"https://bytemode.github.io/reading/38-2019-04-13-k8s-scheduler-reading/","text":" 观看视频   ","title":"第 38 期 kubernetes scheduler 源码阅读"},{"location":"https://bytemode.github.io/reading/37-2019-04-01-talk-from-serverless-in-apache-pulsar/","text":" 参考资料  预习材料 pulsar-effectively-once  观看视频   ","title":"第 37 期 从 serverless 的一个设计说起"},{"location":"https://bytemode.github.io/reading/36-2019-03-28-reading-k8s-context/","text":" 实践  WithValue WithCancel WithTimeout  WithDeadline 基本上没有用到。\n参考资料  How to correctly use context.Context in Go 1.7 How to correctly use package context 视频笔记：如何正确使用 Context - Jack Lindamood  观看视频   ","title":"第 36 期 k8s context 实践源码阅读"},{"location":"https://bytemode.github.io/reading/35-2019-03-21-reading-context/","text":" 预习材料 第 35 期 Go 夜读之《context 包源码阅读》预习资料 #191\n观看视频   ","title":"第 35 期 context 源码阅读"},{"location":"https://bytemode.github.io/reading/34-2019-03-16-plan9-guide/","text":" 2019.3.16 晚上 21 点 ~ 23点\n直播过程中的文字讨论 （如有涉及到隐私，请告知） 21:08:32\tFrom xiong hekuan : 几乎没有 21:08:47\tFrom amatist Kurisu : 大佬开下麦... 21:09:02\tFrom Laily Long : 能听到 21:09:02\tFrom xiong hekuan : 可以 21:09:03\tFrom 何翔宇 : 可以 21:09:06\tFrom xiye : 能听到 21:09:09\tFrom haoc7 : 听到了 21:09:12\tFrom 星星 : 挺清楚的 21:11:01\tFrom amatist Kurisu : ok 21:13:57\tFrom panda : 👍 21:15:40\tFrom albert’s iPhoneSE : 32位都差不多复杂 21:28:15\tFrom 红红火火 : 不太好理解 21:28:24\tFrom dongzerun : rax rbx ….. 一共六个，再多的才通过栈 21:32:09\tFrom 红红火火 : 每个方法都有一个zhanma 21:32:22\tFrom HLewis : 销毁就是sp等于bp吧 21:33:06\tFrom albert’s iPhoneSE : 怎么修改栈大小？ 21:33:10\tFrom 红红火火 : 每个方法都有一个栈指针吗 21:33:19\tFrom Flora Wong : C++里inline函数就没有栈吧 21:33:52\tFrom xiaolong ran : 失效后还给操作系统它怎么处理 ？ 21:34:35\tFrom 红红火火 : 回收再利用吧 21:37:42\tFrom 王耀峰 : 这是当时的值或者地址吧 21:37:49\tFrom amatist Kurisu : 那cpu切换任务的话, 保存的上下文是指寄存器中的值么 21:38:08\tFrom amatist Kurisu : ok 21:42:08\tFrom 王耀峰 : 问个问题啊。系统条用，还会涉及到了内核态或者用户态切换吧，汇编有体现吗 21:42:42\tFrom 王耀峰 : ok 21:42:45\tFrom xiaolong ran : .bss 和 .rodata这两个和.text和.data是怎么交互的 21:43:30\tFrom Laily Long : 就相当于系统调用的时候按要求把参数天刀对应寄存器，然后调用 syscall 进内核，内核就会自己拿参数然后执行对吧，返回的参数也写到固定寄存器？ 21:43:32\tFrom dongzerun : 这哪有交互的说法 21:43:46\tFrom z : syscall 不属于体系架构的指令，而是操作系统提供的？ 21:44:13\tFrom dongzerun : 其它平台有的是不叫 syscall 21:46:59\tFrom Laily Long : $ 表示数字？ 21:47:45\tFrom Laily Long : plan9 是另一个操作系统的项目，不过凉了 21:54:25\tFrom Flora Wong : zhuji 码 是哪两个字？ 21:54:30\tFrom daniel : 不同的assembler 21:55:08\tFrom atlas : 助记码 21:55:12\tFrom 影子的 iPhone : 助记码 21:58:46\tFrom 王耀峰 : 这种应该应该还有一种好处，所有栈信息都保存在协程的结构体里面，省去了好多上线文切换的开销了 22:01:58\tFrom Laily Long : 是不是判断了之后 jmp 到不同的地方 22:05:01\tFrom 卜邪 小 : SB代表什么？ 22:05:45\tFrom Flora Wong : SB是某个寄存器？ 22:06:09\tFrom daniel : SB: Static base pointer: global symbols. 22:06:13\tFrom Odyssey : 所有的外部引用都需通过伪寄存器: PC（virtual Program Counter）/SB（Static Base register） 22:06:25\tFrom Odyssey : 刚搜索的 ：） 22:09:17\tFrom HLewis : 尾递归讲的好，只是有人介绍过，自己没跟过，学习了 22:13:00\tFrom daniel : 能否分析一个函数调用时stack的结构？ 22:13:18\tFrom 卜邪 小 : 不会被抢占？ 22:14:23\tFrom 王耀峰 : 那也就是说gc 没办法正常回收了 22:14:54\tFrom 王耀峰 : 我记得Go 里面好像有一个兜底策略 22:15:37\tFrom pingzheng : 那写gorouting感觉好危险 22:15:46\tFrom liu : 纯运算的是抢占不了 22:15:51\tFrom 王耀峰 : 好好 22:15:53\tFrom 王耀峰 : 还好 22:17:43\tFrom 卜邪 小 : 在听 22:18:17\tFrom z : SB的作用是 22:19:03\tFrom 王耀峰 : 一个G的栈初始化只有2k 22:19:42\tFrom xiye : goroutine的初始分配的内存是2k吧 22:19:59\tFrom 红红火火 : 4k 22:20:19\tFrom 王耀峰 : 这个应该和操作系统，虚拟内存有关吧 22:20:44\tFrom 王耀峰 : 物理不可能，虚拟的也不会 22:23:22\tFrom HLewis : 等一下能讲讲，所有的goroutine都在同一个操作系统进程中吗？ 22:23:30\tFrom dingliu : 所以想到一个case，如果被调用的函数只有一个字符的变量还没超过2k，就不会触发morestack. 22:23:49\tFrom 红红火火 : 去看gmp 22:30:23\tFrom dingliu : ＋8是指8字节吗？ 22:33:45\tFrom z : textflag.h是什么 22:35:55\tFrom Laily Long : 怎么知道 slice 在汇编里是传了三个参数进去的 22:36:05\tFrom Laily Long : 去哪里查，比如我要知道 map 的 22:37:13\tFrom Laily Long : 哦哦。。懂了。。 22:40:02\tFrom 王耀峰 : 后面的值是什么意思 22:40:26\tFrom 王耀峰 : 哈哈，我擦 22:40:41\tFrom 王耀峰 : 这还得算内存对齐了，哈哈 22:41:03\tFrom Flora Wong : 黑科技 太牛 22:43:17\tFrom 榴莲 : 🐂 22:43:41\tFrom 红红火火 : 雨痕是不是很懂这些啊 22:46:01\tFrom Flora Wong : 汇编有点意思 感谢大佬分享 22:46:29\tFrom mai yang : 👍汇编还给老师了。 22:46:33\tFrom xiye : defer一般用来做资源解锁比较好 22:46:37\tFrom HLewis : 所有的goroutine都处在同一个操作系统进程中吗？ 22:46:42\tFrom mai yang : defer 确实很尴尬的。 22:47:25\tFrom 红红火火 : 线程队列里 22:47:51\tFrom haoc7 : 上次有人线上defer没走到，前面崩了，找了半天是defer没走到。 22:48:11\tFrom 王耀峰 : panic了 22:48:21\tFrom z : go语言问题是追的github上issue么？ 22:48:33\tFrom mai yang : pgraph? 22:48:38\tFrom Xargin : pprof 22:48:40\tFrom mai yang : pprof 22:49:18\tFrom mai yang : 太感谢老师今天的分享了 22:49:21\tFrom 卜邪 小 : 有 22:49:23\tFrom 卜邪 小 : https://github.com/golang/go/blob/master/src/runtime/asm_amd64.s#L253 22:49:32\tFrom mai yang : 在群里面 22:49:35\tFrom 卜邪 小 : 老师能帮忙翻译这段汇编吗？ 22:49:40\tFrom Feng Zhu : 谢谢大神分享 22:50:00\tFrom hawken : 还有一个小小的问问，chrome 插件第三个是什么插件啊😂 22:50:13\tFrom HLewis : 所有的goroutine都处在同一个操作系统进程中吗？ 22:50:22\tFrom haoc7 : 哈哈哈，我刚刚也搜了 22:50:23\tFrom 红红火火 : jstogo 22:50:27\tFrom Laily Long : 请问下 Plan9 的汇编优势在哪里，为啥 go 的开发者会抛弃其他的自己造这个轮子 22:50:28\tFrom Flora Wong : 哈哈 你的插件看起来都很棒 22:51:00\tFrom mai yang : 这些插件都可以总结一波。 22:51:22\tFrom Flora Wong : 回头分享一下插件名称哈 大佬 22:52:02\tFrom 星星 : 我看到油猴了 22:52:15\tFrom 王耀峰 : G应该是个宏封装吧 22:52:23\tFrom HLewis : go协程和操作系统进程啥关系？ 22:52:46\tFrom Flora Wong : 一个go程序执行的时候就是一个进程 肯定goroutine都在一个进程里啊 22:52:52\tFrom Flora Wong : 你是想问线程吧？ 22:52:55\tFrom 王耀峰 : 可以从网上看看经典的go的 GMP 22:52:57\tFrom Laily Long : 这个你需要去看 gmp 模型 22:53:10\tFrom HLewis : 好的我先搜一下 22:55:36\tFrom William的 iPhone : 比较迷惑的是协程都在一个进程里面，那他怎么用满多核服务器的 22:56:18\tFrom 王耀峰 : 中间层？ 22:56:30\tFrom HLewis : 对 22:56:48\tFrom HLewis : 系统级别只有进程 22:57:03\tFrom HLewis : 线程是提供的库比如pthreads 22:57:56\tFrom HLewis : 如果协程都在一个进程中，那么就意味着所有协程共享同一个虚拟内存空间， 22:58:37\tFrom HLewis : 那么操作系统提供的进程间ipc跟Go就没有毛关系了？ 22:59:55\tFrom daniel : 比较迷惑的是协程都在一个进程里面，那他怎么用满多核服务器的 22:59:59\tFrom daniel : 多线程呀 23:01:03\tFrom 王耀峰 : 不一定是一个进程，其实G的存在就减少了上下文切换，底层还是多喝都绑定到P上相当于多核了吧 23:01:06\tFrom William的 iPhone : 协程之间走进程间通信吗？ 23:01:54\tFrom William的 iPhone : 多个线程之间的goroutine 怎么通信？ 23:02:08\tFrom 王耀峰 : channel 23:03:02\tFrom William的 iPhone : 说错了是多个核上的多个进程上面的goroutine 之间的通信 23:03:34\tFrom daniel : 啥，一个Go程序跑起来是单进程的呀 23:03:48\tFrom 王耀峰 : Go其实弱化了这些进程线程概念，你遵循mpg这种用就行了 23:03:51\tFrom wangriyu : 不同进程得走系统ipc了吧 23:04:07\tFrom William的 iPhone : 单进程能用满多个核心么 23:04:12\tFrom William的 iPhone : 迷糊了 23:04:14\tFrom Xargin : debug.xxxstack() 23:04:41\tFrom wangriyu : 进程是资源分配的基本单元，线程才是执行单元 23:04:54\tFrom 王耀峰 : 对 23:05:07\tFrom wangriyu : 你多线程跑就能跑满cpu了 23:05:08\tFrom daniel : 一个进程可以搞出来n个线程，这n个线程会执行m个goroutine 23:05:24\tFrom 王耀峰 : 在linux 下层其实进程线程好像不太严格。弱进程 23:06:39\tFrom daniel : 同一个进程下的线程共享很多资源 23:06:48\tFrom William的 iPhone : 这m个在一个核心里面？我理解的一个进程只能用满一个核心吧 23:07:04\tFrom tanrongxian : 峰哥牛鼻 23:07:07\tFrom mai yang : 非常感谢 23:07:07\tFrom luckybear : 多谢大佬 23:07:07\tFrom pingzheng : 感谢大佬 23:07:08\tFrom HLewis : 学习了，谢谢分享 23:07:09\tFrom Laily Long : 辛苦大佬 23:07:14\tFrom Flora Wong : 感谢 @Xargin 23:07:16\tFrom hawken : 非常感谢 23:07:18\tFrom Odyssey : 谢谢分享 23:07:18\tFrom wangriyu : 感谢 23:07:18\tFrom doujiapeng : 感谢感谢 23:07:18\tFrom qclaogui : 辛苦大佬 23:07:21\tFrom 星星 : 感谢 23:07:22\tFrom tanrongxian : 感谢分享 23:07:24\tFrom 饶全成 : 感谢 23:07:24\tFrom Flora Wong : 辛苦大佬 23:07:25\tFrom Feng Zhu : 大佬 23:07:25\tFrom 卜邪 小 : 谢谢 23:07:32\tFrom daniel : 感谢，睡觉了 23:07:33\tFrom amatist Kurisu : 感谢分享 23:07:34\tFrom doujiapeng : 多谢 23:07:36\tFrom haoc7 : 谢谢大佬 23:07:38\tFrom qclaogui : good night 23:07:41\tFrom Odyssey : 谢谢大佬 23:07:46\tFrom 鹏飞 : 6 23:07:49\tFrom mai yang : 晚点分享出来给大家 23:07:50\tFrom HLewis : gnight  观看视频   ","title":"第 34 期 Go 夜读之 plan9 汇编入门，带你打通应用和底层 by Xargin"},{"location":"https://bytemode.github.io/reading/33-2019-03-07-defer-in-go/","text":" 2019.3.7 晚上\n观看视频   ","title":"第 33 期 Go 夜读之 Go defer 和逃逸分析"},{"location":"https://bytemode.github.io/reading/32-2019-03-02-etcd-raft/","text":" etcd raft 阅读\netcd 版本：3.3.10\n2019.3.2 晚上\n总结 etcd里的raft模块只实现了raft共识算法，而像消息的网络传输，数据存储都由上层应用来完成。\n下面是各个文件（夹）的功能简介：\n raftpb  用Protocol Buffer定义了一些需要序列化的数据结构，比如Entry和Message。\n log_unstable.go  unstable数据结构表示用于还没有被用户层持久化的数据，它维护了两部分内容snapshot和entries。\n storage.go  这个文件定义了一个Storage接口，应用层需要实现这个接口，以提供存储和查询日志的能力。\n log.go  维护本地日志信息。其中的committed和applied分别表示已提交和已经应用到状态机的日志索引。\n progress.go  Leader节点通过Progress这个数据结构来追踪一个follower的状态，并根据Progress里的信息来决定每次同步的日志项。\n raft.go  Raft协议的具体实现就在这个文件里。其中最重要的就是Step函数，它用来处理不同的消息。所以以后当我们想知道raft对某种消息的处理逻辑时，到这里找就对了。\n node.go  node的主要作用是应用层和共识模块（raft）的衔接。将应用层的消息传递给底层共识模块，并将底层共识模块共识后的结果反馈给应用层。\n参考资料  深入浅出 Raft - 基本概念 深入浅出 Raft - Membership Change 深入浅出 Raft - Leader 选举 深入浅出 Raft - Optimization Raft在etcd中的实现 etcd contrib Etcd超全解：原理阐释及部署设置的最佳实践  观看视频   ","title":"第 32 期 Go 夜读之 etcd raft 源码阅读"},{"location":"https://bytemode.github.io/reading/31-2019-02-23-flag/","text":" Go 标准包阅读\nGo 版本：go 1.11.5\n总结  *v.URL = *u flag 下有 package flag_test？？ init 中定义相同的 stringvar ； 当一个文件中出现多个 init 函数时，他们都会被加载，并且以 init 出现在文件中的前后顺序执行。 type Value interface { String() string Set(string) error } type Getter interface { Value Get() interface{} } type boolFlag interface { Value IsBoolFlag() bool } strconv.ParseBool 的返回值可以被利用\nv, err := strconv.ParseBool(s) *b = boolValue(v) return err  参考资料  Go 语言中值 receiver 和指针 receiver 的对比（收集的一些资料）  观看视频   ","title":"第 31 期 Go 夜读之 flag 包源码阅读"},{"location":"https://bytemode.github.io/reading/30-2019-02-16-go-mod-part-4/","text":" Go 标准包阅读\nGo 版本：go 1.11.5\nnet/http  `` 换行  本期没有视频回放。\n观看视频   ","title":"第 30 期 Go 夜读之 go mod 源码阅读 part 4"},{"location":"https://bytemode.github.io/reading/29-2019-01-23-opentracing-jaeger-in-go/","text":" Go opentracing jaeger 集成及源码分析 一、分布式追踪论文 论文地址：http://bigbully.github.io/Dapper-translation/\n为什么要用分布式追踪  当代的互联网的服务，通常都是用复杂的、大规模分布式集群来实现的。 互联网应用构建在不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、 可能使用不同的编程语言来实现、有可能布在了几千台服务器，横跨多个不同的数据中心。 因此，就需要一些可以帮助理解系统行为、用于分析性能问题的工具。\n 分布式系统调用过程 使用分布式追踪要留意哪些问题  低损耗\n 跟踪系统对在线服务的影响应该做到足够小。\n 应用透明\n 对于应用的程序员来说，是不需要知道有跟踪系统这回事的。\n  二、Opentracing简介 Opentracing的作用  OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。  可以很自由的在不同的分布式追 踪系统中切换\n 不负责具体实现\n  Opentracing主要组成  一个Trace \u0026gt; 一个trace代表了一个事务或者流程在（分布式）系统中的执行过程\n Span \u0026gt; 记录Trace在执行过程中的信息\n 无限极分类 \u0026gt; 服务与服务之间使用无限极分类的方式，通过HTTP头部或者请求地址传输到最低层，从而把整个调用链串起来。\n  Jaeger-client的实现 Jaeger-client源码 提取  为什么要提取 \u0026gt; 主要作用是为了找到父亲\n 从哪里提取 \u0026gt; 进程内，不同进程之间各自约定 \u0026gt; 粟子：github.com/opentracing-contrib/go-stdlib/nethttp/server.go P86\n 提取什么 \u0026gt; traceid:spanid:parentid:是否采集 \u0026gt; uber-trace-id=157b74261b51d917:157b74261b51d917:0:1 \u0026gt; github.com/jaegertracing/jaeger-client-go/propagation.go P124\n  注入  为什么要注入 \u0026gt; 主要为了让孩子能找到爸爸\n 注入到哪里 \u0026gt; 和提取相对 \u0026gt; github.com/jaegertracing/jaeger-client-go/propagation_test.go\n 注入了什么 \u0026gt; github.com/jaegertracing/jaeger-client-go/propagation.go P103\n  异步report  Span.finish \u0026gt; github.com/jaegertracing/jaeger-client-go/span.go P177\n 把Span放入队列 \u0026gt; github.com/jaegertracing/jaeger-client-go/reporter.go P219\n 从队列取出，生成thrift，放入spanBuffer \u0026gt; github.com/jaegertracing/jaeger-client-go/reporter.go P253\n Flush到远程 \u0026gt; github.com/jaegertracing/jaeger-client-go/transport_udp.go P113\n  低消耗  消耗在哪里 \u0026gt; Jaeger-client作用于应用层，提取、注入、生成span、序列化成Thrift、发送到远程等，一系列操作这些都会带来性能上的损耗。\n 如何处理 \u0026gt; 选择合适采集策略：\n Constant Probabilistic Rate Limiting Remote   应用透明  如何做到让业务开发人员无感知  Golang： 约定第一个参数为ctx，把parentSpan放入ctx github.com/opentracing/opentracing-go/gocontext.go PHP： 使用全局变量   三、Jaeger服务端源码阅读 服务端组件职责  各组件按照微服务架构风格设计，职责单一\n  Jaeger-agent负责上报数据的整理\n Jaeger-collector负责数据保存\n Jaeger-query负责数据查询\n Jaeger-agent和Jaeger-collector使用基于TCP协议实现的RPC进行通讯\n  Jaeger-agent 源码阅读  监听3个UDP端口\n\u0026gt; github.com/jaegertracing/jaeger/cmd/agent/app/flags.go P35 \u0026gt; github.com/jaegertracing/jaeger/cmd/agent/app/servers/thriftudp/transport.go P73\n 接收Jaeger-client的数据，放入队列dataChan \u0026gt; github.com/jaegertracing/jaeger/cmd/agent/app/servers/tbuffered_server.go #80  从队列dataChan获取数据，进行校验 \u0026gt; github.com/jaegertracing/jaeger/cmd/agent/app/processors/thrift_processor.go P108\n 提交数据 \u0026gt; github.com/jaegertracing/jaeger/thrift-gen/jaeger/tchan-jaeger.go #39\n  Jaeger-collector 源码阅读  协程池 \u0026gt; github.com/jaegertracing/jaeger/pkg/queue/bounded_queue.go\n 接收jaeger-agent数据 \u0026gt; github.com/jaegertracing/jaeger/cmd/collector/app/span_handler.go P69\n 放入队列 \u0026gt; github.com/jaegertracing/jaeger/cmd/collector/app/span_processor.go P112\n 从队列拿出来，写入数据库\n\u0026gt; github.com/jaegertracing/jaeger/cmd/collector/app/span_processor.go p54\n\u0026gt; github.com/jaegertracing/jaeger/plugin/storage/cassandra/spanstore/writer.go P136\n  四、Jaeger使用经验 监听指标  Jaeger-client 监听 reporter_spans\n Jaeger-agent 监听 thrift.udp.server.packets.dropped\n Jaeger-collector 监听 spans.dropped\n  http://localhost:16686/metrics\n测试环境debug  测试环境记录执行mysql语句，redis命令，RPC参数、结果 可以很方便定位问题\n 性能调优  观察Jaeger-ui，对线上接口，mysql执行时间进行监控调优\n 观看视频   ","title":"第 29 期 Go opentracing jaeger 集成及源码分析"},{"location":"https://bytemode.github.io/reading/28-2019-01-17-go-mod-part-3/","text":" Go 标准包阅读\nGo 版本：go 1.11.5\n学到的内容  json:\u0026quot;,omitempty\u0026quot;   方法一：\nif path[len(path)-1] == \u0026#39;/\u0026#39; { return fmt.Errorf(\u0026#34;trailing slash\u0026#34;) } 方法二：\nstrings.HasSuffix(path, \u0026#34;/\u0026#34;) benchmark\n   方法一：\nstrings.TrimSuffix(pathMajor, \u0026#34;-unstable\u0026#34;) 方法二：\ni := len(path) if strings.HasSuffix(path, \u0026#34;-unstable\u0026#34;) { i -= len(\u0026#34;-unstable\u0026#34;) } benchmark\n if i := strings.Index(arg, \u0026#34;@\u0026#34;); i \u0026gt;= 0 { path, vers = arg[:i], arg[i+1:] }  也可以用 split(arg, \u0026quot;@\u0026quot;) 来实现。\n观看视频   ","title":"第 28 期 Go 夜读之 go mod 源码阅读 part 3"},{"location":"https://bytemode.github.io/reading/27-2019-01-10-go-mod-part-2/","text":" Go 标准包阅读\nGo 版本：go 1.11.5\n学到的内容 1. mf := new(modfile.File) 2. lineno++ 感觉是无用的代码？ dep.go 中 ParseGopkgLock 方法第48行有用到 lineno ，会打印出 strconv.Unquote 解析错误的文件名和行号\nif len(val) \u0026gt;= 2 \u0026amp;\u0026amp; val[0] == \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; val[len(val)-1] == \u0026#39;\u0026#34;\u0026#39; { q, err := strconv.Unquote(val) // Go unquoting, but close enough for now  if err != nil { return nil, fmt.Errorf(\u0026#34;%s:%d: invalid quoted string: %v\u0026#34;, file, lineno, err) } val = q } 其他几个文件可能是为了保持一致，或者为了将来输出错误信息特意保留的。其他文件里面的 lineno 没有地方引用，大家在阅读代码时会产生困惑，建议用空白符_来替代。\n3. 判断外部网络是否可用 if runtime.GOOS == \u0026#34;nacl\u0026#34; || runtime.GOOS == \u0026#34;js\u0026#34; { t.Skipf(\u0026#34;skipping test: no external network on %s\u0026#34;, runtime.GOOS) } runtime.GOOS返回程序所在的操作系统名\nsrc\\runtime\\extern.go // GOOS is the running program\u0026#39;s operating system target: // one of darwin, freebsd, linux, and so on. const GOOS string = sys.GOOS Native Client(NACL) 是一种允许在浏览器中运行 native compiled code 的技术，允许开发者运用自己熟悉的语言来开发web应用，而不只是JavaScript，目前 NativeClient 技术只能应用于google自己的chrome中。 js 是指 Webassembly 技术，是在新版本1.11中才支持的,最新版本的浏览器可以支持。 NACL 和 JS 都不是真正的操作系统，不提供外部网络功能。\n4.旧版模块管理配置转换为modfile 读取当前目录下旧版模块管理配置文件，从 Converters 中根据配置文件名去获取转换方法。\nsrc\\cmd\\go\\internal\\modconv\\convert.go // ConvertLegacyConfig converts legacy config to modfile. // The file argument is slash-delimited. func ConvertLegacyConfig(f *modfile.File, file string, data []byte) error { i := strings.LastIndex(file, \u0026#34;/\u0026#34;) j := -2 if i \u0026gt;= 0 { j = strings.LastIndex(file[:i], \u0026#34;/\u0026#34;) } convert := Converters[file[i+1:]] if convert == nil \u0026amp;\u0026amp; j != -2 { convert = Converters[file[j+1:]] } if convert == nil { return fmt.Errorf(\u0026#34;unknown legacy config file %s\u0026#34;, file) } mf, err := convert(file, data) if err != nil { return fmt.Errorf(\u0026#34;parsing %s: %v\u0026#34;, file, err) } ... } src\\cmd\\go\\internal\\modconv\\modconv.go var Converters = map[string]func(string, []byte) (*modfile.File, error){ \u0026#34;GLOCKFILE\u0026#34;: ParseGLOCKFILE, \u0026#34;Godeps/Godeps.json\u0026#34;: ParseGodepsJSON, \u0026#34;Gopkg.lock\u0026#34;: ParseGopkgLock, \u0026#34;dependencies.tsv\u0026#34;: ParseDependenciesTSV, \u0026#34;glide.lock\u0026#34;: ParseGlideLock, \u0026#34;vendor.conf\u0026#34;: ParseVendorConf, \u0026#34;vendor.yml\u0026#34;: ParseVendorYML, \u0026#34;vendor/manifest\u0026#34;: ParseVendorManifest, \u0026#34;vendor/vendor.json\u0026#34;: ParseVendorJSON, } 目前go语言是使用map对象来存储旧配置文件和方法的映射关系这种设计思路的。@mai提出还有一种设计思路是抽象一个接口，各种配置管理来实现该接口。\n观看视频   参考 1.Google Native Client\n2.NaCl and networking\n3.Go 1.11 正式发布 支持模块和WebAssembly\n4.WebAssembly 现状与实战\n","title":"第 27 期 Go 夜读之 go mod 源码阅读 part 2"},{"location":"https://bytemode.github.io/reading/26-2019-01-03-blog-with-github-netlify/","text":" Github Netlify 观看视频   ","title":"第 26 期 Go 夜读之手把手教你基于 Github+Netlify 构建自动化持续集成的技术团队博客"},{"location":"https://bytemode.github.io/reading/25-2018-12-27-tsdb/","text":" TSDB 引擎介绍，对比及存储细节  OpenTSDB InfluxDB Druid  观看视频   ","title":"第 25 期 TSDB 引擎介绍，对比及存储细节"},{"location":"https://bytemode.github.io/articles/how_to_test/readme/","text":" HOW TO TESTING 原文/源码参考：\n how_to_test  作者：xpzouying@gmail.com\n测试的作用：\n 验证代码是否符合预期 资源竞争检查：race detect 调优：profiling：memory/cpu  原始代码 代码功能：访客记次数。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var counter = map[string]int{} func handleHello(w http.ResponseWriter, r *http.Request) { name := r.FormValue(\u0026#34;name\u0026#34;) counter[name]++ w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/html; charset=utf-8\u0026#34;) w.Write([]byte(\u0026#34;\u0026lt;h1 style=\u0026#39;color: \u0026#34; + r.FormValue(\u0026#34;color\u0026#34;) + \u0026#34;\u0026#39;\u0026gt;Welcome!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Name: \u0026#34; + name + \u0026#34;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Count: \u0026#34; + fmt.Sprint(counter[name]) + \u0026#34;\u0026lt;/p\u0026gt;\u0026#34;)) } func main() { http.HandleFunc(\u0026#34;/hello\u0026#34;, handleHello) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } 运行：\ngo run main.go 浏览器访问：\n本地日志记录：\n测试规范  运行测试：\n 测试：go test 压力测试：go test -bench 测试覆盖：go test -cover  测试规范：\n 测试函数示例\n// go test or go test -v func TestXxx(*testing.T) // go test -bench func BenchmarkXxx(*testing.B)  Xxx不能以小写字母开头。\n 测试文件规范：文件名以_test.go结尾。\n 在测试函数里面使用：Error，Fail或者相关的函数标示相关错误。\n  例子：\n 单元测试：\nfunc TestTimeConsuming(t *testing.T) { if testing.Short() { t.Skip(\u0026#34;skipping test in short mode.\u0026#34;) } ... } 压力测试：\nfunc BenchmarkHello(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { fmt.Sprintf(\u0026#34;hello\u0026#34;) } } Examples：\nfunc ExampleHello() { fmt.Println(\u0026#34;hello\u0026#34;) // Output: hello } func ExampleSalutations() { fmt.Println(\u0026#34;hello, and\u0026#34;) fmt.Println(\u0026#34;goodbye\u0026#34;) // Output:  // hello, and  // goodbye }   测试用例 运行测试\n使用go test运行测试。\n➜ how_to_test git:(how_to_test) ✗ go test ? _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test [no test files]  也可以使用Golang的TDD小工具：goconvey\n安装：go get github.com/smartystreets/goconvey\n介绍: GoConvey is awesome Go testing\n运行：goconvey\n效果截图：\n 测试用例\n创建main_test.go，\ntouch main_test.go 编写第一个测试用例：\nfunc TestHelloHandleFunc(t *testing.T) { rw := httptest.NewRecorder() name := \u0026#34;zouying\u0026#34; req := httptest.NewRequest(http.MethodPost, \u0026#34;/hello?name=\u0026#34;+name, nil) handleHello(rw, req) if rw.Code != http.StatusOK { t.Errorf(\u0026#34;status code not ok, status code is %v\u0026#34;, rw.Code) } if len(counter) != 1 { t.Errorf(\u0026#34;counter len not correct\u0026#34;) } if counter[name] != 1 { t.Errorf(\u0026#34;counter value is error: visitor=%s count=%v\u0026#34;, name, counter[name]) } } 运行测试：go test -v：\n ➜ how_to_test git:(how_to_test) ✗ go test -v === RUN TestHelloHandleFunc INFO[0000] visited count=1 module=main name=zouying \u0026mdash; PASS: TestHelloHandleFunc (0.00s) PASS ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.015s\n 运行测试覆盖：go test -cover\n ➜ how_to_test git:(how_to_test) ✗ go test -cover INFO[0000] visited count=1 module=main name=zouying PASS coverage: 62.5% of statements ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.021s\n 查看覆盖的代码：\n#!/bin/bash go test -coverprofile=coverage.out go tool cover -html=coverage.out  ➜ how_to_test git:(how_to_test) ✗ go test -coverprofile=/tmp/coverage.out INFO[0000] visited count=1 module=main name=zouying PASS coverage: 62.5% of statements ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.015s ➜ how_to_test git:(how_to_test) ✗ go tool cover -html=/tmp/coverage.out\n 效果图为：\n绿色的表示测试代码覆盖住的，红色的表示没有覆盖。\n第一个测试用例是直接测试http处理函数，我们使用了httptest.NewRecorder()创建ResponseRecorder对象，其中实现了 ResponseWriter interface。该对象在内存中记录了http response的状态。\n还有一种测试方法是运行一个HTTP Server，使用HTTP Client请求该Server对应的接口。\nhttptest package中提供了NewServer方法，监听HandlerFunc处理函数，启动Server，启动Server的地址通过URL成员获得，例如：http://127.0.0.1:52412。需要注意的是，使用完毕后记得调用关闭：Close()。\n代码如下，\nfunc TestHTTPServer(t *testing.T) { ts := httptest.NewServer(http.HandlerFunc(handleHello)) defer ts.Close() logrus.Infof(\u0026#34;server url: %s\u0026#34;, ts.URL) testURL := ts.URL + \u0026#34;/hello?name=zouying\u0026#34; resp, err := http.Get(testURL) if err != nil { t.Error(err) return } if g, w := resp.StatusCode, http.StatusOK; g != w { t.Errorf(\u0026#34;status code = %q; want %q\u0026#34;, g, w) return } } 运行测试，\n➜ how_to_test git:(master) ✗ go test -v -run=TestHTTPServer === RUN TestHTTPServer INFO[0000] server url: http://127.0.0.1:52506 INFO[0000] visited count=1 module=main name=zouying --- PASS: TestHTTPServer (0.00s) PASS ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.015s 测试技巧：表格测试 (Table Based Tests)\n代码如下，\nfunc TestHelloHandlerMultiple(t *testing.T) { tests := []struct { name string wCnt int }{ {name: \u0026#34;zouying\u0026#34;, wCnt: 1}, {name: \u0026#34;zouying\u0026#34;, wCnt: 2}, {name: \u0026#34;user2\u0026#34;, wCnt: 1}, {name: \u0026#34;user3\u0026#34;, wCnt: 1}, } for _, tc := range tests { rw := httptest.NewRecorder() req := httptest.NewRequest(http.MethodPost, \u0026#34;/hello?name=\u0026#34;+tc.name, nil) handleHello(rw, req) if rw.Code != http.StatusOK { t.Errorf(\u0026#34;status code not ok, status code is %v\u0026#34;, rw.Code) } if counter[tc.name] != tc.wCnt { t.Errorf(\u0026#34;counter value is error: visitor=%s count=%v\u0026#34;, tc.name, counter[tc.name]) } } } 运行测试，\n➜ how_to_test git:(how_to_test) ✗ go test -run=TestHelloHandlerMultiple INFO[0000] visited count=1 module=main name=zouying INFO[0000] visited count=2 module=main name=zouying INFO[0000] visited count=1 module=main name=user2 INFO[0000] visited count=1 module=main name=user3 PASS ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.016s 测试工具：testify\n使用工具介绍各种 if {}判断，产生大量的冗余代码。\n代码，\nfunc TestHelloHandlerMultipleWithAssert(t *testing.T) { tests := []struct { name string wCnt int }{ {name: \u0026#34;zouying\u0026#34;, wCnt: 1}, {name: \u0026#34;zouying\u0026#34;, wCnt: 2}, {name: \u0026#34;user2\u0026#34;, wCnt: 1}, {name: \u0026#34;user3\u0026#34;, wCnt: 1}, } for _, tc := range tests { rw := httptest.NewRecorder() req := httptest.NewRequest(http.MethodPost, \u0026#34;/hello?name=\u0026#34;+tc.name, nil) handleHello(rw, req) assert.Equal(t, http.StatusOK, rw.Code) assert.Equal(t, tc.wCnt, counter[tc.name]) } } Sub Test\nfunc TestHelloHandlerInSubtest(t *testing.T) { tests := []struct { name string wCnt int }{ {name: \u0026#34;zouying\u0026#34;, wCnt: 1}, {name: \u0026#34;user2\u0026#34;, wCnt: 1}, {name: \u0026#34;user3\u0026#34;, wCnt: 1}, } for _, tc := range tests { t.Run(\u0026#34;test-\u0026#34;+tc.name, func(t *testing.T) { rw := httptest.NewRecorder() req := httptest.NewRequest(http.MethodPost, \u0026#34;/hello?name=\u0026#34;+tc.name, nil) handleHello(rw, req) assert.Equal(t, http.StatusOK, rw.Code) assert.Equal(t, tc.wCnt, counter[tc.name]) }) } } 运行测试，\n➜ how_to_test git:(how_to_test) ✗ go test -v . -run=TestHelloHandlerInSubtest === RUN TestHelloHandlerInSubtest === RUN TestHelloHandlerInSubtest/test-zouying time=\u0026#34;2018-12-23T23:07:19+08:00\u0026#34; level=info msg=visited count=1 module=main name=zouying === RUN TestHelloHandlerInSubtest/test-user2 time=\u0026#34;2018-12-23T23:07:19+08:00\u0026#34; level=info msg=visited count=1 module=main name=user2 === RUN TestHelloHandlerInSubtest/test-user3 time=\u0026#34;2018-12-23T23:07:19+08:00\u0026#34; level=info msg=visited count=1 module=main name=user3 --- PASS: TestHelloHandlerInSubtest (0.00s) --- PASS: TestHelloHandlerInSubtest/test-zouying (0.00s) --- PASS: TestHelloHandlerInSubtest/test-user2 (0.00s) --- PASS: TestHelloHandlerInSubtest/test-user3 (0.00s) PASS ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.016s Data Race Detect 多个goroutine同时访问共享数据时，如果数据不是线程安全的，那么有可能会产生data race。\nHOW TO\ngo test -race 测试代码\nfunc TestHelloHandlerDetectDataRace(t *testing.T) { tests := []struct { name string wCnt int }{ {name: \u0026#34;zouying\u0026#34;, wCnt: 1}, {name: \u0026#34;zouying\u0026#34;, wCnt: 2}, {name: \u0026#34;user2\u0026#34;, wCnt: 1}, {name: \u0026#34;user3\u0026#34;, wCnt: 1}, } for _, tc := range tests { rw := httptest.NewRecorder() req := httptest.NewRequest(http.MethodPost, \u0026#34;/hello?name=\u0026#34;+tc.name, nil) handleHello(rw, req) assert.Equal(t, http.StatusOK, rw.Code) assert.Equal(t, tc.wCnt, counter[tc.name]) } } 运行测试\n➜ how_to_test git:(how_to_test) ✗ go test -race -v . -run=TestHelloHandlerDetectDataRace === RUN TestHelloHandlerDetectDataRace time=\u0026#34;2018-12-23T22:58:22+08:00\u0026#34; level=info msg=visited count=1 module=main name=zouying time=\u0026#34;2018-12-23T22:58:22+08:00\u0026#34; level=info msg=visited count=2 module=main name=zouying time=\u0026#34;2018-12-23T22:58:22+08:00\u0026#34; level=info msg=visited count=1 module=main name=user2 time=\u0026#34;2018-12-23T22:58:22+08:00\u0026#34; level=info msg=visited count=1 module=main name=user3 --- PASS: TestHelloHandlerDetectDataRace (0.00s) PASS ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 1.029s 测试通过，是否证明了我们的代码是没有问题的呢？\n其实并非如此，只是没有检测出来。为什么没有检测出来？\n是因为没有多个goroutine同时运行，访问共同的数据。\n修改代码\nfunc TestHelloHandlerDetectDataRace(t *testing.T) { tests := []struct { name string wCnt int }{ {name: \u0026#34;zouying\u0026#34;, wCnt: 1}, {name: \u0026#34;user2\u0026#34;, wCnt: 1}, {name: \u0026#34;user3\u0026#34;, wCnt: 1}, } var wg sync.WaitGroup wg.Add(len(tests)) for _, tc := range tests { name := tc.name want := tc.wCnt go func() { defer wg.Done() rw := httptest.NewRecorder() req := httptest.NewRequest(http.MethodPost, \u0026#34;/hello?name=\u0026#34;+name, nil) handleHello(rw, req) assert.Equal(t, http.StatusOK, rw.Code) assert.Equal(t, want, counter[name]) }() } wg.Wait() } 运行测试\n➜ how_to_test git:(how_to_test) ✗ go test -race . -run=TestHelloHandlerDetectDataRace ================== WARNING: DATA RACE Write at 0x00c0000a8f90 by goroutine 8: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:190 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0x11c _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Previous read at 0x00c0000a8f90 by goroutine 7: runtime.mapaccess1_faststr() /usr/local/go/src/runtime/map_faststr.go:12 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0xbc _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Goroutine 8 (running) created at: _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:139 +0x154 testing.tRunner() /usr/local/go/src/testing/testing.go:827 +0x162 Goroutine 7 (running) created at: _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:139 +0x154 testing.tRunner() /usr/local/go/src/testing/testing.go:827 +0x162 ================== ================== WARNING: DATA RACE Read at 0x00c0000a8f90 by goroutine 9: runtime.mapaccess1_faststr() /usr/local/go/src/runtime/map_faststr.go:12 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0xbc _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Previous write at 0x00c0000a8f90 by goroutine 8: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:190 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0x11c _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Goroutine 9 (running) created at: _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:139 +0x154 testing.tRunner() /usr/local/go/src/testing/testing.go:827 +0x162 Goroutine 8 (running) created at: _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:139 +0x154 testing.tRunner() /usr/local/go/src/testing/testing.go:827 +0x162 ================== ================== WARNING: DATA RACE Write at 0x00c0000a8f90 by goroutine 7: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:190 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0x11c _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Previous write at 0x00c0000a8f90 by goroutine 8: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:190 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0x11c _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Goroutine 7 (running) created at: _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:139 +0x154 testing.tRunner() /usr/local/go/src/testing/testing.go:827 +0x162 Goroutine 8 (running) created at: _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:139 +0x154 testing.tRunner() /usr/local/go/src/testing/testing.go:827 +0x162 ================== time=\u0026#34;2018-12-23T23:13:06+08:00\u0026#34; level=info msg=visited count=1 module=main name=user2 time=\u0026#34;2018-12-23T23:13:06+08:00\u0026#34; level=info msg=visited count=1 module=main name=user3 time=\u0026#34;2018-12-23T23:13:06+08:00\u0026#34; level=info msg=visited count=1 module=main name=zouying --- FAIL: TestHelloHandlerDetectDataRace (0.00s) testing.go:771: race detected during execution of test FAIL FAIL _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 0.030s 分析报错\n================== WARNING: DATA RACE Write at 0x00c0000a8f90 by goroutine 8: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:190 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0x11c _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211 Previous read at 0x00c0000a8f90 by goroutine 7: runtime.mapaccess1_faststr() /usr/local/go/src/runtime/map_faststr.go:12 +0x0 _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.handleHello() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main.go:14 +0xbc _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test.TestHelloHandlerDetectDataRace.func1() /Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test/main_test.go:144 +0x211  goroutine 8, goroutine 7, \u0026hellip; DATA RACE how_to_test/main.go:14：counter[name]++ runtime/map_faststr.go:190  原因是因为在多个goroutine中，对map同时进行了++操作，而在go中，map又不是线程安全的（线程安全的map参考sync包中的map），需要进行保护。\n修复race\n如果咱们的代码中有data race，那么一般使用下面方式可以避免，\n 使用channel。\n Share Memory By Communicating\n Go by Example: Channels\n  messages := make(chan string, 2) messages \u0026lt;- \u0026#34;buffered\u0026#34; messages \u0026lt;- \u0026#34;channel\u0026#34;  使用mutex。\n Package sync sync.Mutex - Tour of Go Go by Example: Mutexes  使用atomic。\n Go by Example: Atomic Counters   import \u0026#34;sync/atomic\u0026#34; var ops uint64 for i := 0; i \u0026lt; 50; i++ { go func() { for { atomic.AddUint64(\u0026amp;ops, 1) } }() } opsFinal := atomic.LoadUint64(\u0026amp;ops)  sync/atomic package   引入mutex解决问题\n 增加var mu sync.Mutex对counter map进行保护。 在对counter访问前进行Lock操作，访问结束后，进行Unlock操作。  修改代码为，\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;github.com/sirupsen/logrus\u0026#34; ) var counter = map[string]int{} var mu sync.Mutex // mutex for counter  func handleHello(w http.ResponseWriter, r *http.Request) { name := r.FormValue(\u0026#34;name\u0026#34;) mu.Lock() counter[name]++ cnt := counter[name] mu.Unlock() w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/html; charset=utf-8\u0026#34;) w.Write([]byte(\u0026#34;\u0026lt;h1 style=\u0026#39;color: \u0026#34; + r.FormValue(\u0026#34;color\u0026#34;) + \u0026#34;\u0026#39;\u0026gt;Welcome!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Name: \u0026#34; + name + \u0026#34;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Count: \u0026#34; + fmt.Sprint(cnt) + \u0026#34;\u0026lt;/p\u0026gt;\u0026#34;)) logrus.WithFields(logrus.Fields{ \u0026#34;module\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;name\u0026#34;: name, \u0026#34;count\u0026#34;: cnt, }).Infof(\u0026#34;visited\u0026#34;) } func main() { logrus.SetFormatter(\u0026amp;logrus.JSONFormatter{}) http.HandleFunc(\u0026#34;/hello\u0026#34;, handleHello) logrus.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } 测试代码，\n➜ how_to_test git:(how_to_test) ✗ go test -v -race . -run=TestHelloHandlerDetectDataRace === RUN TestHelloHandlerDetectDataRace time=\u0026#34;2018-12-24T10:11:23+08:00\u0026#34; level=info msg=visited count=1 module=main name=user3 time=\u0026#34;2018-12-24T10:11:23+08:00\u0026#34; level=info msg=visited count=1 module=main name=zouying time=\u0026#34;2018-12-24T10:11:23+08:00\u0026#34; level=info msg=visited count=1 module=main name=user2 --- PASS: TestHelloHandlerDetectDataRace (0.00s) PASS ok _/Users/zouying/src/Github.com/ZOUYING/learning_golang/how_to_test 1.025s 具体参考：\n https://golang.org/pkg/testing/  ","title":"how to testing"},{"location":"https://bytemode.github.io/reading/24-2018-12-23-go-mod-part-1/","text":" Go 标准包阅读\nGo 版本：go 1.11.5\n观看视频   阅读重点  os.Stat filepath.SplitList os.Getwd() switch sync.Once os.IsNotExist(errMod) MustQuote AutoQuote modcmd.runGraph\nformat := func(m module.Version) string { if m.Version == \u0026#34;\u0026#34; { return m.Path } return m.Path + \u0026#34;@\u0026#34; + m.Version } sort.Slice\n  什么是 go mod module 是相关 Go 依赖包的集合。module 是源代码交换和版本控制的单元。go 工具链会直接支持使用 go module，其功能包含记录和解析对其他第三方包的依赖项。模块将会替换旧的基于 $GOPATH 的模式\n目前 Go1.11 是初步支持，后续建议持续观望一下。详见 godoc\n开关 由于当前还在试验阶段，需要设置环境变量 GO111MODULE=on，才能够使用 go mod。支持一下选项：\n off：禁用 go module，按原有 $GOPATH、vendor 的寻址逻辑 on：启用 go module auto：若当前不在 $GOPATH 下，且当前目录的根目录下含有 go.mod 文件。则启用 go module  go mod 一下 $ go mod Go mod provides access to operations on modules. Note that support for modules is built into all the go commands, not just 'go mod'. For example, day-to-day adding, removing, upgrading, and downgrading of dependencies should be done using 'go get'. See 'go help modules' for an overview of module functionality. Usage: go mod \u0026lt;command\u0026gt; [arguments] The commands are: download download modules to local cache edit edit go.mod from tools or scripts graph print module requirement graph init initialize new module in current directory tidy add missing and remove unused modules vendor make vendored copy of dependencies verify verify dependencies have expected content why explain why packages or modules are needed Use \u0026quot;go help mod \u0026lt;command\u0026gt;\u0026quot; for more information about a command.   download：将 modules 下载到本地缓存 edit：对 go.mod 进行编辑。具体可参见 go help mod edit init：初始化 go module tidy：检索代码，新增缺少的依赖，删除不需要的依赖 vendor：拷贝依赖，生成 vendor 目录 verify：验证依赖是否正确 why：解释为什么需要依赖和 modules  怎么找源码 在这里我们用最粗暴也是最简洁的办法，直接搜一下。在这里，我们找到了如下苗头：\n cmd/go/alldocs.go：go cmd 的文档。是通过 mkalldocs.sh 在其他文件中收集注解生成的 godoc cmd/go/internal/modcmd/mod.go：今天的男主角，go module 的代码就存储在 modcmd 目录下。而其实我们搜索到的 mod.go 就是 go mod 这个命令的启动文件  看一看源码 modcmd ├── download.go ├── edit.go ├── graph.go ├── init.go ├── mod.go ├── tidy.go ├── vendor.go ├── verify.go └── why.go  通过 modcmd 的文件结构，可以惊喜地发现与 go mod \u0026lt;command\u0026gt; 的指令集其实是一致的。那么阅读的方向就很清晰了，我们可以按逻辑顺序看下去\ninit.go package modcmd import ( \u0026quot;cmd/go/internal/base\u0026quot; \u0026quot;cmd/go/internal/modload\u0026quot; \u0026quot;os\u0026quot; ) var cmdInit = \u0026amp;base.Command{ UsageLine: \u0026quot;go mod init [module]\u0026quot;, Short: \u0026quot;initialize new module in current directory\u0026quot;, Long: `Init initializes and writes a new go.mod to the current directory...`, Run: runInit, } func runInit(cmd *base.Command, args []string) { modload.CmdModInit = true if len(args) \u0026gt; 1 { base.Fatalf(\u0026quot;go mod init: too many arguments\u0026quot;) } if len(args) == 1 { modload.CmdModModule = args[0] } if _, err := os.Stat(\u0026quot;go.mod\u0026quot;); err == nil { base.Fatalf(\u0026quot;go mod init: go.mod already exists\u0026quot;) } modload.InitMod() // does all the hard work }  cmdInit cmdInit 实际为定义 cmd 命令的基础结构体，其包含成员变量如下：\n UsageLine：用法 Short：简短描述 Long：详细描述 Run：运行命令  其对应的触发场景主要是 help 和执行命令时，如下：\n➜ ~ go help mod init usage: go mod init [module] Init initializes and writes a new go.mod to the current directory, in effect creating a new module rooted at the current directory. The file go.mod must not already exist. If possible, init will guess the module path from import comments (see 'go help importpath') or from version control configuration. To override this guess, supply the module path as an argument.  runInit  声明正在执行 go mod init 命令集 判断参数是否不合法 参数合法下，该入参赋值给 go mod init 的 module 参数（将 args[0] 赋予 CmdModModule） 判断是否存在 go.mod 文件（也就是判断是否已经初始化过） 在 modload.InitMod() 中正式进行初始化的所有工作项  modload.InitMod() 源码中用 “does all the hard work” 来评价这个方法，它是 go mod init 的核心处理逻辑。接下来一起来看看 完整代码，我们将分为两个部分去阅读，如下：\n一、MustInit\nfunc MustInit() { if Init(); ModRoot == \u0026quot;\u0026quot; { die() } if c := cache.Default(); c == nil { base.Fatalf(\u0026quot;go: cannot use modules with build cache disabled\u0026quot;) } }  在该方法中，我们先进行必要的初始化，再读取构建缓存（不是本文重点），接下来详细阅读一下 Init 方法，如下：\nfunc Init() { ... env := os.Getenv(\u0026quot;GO111MODULE\u0026quot;) switch env { default: base.Fatalf(\u0026quot;go: unknown environment setting GO111MODULE=%s\u0026quot;, env) case \u0026quot;\u0026quot;, \u0026quot;auto\u0026quot;: // leave MustUseModules alone case \u0026quot;on\u0026quot;: MustUseModules = true case \u0026quot;off\u0026quot;: if !MustUseModules { return } } if os.Getenv(\u0026quot;GIT_TERMINAL_PROMPT\u0026quot;) == \u0026quot;\u0026quot; { os.Setenv(\u0026quot;GIT_TERMINAL_PROMPT\u0026quot;, \u0026quot;0\u0026quot;) } if os.Getenv(\u0026quot;GIT_SSH\u0026quot;) == \u0026quot;\u0026quot; \u0026amp;\u0026amp; os.Getenv(\u0026quot;GIT_SSH_COMMAND\u0026quot;) == \u0026quot;\u0026quot; { os.Setenv(\u0026quot;GIT_SSH_COMMAND\u0026quot;, \u0026quot;ssh -o ControlMaster=no\u0026quot;) } var err error cwd, err = os.Getwd() if err != nil { base.Fatalf(\u0026quot;go: %v\u0026quot;, err) } inGOPATH = false for _, gopath := range filepath.SplitList(cfg.BuildContext.GOPATH) { if gopath == \u0026quot;\u0026quot; { continue } if search.InDir(cwd, filepath.Join(gopath, \u0026quot;src\u0026quot;)) != \u0026quot;\u0026quot; { inGOPATH = true break } } if inGOPATH \u0026amp;\u0026amp; !MustUseModules { if root, _ := FindModuleRoot(cwd, \u0026quot;\u0026quot;, false); root != \u0026quot;\u0026quot; { cfg.GoModInGOPATH = filepath.Join(root, \u0026quot;go.mod\u0026quot;) } return } if CmdModInit { ModRoot = cwd } else { ... if search.InDir(ModRoot, os.TempDir()) == \u0026quot;.\u0026quot; { ModRoot = \u0026quot;\u0026quot; fmt.Fprintf(os.Stderr, \u0026quot;go: warning: ignoring go.mod in system temp root %v\\n\u0026quot;, os.TempDir()) return } } ... search.SetModRoot(ModRoot) }   判断环境变量 GO111MODULE 选项，主要是设置是否支持 go.mod 和处理一些异常 判断环境变量 GIT_TERMINAL_PROMPT 选项，主要是涉及 Git 的密码弹窗输出提示的处理 判断环境变量 GIT_SSH 选项，主要是判断 Git SSH 连接池，默认为禁用 判断当前路径是否在 $GOPATH 下（可以注意 filepath.SplitList 相关联的代码。主要是读取了 $GOPATH 后利用特定标志位 : 进行了分隔，解决多 $GOPATH 的问题） 判断当前是否在 $GOPATH 下且没有打开 GO111MODULE 选项。若是则检索当前根目录下是否包含 go.mod 文件，存在则代表当前 $GOPATH 下存在 go.mod 文件，这里相对应的是 auto 选项时的逻辑 若当前 CmdModInit 为启用，则在当前目录下创建 go.mod 文件，否则将尽量尝试去临时目录寻找标志文件  当 modRoot 为空时，则触发异常处理，常见的一些错误提示如下：\nfunc die() { if os.Getenv(\u0026quot;GO111MODULE\u0026quot;) == \u0026quot;off\u0026quot; { base.Fatalf(\u0026quot;go: modules disabled by GO111MODULE=off; see 'go help modules'\u0026quot;) } if inGOPATH \u0026amp;\u0026amp; !MustUseModules { base.Fatalf(\u0026quot;go: modules disabled inside GOPATH/src by GO111MODULE=auto; see 'go help modules'\u0026quot;) } base.Fatalf(\u0026quot;go: cannot find main module; see 'go help modules'\u0026quot;) }  二、具体实现逻辑\nfunc InitMod() { ... if modFile != nil { return } list := filepath.SplitList(cfg.BuildContext.GOPATH) if len(list) == 0 || list[0] == \u0026quot;\u0026quot; { base.Fatalf(\u0026quot;missing $GOPATH\u0026quot;) } gopath = list[0] if _, err := os.Stat(filepath.Join(gopath, \u0026quot;go.mod\u0026quot;)); err == nil { base.Fatalf(\u0026quot;$GOPATH/go.mod exists but should not\u0026quot;) } oldSrcMod := filepath.Join(list[0], \u0026quot;src/mod\u0026quot;) pkgMod := filepath.Join(list[0], \u0026quot;pkg/mod\u0026quot;) infoOld, errOld := os.Stat(oldSrcMod) _, errMod := os.Stat(pkgMod) if errOld == nil \u0026amp;\u0026amp; infoOld.IsDir() \u0026amp;\u0026amp; errMod != nil \u0026amp;\u0026amp; os.IsNotExist(errMod) { os.Rename(oldSrcMod, pkgMod) } modfetch.PkgMod = pkgMod modfetch.GoSumFile = filepath.Join(ModRoot, \u0026quot;go.sum\u0026quot;) codehost.WorkRoot = filepath.Join(pkgMod, \u0026quot;cache/vcs\u0026quot;) if CmdModInit { // Running go mod init: do legacy module conversion legacyModInit() modFileToBuildList() WriteGoMod() return } gomod := filepath.Join(ModRoot, \u0026quot;go.mod\u0026quot;) data, err := ioutil.ReadFile(gomod) if err != nil { if os.IsNotExist(err) { legacyModInit() modFileToBuildList() WriteGoMod() return } base.Fatalf(\u0026quot;go: %v\u0026quot;, err) } f, err := modfile.Parse(gomod, data, fixVersion) if err != nil { // Errors returned by modfile.Parse begin with file:line. base.Fatalf(\u0026quot;go: errors parsing go.mod:\\n%s\\n\u0026quot;, err) } modFile = f if len(f.Syntax.Stmt) == 0 || f.Module == nil { // Empty mod file. Must add module path. path, err := FindModulePath(ModRoot) if err != nil { base.Fatalf(\u0026quot;go: %v\u0026quot;, err) } f.AddModuleStmt(path) } if len(f.Syntax.Stmt) == 1 \u0026amp;\u0026amp; f.Module != nil { // Entire file is just a module statement. // Populate require if possible. legacyModInit() } excluded = make(map[module.Version]bool) for _, x := range f.Exclude { excluded[x.Mod] = true } modFileToBuildList() WriteGoMod() }   判断是否已存在 go.mod 的文件句柄（代指已经处理过相应的逻辑） 检查 $GOPATH 是否设置，并判断 go.mod 文件是否已存在（代指是否已经初始化过） 若 oldSrcMod（src/mod）存在，则 pkgMod（pkg/mod) 不存在，则进行重命名。这里考虑为兼容性操作 若为初次初始化，则执行以下步骤  第一步先做兼容处理，也就是执行 legacyModInit() 对前身（vgo）的一些东西进行兼容处理转换为 go module 现在的模式 第二步执行 modFileToBuildList() 方法 从 modFile 中初始化 mod 构建列表 最后通过 WriteGoMod 进行逻辑处理后（例：处理最小依赖版本）将当前构建列表反写回 go.mod 文件  若并非初次初始化，将会读取 go.mod 文件，根据语法解析 go.mod 的文件内容。接下来会进行一些基准操作  若 go.mod 文件是否为空，则先通过 FindModulePath 检索现有的路径。另外在这里也做了 godeps、govendor 的兼容处理。寻找到 module path 后通过 AddModuleStmt() 添加 module path 到文件中 若只存在 module path，则通过 legacyModInit() 进行兼容处理 最后与上小点一致，均为构建回写等动作   总结 在 go module 中，更多的是本身对包管理工具的思考和实现。如果你仔细阅读过，可以想想如下方面：\n 为什么要这么做 为什么要在这个地方做 有没有更好的方法  依赖包管理工具，是 Go 一个比较要命的痛点。那为什么 go module 又能 \u0026ldquo;解决\u0026rdquo; 呢？请想想\u0026hellip;\n基于篇幅我没有把所有内容都写出来，但是写法、思维是类似的。有兴趣的同学可以认真看看视频，举一反三\n问题 Go 1.11 在 go mod edit -module a/new/mod/name 命令中的一个 bug go mod edit 命令的 -module flag 是用于修改当前 module 的 path。也就是 go.mod 文件中，module 那一行。 在这个命令的源码 src/cmd/go/internal/modcmd/edit.go 文件 177 行开始：\nif *editModule != \u0026#34;\u0026#34; { modFile.AddModuleStmt(modload.CmdModModule) } AddModuleStmt 这个函数的参数应该是 *editModule，而不是 modload.CmdModule。 modload.CmdModule 只在 go mod init 命令启动时初始化。\n// src/cmd/go/internal/modcmd/init.go func runInit(cmd *base.Command, args []string) { modload.CmdModInit = true if len(args) \u0026gt; 1 { base.Fatalf(\u0026#34;go mod init: too many arguments\u0026#34;) } if len(args) == 1 { modload.CmdModModule = args[0] // INITIALIZATION IS HERE! \t} if _, err := os.Stat(\u0026#34;go.mod\u0026#34;); err == nil { base.Fatalf(\u0026#34;go mod init: go.mod already exists\u0026#34;) } modload.InitMod() // does all the hard work } 因此，由于 string 类型变量的 empty value 是空字符串，所以每次使运行 go mod edit -module a/new/module/name 并不会把 module path 修改为 a/new/module/name，而是修改为空字符串。\n$ go mod init github.com/ziyi-yan/hello go: creating new go.mod: module github.com/ziyi-yan/hello $ cat go.mod module github.com/ziyi-yan/hello $ go mod edit -module github.com/ziyi-yan/hello-new $ cat go.mod module \u0026quot;\u0026quot;  go 语言最新的代码 已经修复了这个 bug，预计在 Go 1.12 中发布。\n","title":"第 24 期 go mod 源码阅读 part 1"},{"location":"https://bytemode.github.io/reading/23-2018-12-13-drone-guide/","text":" 观看视频   参考资料  基于 gogs/gitlab 和 drone 搭建的 CI/CD 平台 Drone 源码分析之同步 repos 的策略研讨 Drone 源码分析之数据库初始化  ","title":"第 23 期 Drone 简单介绍和部分源码分析"},{"location":"https://bytemode.github.io/reading/22-2018-12-06-go-ide-discuss/","text":" 观看视频   ","title":"第 22 期 Go 开发工具讨论"},{"location":"https://bytemode.github.io/reading/21-2018-11-28-errors-in-go/","text":" 观看视频   ","title":"第 21 期 Go errors 处理及 zap 源码分析"},{"location":"https://bytemode.github.io/reading/20-2018-11-15-go-test/","text":" 观看视频   ","title":"第 20 期 go test 及测试覆盖率"},{"location":"https://bytemode.github.io/articles/2018-11-11-golang-file-lock/","text":" 这篇文章给大家介绍一下 golang 的文件锁。我们在使用 golang 开发程序的时候，经常会出现多个 goroutine 操作同一个文件（或目录）的时候，如果不加锁，很容易导致文件中的数据混乱，于是，Flock 应运而生。\nFlock 是对于整个文件的建议性锁（不强求 goroutine 遵守），如果一个 goroutine 在文件上获取了锁，那么其他 goroutine 是可以知道的。默认情况下，当一个 goroutine 将文件锁住，另外一个 goroutine 可以直接操作被锁住的文件，原因在于 Flock 只是用于检测文件是否被加锁，针对文件已经被加锁，另一个 goroutine 写入数据的情况，内核不会阻止这个 goroutine 的写入操作，也就是建议性锁的内核处理策略。\n函数 import \u0026#34;syscall\u0026#34; func Flock(fd int, how int) (err error) Flock 位于 syscall 包中，fd 参数指代文件描述符，how 参数指代锁的操作类型。\nhow 主要的参数类型：\n LOCK_SH，共享锁，多个进程可以使用同一把锁，常被用作读共享锁； LOCK_EX，排他锁，同时只允许一个进程使用，常被用作写锁； LOCK_NB，遇到锁的表现，当采用排他锁的时候，默认 goroutine 会被阻塞等待锁被释放，采用 LOCK_NB 参数，可以让 goroutine 返回 Error; LOCK_UN，释放锁；  示例 下面的例子来自于 NSQ，位于 nsq/internal/dirlock，用于实现对目录的加锁\n// +build !windows  package dirlock import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;syscall\u0026#34; ) // 定义一个 DirLock 的struct type DirLock struct { dir string // 目录路径，例如 /home/XXX/go/src \tf *os.File // 文件描述符 } // 新建一个 DirLock func New(dir string) *DirLock { return \u0026amp;DirLock{ dir: dir, } } // 加锁操作 func (l *DirLock) Lock() error { f, err := os.Open(l.dir) // 获取文件描述符 \tif err != nil { return err } l.f = f err = syscall.Flock(int(f.Fd()), syscall.LOCK_EX|syscall.LOCK_NB) // 加上排他锁，当遇到文件加锁的情况直接返回 Error \tif err != nil { return fmt.Errorf(\u0026#34;cannot flock directory %s - %s\u0026#34;, l.dir, err) } return nil } // 解锁操作 func (l *DirLock) Unlock() error { defer l.f.Close() // close 掉文件描述符 \treturn syscall.Flock(int(l.f.Fd()), syscall.LOCK_UN) // 释放 Flock 文件锁 } 总结  Flock 是建议性的锁，使用的时候需要指定 how 参数，否则容易出现多个 goroutine 共用文件的问题 how 参数指定 LOCK_NB 之后，goroutine 遇到已加锁的 Flock，不会阻塞，而是直接返回错误  ","title":"golang 的文件锁操作"},{"location":"https://bytemode.github.io/reading/19-2018-11-08-http-router-in-go/","text":" 观看视频   ","title":"第 19 期 如何开发一个简单高性能的http router及gorouter源码分析"},{"location":"https://bytemode.github.io/reading/18-2018-09-27-covenantsql-dh-rpc/","text":" 观看视频   ","title":"第 18 期 去中心化加密通信框架 CovenantSQL/DH-RPC的设计"},{"location":"https://bytemode.github.io/reading/17-2018-09-20-grpcp/","text":" 观看视频   ","title":"第 17 期 grpc 开发及 grpcp 的源码分析"},{"location":"https://bytemode.github.io/articles/sync/sync_cond_source_code_analysis/","text":" Cond的主要作用就是获取锁之后，wait()方法会等待一个通知，来进行下一步锁释放等操作，以此控制锁合适释放，释放频率,适用于在并发环境下goroutine的等待和通知。\n针对Golang 1.9的sync.Cond，与Golang 1.10一样。 源代码位置：sync\\cond.go。\n结构体 type Cond struct { noCopy noCopy // noCopy可以嵌入到结构中，在第一次使用后不可复制,使用go vet作为检测使用  // 根据需求初始化不同的锁，如*Mutex 和 *RWMutex \tL Locker notify notifyList // 通知列表,调用Wait()方法的goroutine会被放入list中,每次唤醒,从这里取出 \tchecker copyChecker // 复制检查,检查cond实例是否被复制 } 再来看看等待队列notifyList结构体：\ntype notifyList struct { wait uint32 notify uint32 lock uintptr head unsafe.Pointer tail unsafe.Pointer } 函数 NewCond 相当于Cond的构造函数，用于初始化Cond。\n参数为Locker实例初始化,传参数的时候必须是引用或指针,比如\u0026amp;sync.Mutex{}或new(sync.Mutex)，不然会报异常:cannot use lock (type sync.Mutex) as type sync.Locker in argument to sync.NewCond。\n大家可以想想为什么一定要是指针呢？ 因为如果传入 Locker 实例，在调用 c.L.Lock() 和 c.L.Unlock() 的时候，会频繁发生锁的复制，会导致锁的失效，甚至导致死锁。\nfunc NewCond(l Locker) *Cond { return \u0026amp;Cond{L: l} } Wait 等待自动解锁c.L和暂停执行调用goroutine。恢复执行后,等待锁c.L返回之前。与其他系统不同，等待不能返回，除非通过广播或信号唤醒。\n因为c。当等待第一次恢复时，L并没有被锁定，调用者通常不能假定等待返回时的条件是正确的。相反，调用者应该在循环中等待:\nfunc (c *Cond) Wait() { // 检查c是否是被复制的，如果是就panic \tc.checker.check() // 将当前goroutine加入等待队列 \tt := runtime_notifyListAdd(\u0026amp;c.notify) // 解锁 \tc.L.Unlock() // 等待队列中的所有的goroutine执行等待唤醒操作 \truntime_notifyListWait(\u0026amp;c.notify, t) c.L.Lock() } 判断cond是否被复制。\ntype copyChecker uintptr func (c *copyChecker) check() { if uintptr(*c) != uintptr(unsafe.Pointer(c)) \u0026amp;\u0026amp; !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) \u0026amp;\u0026amp; uintptr(*c) != uintptr(unsafe.Pointer(c)) { panic(\u0026#34;sync.Cond is copied\u0026#34;) } } Signal 唤醒等待队列中的一个goroutine，一般都是任意唤醒队列中的一个goroutine，为什么没有选择FIFO的模式呢？这是因为FiFO模式效率不高，虽然支持，但是很少使用到。\nfunc (c *Cond) Signal() { // 检查c是否是被复制的，如果是就panic \tc.checker.check() // 通知等待列表中的一个 \truntime_notifyListNotifyOne(\u0026amp;c.notify) } Broadcast 唤醒等待队列中的所有goroutine。\nfunc (c *Cond) Broadcast() { // 检查c是否是被复制的，如果是就panic \tc.checker.check() // 检查c是否是被复制的，如果是就panic \truntime_notifyListNotifyAll(\u0026amp;c.notify) } 实例 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var locker = new(sync.Mutex) var cond = sync.NewCond(locker) func main() { for i := 0; i \u0026lt; 40; i++ { go func(x int) { cond.L.Lock() //获取锁 \tdefer cond.L.Unlock() //释放锁 \tcond.Wait() //等待通知,阻塞当前goroutine \tfmt.Println(x) time.Sleep(time.Second * 1) }(i) } time.Sleep(time.Second * 1) fmt.Println(\u0026#34;Signal...\u0026#34;) cond.Signal() // 下发一个通知给已经获取锁的goroutine \ttime.Sleep(time.Second * 1) cond.Signal() // 3秒之后 下发一个通知给已经获取锁的goroutine \ttime.Sleep(time.Second * 3) cond.Broadcast() //3秒之后 下发广播给所有等待的goroutine \tfmt.Println(\u0026#34;Broadcast...\u0026#34;) time.Sleep(time.Second * 60) }","title":"sync.Cond源码分析"},{"location":"https://bytemode.github.io/articles/sync/sync_map_source_code_analysis/","text":" 背景 众所周知,go普通的map是不支持并发的，换而言之,不是线程(goroutine)安全的。博主是从golang 1.4开始使用的，那时候map的并发读是没有支持，但是并发写会出现脏数据。golang 1.6之后，并发地读写会直接panic：\nfatal error: concurrent map read and map write  package main func main() { m := make(map[int]int) go func() { for { _ = m[1] } }() go func() { for { m[2] = 2 } }() select {} } 所以需要支持对map的并发读写时候，博主使用两种方法： 1. 第三方类库 concurrent-map。 2. map加上sync.RWMutex来保障线程(goroutine)安全的。\ngolang 1.9之后,go 在sync包下引入了并发安全的map，也为博主提供了第三种方法。本文重点也在此，为了时效性，本文基于golang 1.10源码进行分析。\nsync.Map 结构体 Map type Map struct { mu Mutex //互斥锁，用于锁定dirty map  read atomic.Value //优先读map,支持原子操作，注释中有readOnly不是说read是只读，而是它的结构体。read实际上有写的操作  dirty map[interface{}]*entry // dirty是一个当前最新的map，允许读写  misses int // 主要记录read读取不到数据加锁读取read map以及dirty map的次数，当misses等于dirty的长度时，会将dirty复制到read } readOnly readOnly 主要用于存储，通过原子操作存储在Map.read中元素。\ntype readOnly struct { m map[interface{}]*entry amended bool // 如果数据在dirty中但没有在read中，该值为true,作为修改标识 }  entry type entry struct { // nil: 表示为被删除，调用Delete()可以将read map中的元素置为nil // expunged: 也是表示被删除，但是该键只在read而没有在dirty中，这种情况出现在将read复制到dirty中，即复制的过程会先将nil标记为expunged，然后不将其复制到dirty // 其他: 表示存着真正的数据 p unsafe.Pointer // *interface{} }  原理 如果你接触过大Java，那你一定对CocurrentHashMap利用锁分段技术增加了锁的数目，从而使争夺同一把锁的线程的数目得到控制的原理记忆深刻。\n那么Golang的sync.Map是否也是使用了相同的原理呢？sync.Map的原理很简单，使用了空间换时间策略，通过冗余的两个数据结构(read、dirty),实现加锁对性能的影响。 通过引入两个map将读写分离到不同的map，其中read map提供并发读和已存元素原子写，而dirty map则负责读写。 这样read map就可以在不加锁的情况下进行并发读取,当read map中没有读取到值时,再加锁进行后续读取,并累加未命中数,当未命中数大于等于dirty map长度,将dirty map上升为read map。从之前的结构体的定义可以发现，虽然引入了两个map，但是底层数据存储的是指针，指向的是同一份值。\n开始时sync.Map写入数据\nX=1 Y=2 Z=3  dirty map主要接受写请求，read map没有数据，此时read map与dirty map数据如下图。 读取数据的时候从read map中读取，此时read map并没有数据，miss记录从read map读取失败的次数，当misses\u0026gt;=len(dirty map)时，将dirty map直接升级为read map,这里直接对dirty map进行地址拷贝并且dirty map被清空，misses置为0。此时read map与dirty map数据如下图。 现在有需求对Z元素进行修改Z=4，sync.Map会直接修改read map的元素。\n新加元素K=5，新加的元素就需要操作dirty map了，如果misses达到阀值后dirty map直接升级为read map并且dirty map为空map(read的amended==false)，则dirty map需要从read map复制数据。\n升级后的效果如下。\n如果需要删除Z，需要分几种情况：\n一种read map存在该元素且read的amended==false：直接将read中的元素置为nil。 另一种为元素刚刚写入dirty map且未升级为read map:直接调用golang内置函数delete删除dirty map的元素； 还有一种是read map和dirty map同时存在该元素：将read map中的元素置为nil，因为read map和dirty map 使用的均为元素地址，所以均被置为nil。 优化点  空间换时间。通过冗余的两个数据结构(read、dirty),实现加锁对性能的影响。 使用只读数据(read)，避免读写冲突。 动态调整，miss次数多了之后，将dirty数据提升为read。 double-checking（双重检测）。 延迟删除。 删除一个键值只是打标记，只有在提升dirty的时候才清理删除的数据。 优先从read读取、更新、删除，因为对read的读取不需要锁。  方法源码分析 Load Load返回存储在映射中的键值，如果没有值，则返回nil。ok结果指示是否在映射中找到值。\nfunc (m *Map) Load(key interface{}) (value interface{}, ok bool) { // 第一次检测元素是否存在 \tread, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok \u0026amp;\u0026amp; read.amended { // 为dirty map 加锁 \tm.mu.Lock() // 第二次检测元素是否存在，主要防止在加锁的过程中,dirty map转换成read map,从而导致读取不到数据 \tread, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026amp;\u0026amp; read.amended { // 从dirty map中获取是为了应对read map中不存在的新元素 \te, ok = m.dirty[key] // 不论元素是否存在，均需要记录miss数，以便dirty map升级为read map \tm.missLocked() } // 解锁 \tm.mu.Unlock() } // 元素不存在直接返回 \tif !ok { return nil, false } return e.load() } dirty map升级为read map\nfunc (m *Map) missLocked() { // misses自增1 \tm.misses++ // 判断dirty map是否可以升级为read map \tif m.misses \u0026lt; len(m.dirty) { return } // dirty map升级为read map \tm.read.Store(readOnly{m: m.dirty}) // dirty map 清空 \tm.dirty = nil // misses重置为0 \tm.misses = 0 } 元素取值\nfunc (e *entry) load() (value interface{}, ok bool) { p := atomic.LoadPointer(\u0026amp;e.p) // 元素不存在或者被删除，则直接返回 \tif p == nil || p == expunged { return nil, false } return *(*interface{})(p), true } read map主要用于读取，每次Load都先从read读取，当read中不存在且amended为true，就从dirty读取数据 。无论dirty map中是否存在该元素，都会执行missLocked函数，该函数将misses+1，当m.misses \u0026gt;= len(m.dirty)时，便会将dirty复制到read，此时再将dirty置为nil,misses=0。\nstorage 设置Key=\u0026gt;Value。\nfunc (m *Map) Store(key, value interface{}) { // 如果read存在这个键，并且这个entry没有被标记删除，尝试直接写入,写入成功，则结束 \t// 第一次检测 \tread, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok \u0026amp;\u0026amp; e.tryStore(\u0026amp;value) { return } // dirty map锁 \tm.mu.Lock() // 第二次检测 \tread, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok { // unexpungelocc确保元素没有被标记为删除 \t// 判断元素被标识为删除 \tif e.unexpungeLocked() { // 这个元素之前被删除了，这意味着有一个非nil的dirty，这个元素不在里面. \tm.dirty[key] = e } // 更新read map 元素值 \te.storeLocked(\u0026amp;value) } else if e, ok := m.dirty[key]; ok { // 此时read map没有该元素，但是dirty map有该元素，并需修改dirty map元素值为最新值 \te.storeLocked(\u0026amp;value) } else { // read.amended==false,说明dirty map为空，需要将read map 复制一份到dirty map \tif !read.amended { m.dirtyLocked() // 设置read.amended==true，说明dirty map有数据 \tm.read.Store(readOnly{m: read.m, amended: true}) } // 设置元素进入dirty map，此时dirty map拥有read map和最新设置的元素 \tm.dirty[key] = newEntry(value) } // 解锁，有人认为锁的范围有点大，假设read map数据很大，那么执行m.dirtyLocked()会耗费花时间较多，完全可以在操作dirty map时才加锁，这样的想法是不对的，因为m.dirtyLocked()中有写入操作 \tm.mu.Unlock() } 尝试存储元素。\nfunc (e *entry) tryStore(i *interface{}) bool { // 获取对应Key的元素，判断是否标识为删除 \tp := atomic.LoadPointer(\u0026amp;e.p) if p == expunged { return false } for { // cas尝试写入新元素值 \tif atomic.CompareAndSwapPointer(\u0026amp;e.p, p, unsafe.Pointer(i)) { return true } // 判断是否标识为删除 \tp = atomic.LoadPointer(\u0026amp;e.p) if p == expunged { return false } } } unexpungelocc确保元素没有被标记为删除。如果这个元素之前被删除了，它必须在未解锁前被添加到dirty map上。\nfunc (e *entry) unexpungeLocked() (wasExpunged bool) { return atomic.CompareAndSwapPointer(\u0026amp;e.p, expunged, nil) } 从read map复制到dirty map。\nfunc (m *Map) dirtyLocked() { if m.dirty != nil { return } read, _ := m.read.Load().(readOnly) m.dirty = make(map[interface{}]*entry, len(read.m)) for k, e := range read.m { // 如果标记为nil或者expunged，则不复制到dirty map \tif !e.tryExpungeLocked() { m.dirty[k] = e } } } LoadOrStore 如果对应的元素存在，则返回该元素的值，如果不存在，则将元素写入到sync.Map。如果已加载值，则加载结果为true;如果已存储，则为false。\nfunc (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) { // 不加锁的情况下读取read map \t// 第一次检测 \tread, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok { // 如果元素存在（是否标识为删除由tryLoadOrStore执行处理），尝试获取该元素已存在的值或者将元素写入 \tactual, loaded, ok := e.tryLoadOrStore(value) if ok { return actual, loaded } } m.mu.Lock() // 第二次检测 \t// 以下逻辑参看Store \tread, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok { if e.unexpungeLocked() { m.dirty[key] = e } actual, loaded, _ = e.tryLoadOrStore(value) } else if e, ok := m.dirty[key]; ok { actual, loaded, _ = e.tryLoadOrStore(value) m.missLocked() } else { if !read.amended { m.dirtyLocked() m.read.Store(readOnly{m: read.m, amended: true}) } m.dirty[key] = newEntry(value) actual, loaded = value, false } m.mu.Unlock() return actual, loaded } 如果没有删除元素，tryLoadOrStore将自动加载或存储一个值。如果删除元素，tryLoadOrStore保持条目不变并返回ok= false。\nfunc (e *entry) tryLoadOrStore(i interface{}) (actual interface{}, loaded, ok bool) { p := atomic.LoadPointer(\u0026amp;e.p) // 元素标识删除，直接返回 \tif p == expunged { return nil, false, false } // 存在该元素真实值，则直接返回原来的元素值 \tif p != nil { return *(*interface{})(p), true, true } // 如果p为nil(此处的nil，并是不是指元素的值为nil，而是atomic.LoadPointer(\u0026amp;e.p)为nil，元素的nil在unsafe.Pointer是有值的)，则更新该元素值 \tic := i for { if atomic.CompareAndSwapPointer(\u0026amp;e.p, nil, unsafe.Pointer(\u0026amp;ic)) { return i, false, true } p = atomic.LoadPointer(\u0026amp;e.p) if p == expunged { return nil, false, false } if p != nil { return *(*interface{})(p), true, true } } } Delete 删除元素,采用延迟删除，当read map存在元素时，将元素置为nil，只有在提升dirty的时候才清理删除的数,延迟删除可以避免后续获取删除的元素时候需要加锁。当read map不存在元素时，直接删除dirty map中的元素\nfunc (m *Map) Delete(key interface{}) { // 第一次检测 \tread, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok \u0026amp;\u0026amp; read.amended { m.mu.Lock() // 第二次检测 \tread, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026amp;\u0026amp; read.amended { // 不论dirty map是否存在该元素，都会执行删除 \tdelete(m.dirty, key) } m.mu.Unlock() } if ok { // 如果在read中，则将其标记为删除（nil） \te.delete() } } 元素值置为nil\nfunc (e *entry) delete() (hadValue bool) { for { p := atomic.LoadPointer(\u0026amp;e.p) if p == nil || p == expunged { return false } if atomic.CompareAndSwapPointer(\u0026amp;e.p, p, nil) { return true } } } Range 遍历获取sync.Map中所有的元素，使用的为快照方式，所以不一定是准确的。\nfunc (m *Map) Range(f func(key, value interface{}) bool) { // 第一检测 \tread, _ := m.read.Load().(readOnly) // read.amended=true,说明dirty map包含所有有效的元素（含新加，不含被删除的），使用dirty map \tif read.amended { // 第二检测 \tm.mu.Lock() read, _ = m.read.Load().(readOnly) if read.amended { // 使用dirty map并且升级为read map \tread = readOnly{m: m.dirty} m.read.Store(read) m.dirty = nil m.misses = 0 } m.mu.Unlock() } // 一贯原则，使用read map作为读 \tfor k, e := range read.m { v, ok := e.load() // 被删除的不计入 \tif !ok { continue } // 函数返回false，终止 \tif !f(k, v) { break } } } 总结 经过了上面的分析可以得到,sync.Map并不适合同时存在大量读写的场景,大量的写会导致read map读取不到数据从而加锁进行进一步读取,同时dirty map不断升级为read map。 从而导致整体性能较低,特别是针对cache场景.针对append-only以及大量读,少量写场景使用sync.Map则相对比较合适。\nsync.Map没有提供获取元素个数的Len()方法，不过可以通过Range()实现。\nfunc Len(sm sync.Map) int { lengh := 0 f := func(key, value interface{}) bool { lengh++ return true } one:=lengh lengh=0 sm.Range(f) if one != lengh { one = lengh lengh=0 sm.Range(f) if one \u0026lt;lengh { return lengh } } return one } 参考 * Go sync.Map * Go 1.9 sync.Map揭秘\n","title":"sync.Map源码分析"},{"location":"https://bytemode.github.io/articles/sync/sync_mutex_source_code_analysis/","text":" 针对 Golang 1.10.3 的 sync.Mutex 进行分析，代码位置：sync/mutex.go\n结构体 type Mutex struct { state int32 // 指代mutex锁当前的状态 \tsema uint32 // 信号量，用于唤醒goroutine } Mutex 中的 state 用于指代锁当前的状态，如下所示\n1111 1111 ...... 1111 1111 \\_________29__________/||| 存储等待 goroutine 数量 ||表示当前 mutex 是否加锁 |表示当前 mutex 是否被唤醒 表示 mutex 当前是否处于饥饿状态  几个常量 const ( mutexLocked = 1 \u0026lt;\u0026lt; iota mutexWoken mutexStarving mutexWaiterShift = iota starvationThresholdNs = 1e6 )  mutexLocked 值为1，根据 mutex.state \u0026amp; mutexLocked 得到 mutex 的加锁状态，结果为1表示已加锁，0表示未加锁 mutexWoken 值为2（二进制：10），根据 mutex.state \u0026amp; mutexWoken 得到 mutex 的唤醒状态，结果为1表示已唤醒，0表示未唤醒 mutexStarving 值为4（二进制：100），根据 mutex.state \u0026amp; mutexStarving 得到 mutex 的饥饿状态，结果为1表示处于饥饿状态，0表示处于正常状态 mutexWaiterShift 值为3，根据 mutex.state \u0026gt;\u0026gt; mutexWaiterShift 得到当前等待的 goroutine 数目 starvationThresholdNs 值为1e6纳秒，也就是1毫秒，当等待队列中队首 goroutine 等待时间超过 starvationThresholdNs，mutex 进入饥饿模式  饥饿模式与正常模式 Mutex 有两种工作模式：正常模式和饥饿模式\n在正常模式中，等待者按照 FIFO 的顺序排队获取锁，但是一个被唤醒的等待者有时候并不能获取 mutex，它还需要和新到来的 goroutine 们竞争 mutex 的使用权。新到来的 goroutine 存在一个优势，它们已经在 CPU 上运行且它们数量很多，因此一个被唤醒的等待者有很大的概率获取不到锁，在这种情况下它处在等待队列的前面。如果一个 goroutine 等待 mutex 释放的时间超过1ms，它就会将 mutex 切换到饥饿模式\n在饥饿模式中，mutex 的所有权直接从解锁的 goroutine 递交到等待队列中排在最前方的 goroutine。新到达的 goroutine 们不要尝试去获取 mutex，即使它看起来是在解锁状态，也不要试图自旋，而是排到等待队列的尾部\n如果一个等待者获得 mutex 的所有权，并且看到以下两种情况中的任一种：1) 它是等待队列中的最后一个，或者 2) 它等待的时间少于1ms，它便将 mutex 切换回正常操作模式\n函数 以下代码已经去掉了与核心代码无关的 race 代码\nLock Lock 方法申请对 mutex 加锁，Lock 执行的时候，分三种情况\n 无冲突 通过 CAS 操作把当前状态设置为加锁状态 有冲突 开始自旋，并等待锁释放，如果其他 goroutine 在这段时间内释放了该锁，直接获得该锁；如果没有释放，进入3 有冲突，且已经过了自旋阶段 通过调用 semacquire 函数来让当前 goroutine 进入等待状态\nfunc (m *Mutex) Lock() { // 查看 state 是否为0，如果是则表示可以加锁，将其状态转换为1，当前 goroutine 加锁成功，函数返回 \tif atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { return } var waitStartTime int64 // 当前 goroutine 开始等待的时间 \tstarving := false // mutex 当前所处的模式 \tawoke := false // 当前 goroutine 是否被唤醒 \titer := 0 // 自旋迭代的次数 \told := m.state // old 保存当前 mutex 的状态 \tfor { // 当 mutex 处于正常工作模式且能够自旋的时候，进行自旋操作（汇编实现，内部持续调用 PAUSE 指令，消耗 CPU 时间） \tif old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // 将 mutex.state 的倒数第二位设置为1，用来告 Unlock 操作，存在 goroutine \t// 即将得到锁，不需要唤醒其他 goroutine \tif !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state continue } new := old // 当 mutex 不处于饥饿状态的时候，将 new 的第一位设置为1，即加锁 \tif old\u0026amp;mutexStarving == 0 { new |= mutexLocked } // 当 mutex 处于加锁状态或饥饿状态的时候，新到来的 goroutine 进入等待队列 \tif old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift } // 当前 goroutine 将 mutex 切换为饥饿状态，但如果当前 mutex 未加锁，则不需要切换 \t// Unlock 操作希望饥饿模式存在等待者 \tif starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving } if awoke { // 当前 goroutine 被唤醒，将 mutex.state 倒数第二位重置 \tif new\u0026amp;mutexWoken == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } new \u0026amp;^= mutexWoken } // 调用 CAS 更新 state 状态 \tif atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { // mutex 处于未加锁，正常模式下，当前 goroutine 获得锁 \tif old\u0026amp;(mutexLocked|mutexStarving) == 0 { break } // queueLifo 为 true 代表当前 goroutine 是等待状态的 goroutine \tqueueLifo := waitStartTime != 0 if waitStartTime == 0 { // 记录开始等待时间 \twaitStartTime = runtime_nanotime() } // 将被唤醒却没得到锁的 goroutine 插入当前等待队列的最前端 \truntime_SemacquireMutex(\u0026amp;m.sema, queueLifo) // 如果当前 goroutine 等待时间超过starvationThresholdNs，mutex 进入饥饿模式 \tstarving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state if old\u0026amp;mutexStarving != 0 { if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } // 等待状态的 goroutine - 1 \tdelta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) // 如果不是饥饿模式了或者当前等待着只剩下一个，退出饥饿模式 \tif !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { delta -= mutexStarving } // 更新状态 \tatomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } }  Unlock Unlock方法释放所申请的锁\nfunc (m *Mutex) Unlock() { // mutex 的 state 减去1，加锁状态 -\u0026gt; 未加锁 \tnew := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) // 未 Lock 直接 Unlock，报 panic \tif (new+mutexLocked)\u0026amp;mutexLocked == 0 { throw(\u0026#34;sync: unlock of unlocked mutex\u0026#34;) } // mutex 正常模式 \tif new\u0026amp;mutexStarving == 0 { old := new for { // 如果没有等待者，或者已经存在一个 goroutine 被唤醒或得到锁，或处于饥饿模式 \t// 无需唤醒任何处于等待状态的 goroutine \tif old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // 等待者数量减1，并将唤醒位改成1 \tnew = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { // 唤醒一个阻塞的 goroutine，但不是唤醒第一个等待者 \truntime_Semrelease(\u0026amp;m.sema, false) return } old = m.state } } else { // mutex 饥饿模式，直接将 mutex 拥有权移交给等待队列最前端的 goroutine \truntime_Semrelease(\u0026amp;m.sema, true) } }","title":"sync.Mutex 源码分析"},{"location":"https://bytemode.github.io/articles/sync/sync_once_source_code_analysis/","text":" sync.Once可以实现单例模式，确保sync.Once.Do(f func())只会被执行一次，可以初始化某个实例单例。\n针对Golang 1.9的sync.Once，与Golang 1.10一样。 源代码位置：sync\\once.go。\n结构体 Once结构体定义如下：\ntype Once struct { m Mutex done uint32 // 初始值为0表示还未执行过，1表示已经执行过 } Do func (o *Once) Do(f func()) { // done==1表示已经执行过了，直接结束返回 \tif atomic.LoadUint32(\u0026amp;o.done) == 1 { return } // 锁住对象，避免并发问题 \to.m.Lock() defer o.m.Unlock() if o.done == 0 { // 执行f函数后将done设置为1 \tdefer atomic.StoreUint32(\u0026amp;o.done, 1) f() } } 需要注意的是执行f函数是同步进行的，也就是说可能存在阻塞问题。\n","title":"sync.Once源码分析"},{"location":"https://bytemode.github.io/articles/sync/sync_rwmutex_source_code_analysis/","text":" 针对 Golang 1.9 的 sync.RWMutex 进行分析，与 Golang 1.10 基本一样除了将panic改为了throw之外其他的都一样\nRWMutex 是读写互斥锁，锁可以由任意数量的读取器或单个写入器来保持\nRWMutex 的零值是一个解锁的互斥锁\nRWMutex 是抢占式的读写锁，写锁之后来的读锁是加不上的\n以下代码均去除race竞态检测代码\n源代码位置：sync/rwmutex.go\n结构体 type RWMutex struct { w Mutex // 互斥锁  writerSem uint32 // 写锁信号量  readerSem uint32 // 读锁信号量  readerCount int32 // 读锁计数器  readerWait int32 // 获取写锁时需要等待的读锁释放数量 } 常量\nconst rwmutexMaxReaders = 1 \u0026lt;\u0026lt; 30 // 支持最多2^30个读锁 方法 以下是 sync.RWMutex 提供的4个方法\nLock 提供写锁加锁操作\nfunc (rw *RWMutex) Lock() { // 使用 Mutex 锁 \trw.w.Lock() // 将当前的 readerCount 置为负数，告诉 RUnLock 当前存在写锁等待 \tr := atomic.AddInt32(\u0026amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // 等待读锁释放 \tif r != 0 \u0026amp;\u0026amp; atomic.AddInt32(\u0026amp;rw.readerWait, r) != 0 { runtime_Semacquire(\u0026amp;rw.writerSem) } } Unlock 提供写锁释放操作\nfunc (rw *RWMutex) Unlock() { // 加上 Lock 的时候减去的 rwmutexMaxReaders \tr := atomic.AddInt32(\u0026amp;rw.readerCount, rwmutexMaxReaders) // 没执行Lock调用Unlock，抛出异常 \tif r \u0026gt;= rwmutexMaxReaders { race.Enable() throw(\u0026#34;sync: Unlock of unlocked RWMutex\u0026#34;) } // 通知当前等待的读锁 \tfor i := 0; i \u0026lt; int(r); i++ { runtime_Semrelease(\u0026amp;rw.readerSem, false) } // 释放 Mutex 锁 \trw.w.Unlock() } RLock 提供读锁操作\nfunc (rw *RWMutex) RLock() { // 每次 goroutine 获取读锁时，readerCount+1  // 如果写锁已经被获取，那么 readerCount 在 -rwmutexMaxReaders 与 0 之间，这时挂起获取读锁的 goroutine  // 如果写锁没有被获取，那么 readerCount \u0026gt; 0，获取读锁, 不阻塞  // 通过 readerCount 判断读锁与写锁互斥, 如果有写锁存在就挂起goroutine, 多个读锁可以并行 \tif atomic.AddInt32(\u0026amp;rw.readerCount, 1) \u0026lt; 0 { // 将 goroutine 排到G队列的后面,挂起 goroutine \truntime_Semacquire(\u0026amp;rw.readerSem) } } RUnLock RUnLock 方法对读锁进行解锁\nfunc (rw *RWMutex) RUnlock() { // 写锁等待状态，检查当前是否可以进行获取 \tif r := atomic.AddInt32(\u0026amp;rw.readerCount, -1); r \u0026lt; 0 { // r + 1 == 0表示直接执行RUnlock() \t// r + 1 == -rwmutexMaxReaders表示执行Lock()再执行RUnlock() \t// 两总情况均抛出异常 \tif r+1 == 0 || r+1 == -rwmutexMaxReaders { race.Enable() throw(\u0026#34;sync: RUnlock of unlocked RWMutex\u0026#34;) } // 当读锁释放完毕后，通知写锁 \tif atomic.AddInt32(\u0026amp;rw.readerWait, -1) == 0 { // The last reader unblocks the writer. \truntime_Semrelease(\u0026amp;rw.writerSem, false) } } } RLocker 可以看到 RWMutex 实现接口 Locker\ntype Locker interface { Lock() Unlock() } 而方法 RLocker 就是将 RWMutex 转换为 Locker\nfunc (rw *RWMutex) RLocker() Locker { return (*rlocker)(rw) } 总结 读写互斥锁的实现比较有技巧性一些，需要几点\n 读锁不能阻塞读锁，引入readerCount实现\n 读锁需要阻塞写锁，直到所有读锁都释放，引入readerSem实现\n 写锁需要阻塞读锁，直到所有写锁都释放，引入wirterSem实现\n 写锁需要阻塞写锁，引入Metux实现\n  ","title":"sync.RWMutex源码分析"},{"location":"https://bytemode.github.io/articles/sync/sync_waitgroup_source_code_analysis/","text":" 针对Golang 1.9的sync.WaitGroup进行分析，与Golang 1.10基本一样除了将panic改为了throw之外其他的都一样。 源代码位置：sync\\waitgroup.go。\n结构体 type WaitGroup struct { noCopy noCopy // noCopy可以嵌入到结构中，在第一次使用后不可复制,使用go vet作为检测使用，并因此只能进行指针传递，从而保证全局唯一 // 位值:高32位是计数器，低32位是goroutine等待计数。 // 64位的原子操作需要64位的对齐，但是32位。编译器不能确保它,所以分配了12个byte对齐的8个byte作为状态。 state1 [12]byte // byte=uint8范围：0~255，只取前8个元素。转为2进制：0000 0000，0000 0000... ...0000 0000 sema uint32 // 信号量，用于唤醒goroutine }  不知道大家是否和我一样，不论是使用Java的CountDownLatch还是Golang的WaitGroup，都会疑问，可以装下多个线程|协程等待呢？看了源码后可以回答了，可以装下\n1111 1111 1111 ... 1111 \\________32___________/  2^32个辣么多！所以不需要担心单机情况下会被撑爆了。\n函数 以下代码已经去掉了与核心代码无关的race代码。\nAdd 添加或者减少等待goroutine的数量。\n参数delta可能是负的，加到WaitGroup计数器,可能出现如下结果 - 如果计数器变为零，所有被阻塞的goroutines都会被释放。 - 如果计数器变成负数，就增加恐慌。\nfunc (wg *WaitGroup) Add(delta int) { // 获取到wg.state1数组中元素组成的二进制对应的十进制的值 statep := wg.state() // 高32位是计数器 // 原子操作，如初始状态 statep 为空，且 delta 等于 1, 操作 加 1： // 00000000 00000000 00000000 00000001 00000000 …… 00000000 // \\___________ 前32位 _______________/\\__ 后32位均为0 __/ // 若当前状态位存在值 1，则再添加 delta 等于 1， 其结果为： // 00000000 00000000 00000000 00000010 00000000 …… 00000000 // \\___________ 前32位 _______________/\\__ 后32位均为0 __/ state := atomic.AddUint64(statep, uint64(delta)\u0026lt;\u0026lt;32) // 获取计数器 v := int32(state \u0026gt;\u0026gt; 32) w := uint32(state) // 计数器为负数，报panic if v \u0026lt; 0 { panic(\u0026quot;sync: negative WaitGroup counter\u0026quot;) } // 添加与等待并发调用，报panic if w != 0 \u0026amp;\u0026amp; delta \u0026gt; 0 \u0026amp;\u0026amp; v == int32(delta) { panic(\u0026quot;sync: WaitGroup misuse: Add called concurrently with Wait\u0026quot;) } // 计数器添加成功 if v \u0026gt; 0 || w == 0 { return } // 当等待计数器\u0026gt; 0时，而goroutine设置为0。 // 此时不可能有同时发生的状态突变: // - 增加不能与等待同时发生， // - 如果计数器counter == 0，不再增加等待计数器 if *statep != state { panic(\u0026quot;sync: WaitGroup misuse: Add called concurrently with Wait\u0026quot;) } // Reset waiters count to 0. *statep = 0 for ; w != 0; w-- { // 目的是作为一个简单的wakeup原语，以供同步使用。true为唤醒排在等待队列的第一个goroutine runtime_Semrelease(\u0026amp;wg.sema, false) } }  // unsafe.Pointer其实就是类似C的void *，在golang中是用于各种指针相互转换的桥梁。 // uintptr是golang的内置类型，是能存储指针的整型，uintptr的底层类型是int，它和unsafe.Pointer可相互转换。 // uintptr和unsafe.Pointer的区别就是：unsafe.Pointer只是单纯的通用指针类型，用于转换不同类型指针，它不可以参与指针运算； // 而uintptr是用于指针运算的，GC 不把 uintptr 当指针，也就是说 uintptr 无法持有对象，uintptr类型的目标会被回收。 // state()函数可以获取到wg.state1数组中元素组成的二进制对应的十进制的值。 // 根据结构体中初始化分配的 12bytes 来兼容处理 64位操作系统和 32位操作系统, // 具体原理是，12bytes 中必定含有一个8bytes，仅仅使用这个含有的8bytes做为数据对齐使用，具体： // 当指针位置刚好指在 (2n) 的位置，证明位对齐，使用 8bytes 作为状态计数； // 当指针位置指在 (2n+1) 的位置上，抛弃前 4bytes，使用 后8bytes作为位对齐，用于记录状态计数。 func (wg *WaitGroup) state() *uint64 { if uintptr(unsafe.Pointer(\u0026amp;wg.state1))%8 == 0 { return (*uint64)(unsafe.Pointer(\u0026amp;wg.state1)) } else { return (*uint64)(unsafe.Pointer(\u0026amp;wg.state1[4])) } }  Done 相当于Add(-1)。\nfunc (wg *WaitGroup) Done() { // 计数器减一 wg.Add(-1) }  Wait 执行阻塞，直到所有的WaitGroup数量变成0。\nfunc (wg *WaitGroup) Wait() { // 获取到wg.state1数组中元素组成的二进制对应的十进制的值 statep := wg.state() // cas算法 for { state := atomic.LoadUint64(statep) // 高32位是计数器 v := int32(state \u0026gt;\u0026gt; 32) w := uint32(state) // 计数器为0，结束等待 if v == 0 { // Counter is 0, no need to wait. return } // 增加等待goroutine计数，对低32位加1，不需要移位 if atomic.CompareAndSwapUint64(statep, state, state+1) { // 目的是作为一个简单的sleep原语，以供同步使用 runtime_Semacquire(\u0026amp;wg.sema) if *statep != 0 { panic(\u0026quot;sync: WaitGroup is reused before previous Wait has returned\u0026quot;) } return } } }  使用注意事项  WaitGroup不能保证多个 goroutine 执行次序 WaitGroup无法指定固定的goroutine数目  ","title":"sync.WaitGroup源码分析"},{"location":"https://bytemode.github.io/reading/16-2018-09-06-gateway-reading/","text":" OpenFaaS的Gateway是一个golang实现的请求转发的网关，在这个网关服务中，主要有以下几个功能：\n UI 部署函数 监控 自动伸缩  架构分析 从图中可以发现，当Gateway作为一个入口，当CLI或者web页面发来要部署或者调用一个函数的时候，Gateway会将请求转发给Provider，同时会将监控指标发给Prometheus。AlterManager会根据需求，调用API自动伸缩函数。\n源码分析 依赖 github.com/gorilla/mux github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/nats-queue-worker github.com/prometheus/client_golang mux 是一个用来执行http请求的路由和分发的第三方扩展包。\ngo-nats-streaming，go-nats，nats-queue-worker这三个依赖是异步函数的时候才会用到，在分析queue-worker的时候有说到Gateway也是一个发布者。\nclient_golang是Prometheus的客户端。\n项目结构 ├── Dockerfile ├── Dockerfile.arm64 ├── Dockerfile.armhf ├── Gopkg.lock ├── Gopkg.toml ├── README.md ├── assets ├── build.sh ├── handlers │ ├── alerthandler.go │ ├── alerthandler_test.go │ ├── asyncreport.go │ ├── baseurlresolver_test.go │ ├── basic_auth.go │ ├── basic_auth_test.go │ ├── callid_middleware.go │ ├── cors.go │ ├── cors_test.go │ ├── forwarding_proxy.go │ ├── forwarding_proxy_test.go │ ├── function_cache.go │ ├── function_cache_test.go │ ├── infohandler.go │ ├── metrics.go │ ├── queueproxy.go │ ├── scaling.go │ └── service_query.go ├── metrics │ ├── add_metrics.go │ ├── add_metrics_test.go │ ├── externalwatcher.go │ ├── metrics.go │ └── prometheus_query.go ├── plugin │ ├── external.go │ └── external_test.go ├── queue │ └── types.go ├── requests │ ├── forward_request.go │ ├── forward_request_test.go │ ├── prometheus.go │ ├── prometheus_test.go │ └── requests.go ├── server.go ├── tests │ └── integration ├── types │ ├── handler_set.go │ ├── inforequest.go │ ├── load_credentials.go │ ├── proxy_client.go │ ├── readconfig.go │ └── readconfig_test.go ├── vendor │ └── github.com └── version └── version.go Gateway的目录明显多了很多，看源码的时候，首先要找到的是main包，从main函数看起，就能很容易分析出来项目是如何运行的。\n从server.go的main函数中我们可以看到，其实有如下几个模块：\n 基本的安全验证 和函数相关的代理转发  同步函数 列出函数 部署函数 删除函数 更新函数 异步函数  Prometheus的监控 ui 自动伸缩  基本的安全验证 如果配置了开启基本安全验证，会从磁盘中读取密钥：\nvar credentials *types.BasicAuthCredentials if config.UseBasicAuth { var readErr error reader := types.ReadBasicAuthFromDisk{ SecretMountPath: config.SecretMountPath, } credentials, readErr = reader.Read() if readErr != nil { log.Panicf(readErr.Error()) } } 在Gateway的配置相关的，都会有一个read()方法，进行初始化赋值。\n如果credentials被赋值之后，就会对一些要加密的API handler进行一个修饰，被修饰的API有：\n UpdateFunction DeleteFunction DeployFunction ListFunctions ScaleFunction\nif credentials != nil { faasHandlers.UpdateFunction = handlers.DecorateWithBasicAuth(faasHandlers.UpdateFunction, credentials) faasHandlers.DeleteFunction = handlers.DecorateWithBasicAuth(faasHandlers.DeleteFunction, credentials) faasHandlers.DeployFunction = handlers.DecorateWithBasicAuth(faasHandlers.DeployFunction, credentials) faasHandlers.ListFunctions = handlers.DecorateWithBasicAuth(faasHandlers.ListFunctions, credentials) faasHandlers.ScaleFunction = handlers.DecorateWithBasicAuth(faasHandlers.ScaleFunction, credentials) }  这个DecorateWithBasicAuth()方法是一个路由中间件：\n 调用mux路由的BasicAuth()，从http的header中取到用户名和密码 然后给请求头上设置一个字段WWW-Authenticate，值为Basic realm=\u0026quot;Restricted\u0026quot; 如果校验失败，则返回错误，成功的话调用next方法继续进入下一个handler。\n// DecorateWithBasicAuth enforces basic auth as a middleware with given credentials func DecorateWithBasicAuth(next http.HandlerFunc, credentials *types.BasicAuthCredentials) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { user, password, ok := r.BasicAuth() w.Header().Set(\u0026#34;WWW-Authenticate\u0026#34;, `Basic realm=\u0026#34;Restricted\u0026#34;`) if !ok || !(credentials.Password == password \u0026amp;\u0026amp; user == credentials.User) { w.WriteHeader(http.StatusUnauthorized) w.Write([]byte(\u0026#34;invalid credentials\u0026#34;)) return } next.ServeHTTP(w, r) } }  代理转发 Gateway本身不做任何和部署发布函数的事情，它只是作为一个代理，把请求转发给相应的Provider去处理，所有的请求都要通过这个网关。\n同步函数转发 主要转发的API有：\n RoutelessProxy ListFunctions DeployFunction DeleteFunction UpdateFunction\nfaasHandlers.RoutelessProxy = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.ListFunctions = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.DeployFunction = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.DeleteFunction = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.UpdateFunction = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver)  MakeForwardingProxyHandler()有三个参数：\n proxy  这是一个http的客户端，作者把这个客户端抽成一个类，然后使用该类的NewHTTPClientReverseProxy方法创建实例，这样就简化了代码，不用每次都得写一堆相同的配置。\n notifiers  这个其实是要打印的日志，这里是一个HTTPNotifier的接口。而在这个MakeForwardingProxyHandler中其实有两个实现类，一个是LoggingNotifier，一个是PrometheusFunctionNotifier，分别用来打印和函数http请求相关的日志以及和Prometheus监控相关的日志。\n baseURLResolver  这个就是Provider的url地址。\n在这个MakeForwardingProxyHandler中主要做了三件事儿：\n 解析要转发的url\n 调用forwardRequest方法转发请求，\n  forwardRequest方法的逻辑比较简单，只是把请求发出去。这里就不深入分析了。\n 打印日志\n// MakeForwardingProxyHandler create a handler which forwards HTTP requests func MakeForwardingProxyHandler(proxy *types.HTTPClientReverseProxy, notifiers []HTTPNotifier, baseURLResolver BaseURLResolver) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { baseURL := baseURLResolver.Resolve(r) requestURL := r.URL.Path start := time.Now() statusCode, err := forwardRequest(w, r, proxy.Client, baseURL, requestURL, proxy.Timeout) seconds := time.Since(start) if err != nil { log.Printf(\u0026#34;error with upstream request to: %s, %s\\n\u0026#34;, requestURL, err.Error()) } for _, notifier := range notifiers { notifier.Notify(r.Method, requestURL, statusCode, seconds) } } }  异步函数转发 前面说过，如果是异步函数，Gateway就作为一个发布者，将函数放到队列里。MakeQueuedProxy方法就是做这件事儿的：\n 读取请求体 将X-Callback-Url参数从参数中http的header中读出来 实例化用于异步处理的Request对象 调用canQueueRequests.Queue(req)，将请求发布到队列中\n// MakeQueuedProxy accepts work onto a queue func MakeQueuedProxy(metrics metrics.MetricOptions, wildcard bool, canQueueRequests queue.CanQueueRequests) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { defer r.Body.Close() body, err := ioutil.ReadAll(r.Body) // 省略错误处理代码 \tvars := mux.Vars(r) name := vars[\u0026#34;name\u0026#34;] callbackURLHeader := r.Header.Get(\u0026#34;X-Callback-Url\u0026#34;) var callbackURL *url.URL if len(callbackURLHeader) \u0026gt; 0 { urlVal, urlErr := url.Parse(callbackURLHeader) // 省略错误处理代码 \tcallbackURL = urlVal } req := \u0026amp;queue.Request{ Function: name, Body: body, Method: r.Method, QueryString: r.URL.RawQuery, Header: r.Header, CallbackURL: callbackURL, } err = canQueueRequests.Queue(req) // 省略错误处理代码 \tw.WriteHeader(http.StatusAccepted) } }  自动伸缩 伸缩性其实有两种，一种是可以通过调用API接口，来将函数进行缩放。另外一种就是通过AlertHandler。\n自动伸缩是OpenFaaS的一大特点，触发自动伸缩主要是根据不同的指标需求。\n 根据每秒请求数来做伸缩  OpenFaaS附带了一个自动伸缩的规则，这个规则是在AlertManager配置文件中定义。AlertManager从Prometheus中读取使用情况（每秒请求数），然后在满足一定条件时向Gateway发送警报。\n可以通过删除AlertManager，或者将部署扩展的环境变量设置为0，来禁用此方式。\n 最小/最大副本数  通过向函数添加标签, 可以在部署时设置最小 (初始) 和最大副本数。\n com.openfaas.scale.min 默认是 1 com.openfaas.scale.max 默认是 20 com.openfaas.scale.factor 默认是 20% ，在0-100之间，这是每次扩容的时候，新增实例的百分比，若是100的话，会瞬间飙升到副本数的最大值。  com.openfaas.scale.min 和 com.openfaas.scale.max值一样的时候，可以关闭自动伸缩。\ncom.openfaas.scale.factor是0时，也会关闭自动伸缩。\n 通过内存和CPU的使用量。  使用k8s内置的HPA，也可以触发AlertManager。\n手动指定伸缩的值 可以从这句代码中发现，调用这个路由，转发给了provider处理。\nr.HandleFunc(\u0026quot;/system/scale-function/{name:[-a-zA-Z_0-9]+}\u0026quot;, faasHandlers.ScaleFunction).Methods(http.MethodPost)  处理AlertManager的伸缩请求 Prometheus将监控指标发给AlertManager之后，会触发AlterManager调用/system/alert接口，这个接口的handler是由handlers.MakeAlertHandler方法生成。\nMakeAlertHandler方法接收的参数是ServiceQuery。ServiceQuery是一个接口，它有两个函数，用来get或者ser最大的副本数。Gateway中实现这个接口的类是ExternalServiceQuery，这个实现类是在plugin包中，我们也可以直接定制这个实现类，用来实现满足特定条件。\n// ServiceQuery provides interface for replica querying/setting type ServiceQuery interface { GetReplicas(service string) (response ServiceQueryResponse, err error) SetReplicas(service string, count uint64) error } // ExternalServiceQuery proxies service queries to external plugin via HTTP type ExternalServiceQuery struct { URL url.URL ProxyClient http.Client } 这个ExternalServiceQuery有一个NewExternalServiceQuery方法，这个方法也是一个工厂方法，用来创建实例。这个url其实就是provider的url，proxyClient就是一个http的client对象。\n GetReplicas方法  从system/function/:name接口获取到函数的信息，组装一个ServiceQueryResponse对象即可。\n SetReplicas方法  调用system/scale-function/:name接口，设置副本数。\nMakeAlertHandler的函数主要是从http.Request中读取body，然后反序列化成PrometheusAlert对象：\n// PrometheusAlert as produced by AlertManager type PrometheusAlert struct { Status string `json:\u0026#34;status\u0026#34;` Receiver string `json:\u0026#34;receiver\u0026#34;` Alerts []PrometheusInnerAlert `json:\u0026#34;alerts\u0026#34;` } 可以发现，这个Alerts是一个数组对象，所以可以是对多个函数进行缩放。反序列化之后，调用handleAlerts方法，而handleAlerts对Alerts进行遍历，针对每个Alerts调用了scaleService方法。scaleService才是真正处理伸缩服务的函数。\nfunc scaleService(alert requests.PrometheusInnerAlert, service ServiceQuery) error { var err error serviceName := alert.Labels.FunctionName if len(serviceName) \u0026gt; 0 { queryResponse, getErr := service.GetReplicas(serviceName) if getErr == nil { status := alert.Status newReplicas := CalculateReplicas(status, queryResponse.Replicas, uint64(queryResponse.MaxReplicas), queryResponse.MinReplicas, queryResponse.ScalingFactor) log.Printf(\u0026#34;[Scale] function=%s %d =\u0026gt; %d.\\n\u0026#34;, serviceName, queryResponse.Replicas, newReplicas) if newReplicas == queryResponse.Replicas { return nil } updateErr := service.SetReplicas(serviceName, newReplicas) if updateErr != nil { err = updateErr } } } return err } 从代码总就可以看到，scaleService做了三件事儿：\n 获取现在的副本数\n 计算新的副本数\n  新副本数的计算方法是根据com.openfaas.scale.factor计算步长：\nstep := uint64((float64(maxReplicas) / 100) * float64(scalingFactor))  设置为新的副本数  从0增加副本到的最小值 我们在调用函数的时候，用的路由是：/function/:name。如果环境变量里有配置scale_from_zero为true，先用MakeScalingHandler()方法对proxyHandler进行一次包装。\nMakeScalingHandler接受参数主要是：\n next：就是下一个httpHandlerFunc，中间件都会有这样一个参数\n config：ScalingConfig的对象：\n// ScalingConfig for scaling behaviours type ScalingConfig struct { MaxPollCount uint // 查到的最大数量 \tFunctionPollInterval time.Duration // 函数调用时间间隔 \tCacheExpiry time.Duration // 缓存过期时间 \tServiceQuery ServiceQuery // 外部服务调用的一个接口 }  这个MakeScalingHandler中间件主要做了如下的事情：\n 先从FunctionCache缓存中获取该函数的基本信息，从这个缓存可以拿到每个函数的副本数量。 为了加快函数的启动速度，如果缓存中可以获该得函数，且函数的副本数大于0，满足条件，return即可。 如果不满足上一步，就会调用SetReplicas方法设置副本数，并更新FunctionCache的缓存。\n// MakeScalingHandler creates handler which can scale a function from // zero to 1 replica(s). func MakeScalingHandler(next http.HandlerFunc, upstream http.HandlerFunc, config ScalingConfig) http.HandlerFunc { cache := FunctionCache{ Cache: make(map[string]*FunctionMeta), Expiry: config.CacheExpiry, } return func(w http.ResponseWriter, r *http.Request) { functionName := getServiceName(r.URL.String()) if serviceQueryResponse, hit := cache.Get(functionName); hit \u0026amp;\u0026amp; serviceQueryResponse.AvailableReplicas \u0026gt; 0 { next.ServeHTTP(w, r) return } queryResponse, err := config.ServiceQuery.GetReplicas(functionName) cache.Set(functionName, queryResponse) // 省略错误处理 \tif queryResponse.AvailableReplicas == 0 { minReplicas := uint64(1) if queryResponse.MinReplicas \u0026gt; 0 { minReplicas = queryResponse.MinReplicas } err := config.ServiceQuery.SetReplicas(functionName, minReplicas) // 省略错误处理代码 \tfor i := 0; i \u0026lt; int(config.MaxPollCount); i++ { queryResponse, err := config.ServiceQuery.GetReplicas(functionName) cache.Set(functionName, queryResponse) // 省略错误处理 \ttime.Sleep(config.FunctionPollInterval) } } next.ServeHTTP(w, r) } }  监控 监控是一个定时任务，开启了一个新协程，利用go的ticker.C的间隔不停的去调用/system/functions接口。反序列化到MetricOptions对象中。\nfunc AttachExternalWatcher(endpointURL url.URL, metricsOptions MetricOptions, label string, interval time.Duration) { ticker := time.NewTicker(interval) quit := make(chan struct{}) proxyClient := // 省略创建一个http.Client对象  go func() { for { select { case \u0026lt;-ticker.C: get, _ := http.NewRequest(http.MethodGet, endpointURL.String()+\u0026#34;system/functions\u0026#34;, nil) services := []requests.Function{} res, err := proxyClient.Do(get) // 省略反序列的代码 \tfor _, service := range services { metricsOptions.ServiceReplicasCounter. WithLabelValues(service.Name). Set(float64(service.Replicas)) } break case \u0026lt;-quit: return } } }() } UI UI的代码很简单，主要就是一些前端的代码，调用上面的讲的一些API接口即可，这里就略去不表。\n总结 Gateway是OpenFaaS最为重要的一个组件。回过头看整个项目的结构，Gateway就是一个rest转发服务，一个一个的handler，每个模块之间的耦合性不是很高，可以很容易的去拆卸，自定义实现相应的模块。\n","title":"第 16 期 gateway-reading"},{"location":"https://bytemode.github.io/reading/other/16-2018-09-06-quick-start/","text":"创建一个新函数\nfaas-cli new --lang node hell-node  构建函数\nfaas-cli build -f hello-node.yml  推送函数到docker仓库\nfaas-cli push -f hello-node.yml  部署函数\nfaas-cli deploy -f hello-node.yml  稍等几秒钟，等待部署，然后就可以从postman发送get或者post请求。\n在rancher中的状态\n函数的状态\n","title":"第 16 期 Go 快速入门"},{"location":"https://bytemode.github.io/reading/other/16-2018-09-06-faas-provider/","text":" faas-provider是一个模板，只要实现了这个模板的接口，就可以自定义实现自己的provider。\nfaas-provider OpenFaaS官方提供了两套后台provider：\n Docker Swarm Kubernetes  这两者在部署和调用函数的时候流程图如下：\n部署一个函数\n调用一个函数\nprovider要提供的一些API有：\n List / Create / Delete 一个函数  /system/functions\n方法: GET / POST / DELETE\n 获取一个函数  /system/function/{name:[-a-zA-Z_0-9]+}\n方法: GET\n 伸缩一个函数  /system/scale-function/{name:[-a-zA-Z_0-9]+}\n方法: POST\n 调用一个函数  /function/{name:[-a-zA-Z_0-9]+}\n方法: POST\n在provider的server.go的serve方法，可以看到这个serve方法创建了几个路由，接受一个FaaSHandler对象。\n// Serve load your handlers into the correct OpenFaaS route spec. This function is blocking. func Serve(handlers *types.FaaSHandlers, config *types.FaaSConfig) { r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.FunctionReader).Methods(\u0026#34;GET\u0026#34;) r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.DeployHandler).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.DeleteHandler).Methods(\u0026#34;DELETE\u0026#34;) r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.UpdateHandler).Methods(\u0026#34;PUT\u0026#34;) r.HandleFunc(\u0026#34;/system/function/{name:[-a-zA-Z_0-9]+}\u0026#34;, handlers.ReplicaReader).Methods(\u0026#34;GET\u0026#34;) r.HandleFunc(\u0026#34;/system/scale-function/{name:[-a-zA-Z_0-9]+}\u0026#34;, handlers.ReplicaUpdater).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/function/{name:[-a-zA-Z_0-9]+}\u0026#34;, handlers.FunctionProxy) r.HandleFunc(\u0026#34;/function/{name:[-a-zA-Z_0-9]+}/\u0026#34;, handlers.FunctionProxy) r.HandleFunc(\u0026#34;/system/info\u0026#34;, handlers.InfoHandler).Methods(\u0026#34;GET\u0026#34;) if config.EnableHealth { r.HandleFunc(\u0026#34;/healthz\u0026#34;, handlers.Health).Methods(\u0026#34;GET\u0026#34;) } // 省略 } 因此在自定义的provider，只需实现FaaSHandlers中的几个路由处理函数即可。这几个handler是：\n// FaaSHandlers provide handlers for OpenFaaS type FaaSHandlers struct { FunctionReader http.HandlerFunc DeployHandler http.HandlerFunc DeleteHandler http.HandlerFunc ReplicaReader http.HandlerFunc FunctionProxy http.HandlerFunc ReplicaUpdater http.HandlerFunc // Optional: Update an existing function \tUpdateHandler http.HandlerFunc Health http.HandlerFunc InfoHandler http.HandlerFunc } 我们以官方实现的faas-netes为例，讲解一下这几个hander的实现过程。\nfaas-netes 我们看下在faas-netes的中的FaaSHandlers实现：\nbootstrapHandlers := bootTypes.FaaSHandlers{ FunctionProxy: handlers.MakeProxy(functionNamespace, cfg.ReadTimeout), DeleteHandler: handlers.MakeDeleteHandler(functionNamespace, clientset), DeployHandler: handlers.MakeDeployHandler(functionNamespace, clientset, deployConfig), FunctionReader: handlers.MakeFunctionReader(functionNamespace, clientset), ReplicaReader: handlers.MakeReplicaReader(functionNamespace, clientset), ReplicaUpdater: handlers.MakeReplicaUpdater(functionNamespace, clientset), UpdateHandler: handlers.MakeUpdateHandler(functionNamespace, clientset), Health: handlers.MakeHealthHandler(), InfoHandler: handlers.MakeInfoHandler(version.BuildVersion(), version.GitCommit), } 因为是Kubernetes上的provider实现，所以这些函数都带有一个namespace的参数。\nFunctionProxy 这里最重要的就是FunctionProxy，它主要负责调用函数。这个handler其实也是起到了一个代理转发的作用，在这个函数中，只接受get和post。调用函数只接受post和get请求\n 创建一个http的client对象\n 只处理get和post请求。\n 组装代理转发的watchdog的地址\nurl := forwardReq.ToURL(fmt.Sprintf(\u0026#34;%s.%s\u0026#34;, service, functionNamespace), watchdogPort)  所以最后请求的格式就会形如：\n http://函数名.namespace:监视器的端口/路径   将请求发出去\n 设置http响应的头\n  ReplicaReader和ReplicaUpdater 这两个是和副本数相关的，所以放在一起对比讲解。这两个的实现依赖于Kubernetes的客户端，获取代码如下：\nclientset, err := kubernetes.NewForConfig(config) 这个config主要满足以下几个条件就行：\nConfig{ // TODO: switch to using cluster DNS. \tHost: \u0026#34;https://\u0026#34; + net.JoinHostPort(host, port), BearerToken: string(token), TLSClientConfig: tlsClientConfig, } Kubernetes的所有操作都可以通过rest api来完成，这两个handler也是通过调用Kubernetes的api来做的。\nReplicaReader MakeReplicaReader函数是获取当前的副本数：\n 通过mux从路由中获取到name参数\n 调用getService方法获取副本数，getService的核心代码就一句：\nitem, err := clientset.ExtensionsV1beta1().Deployments(functionNamespace).Get(functionName, getOpts) 序列化之后，把结果返回\n  ReplicaUpdater MakeReplicaUpdater是解析从gateway传过来的post请求，调用k8s的API设置副本数。\n 从请求中取出body\n 首先获取该函数的已部署的deployment对象\n 然后将deployment的副本数量设置为应设数量，这样做的目的是为了仅仅修改副本数，而不修改别的属性。\n_, err = clientset.ExtensionsV1beta1().Deployments(functionNamespace).Update(deployment)   注：mux做路由的时候，如果成功的时候不对w做任何处理，是会默认状态码为200，空字符串。\n DeleteHandler，DeployHandler，FunctionReader和UpdateHandler 这几个都是对函数的操作，其实就是调用一下Kubernetes的API进行操作。\n这几个是核心的几句代码：\nclientset.ExtensionsV1beta1().Deployments(functionNamespace).Delete(request.FunctionName, opts) deploy := clientset.Extensions().Deployments(functionNamespace) res, err := clientset.ExtensionsV1beta1().Deployments(functionNamespace).List(listOpts) _, updateErr := clientset.CoreV1().Services(functionNamespace).Update(service) 总结 官方还提供了一个faas-swarm，其实现思路也是这样，操作swarm的api来做对容器的操作。至于如何调用一个函数，都是在函数的watchdog中实现。\n","title":"第16期 faas-provider"},{"location":"https://bytemode.github.io/reading/other/16-2018-09-06-openfaas-guide/","text":" 关于我 网名： Lucas\nGithub：https://github.com/zhenfeng-zhu\n博客：https://zhenfeng-zhu.github.io/\n知乎：https://www.zhihu.com/people/zhu-zhen-feng-96/activities\n专栏：https://zhuanlan.zhihu.com/openfaas-cn\n微信：zhuzhenfeng1993\n主要内容  OpenFaaS的简介\n OpenFaaS的快速入门\n OpenFaaS的基础组件\n OpenFaaS的源码分析\n OpenFaaS的定制\n  观看视频   ","title":"第16期 OpenFaas 介绍及源码分析"},{"location":"https://bytemode.github.io/reading/other/16-2018-09-06-queue-worker/","text":" 异步函数和同步函数 在OpenFaaS中同步调用函数时，将会连接到网关，直到函数成功返回才会关闭连接。同步调用是阻塞的。\n 网关的路由是：/function/\u0026lt;function_name\u0026gt; 必须等待 在结束的时候得到结果 明确知道是成功还是失败  异步函数会有一些差异：\n 网关的路由是：/async-function/\u0026lt;function_name\u0026gt; 客户端获得202的即时响应码 从queue-worker中调用函数 默认情况下，结果是被丢弃的。  查看queue-worker的日志 docker service logs -f func_queue-worker 利用requestbin和X-Callback-Url获取异步函数的结果 如果需要获得异步函数的结果，有两个方法：\n 更改代码，将结果返回给端点或者消息系统 利用内置的回调 内置的回调将会允许函数提供一个url，queue-worker会报告函数的成功或失败。 requestbin会创建一个新的bin，这是互联网的一个url地址，可以从这里获取函数的结果。  源码分析 依赖项 github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/faas go-nats和go-nats-streaming是nats和nats-streaming的go版本的客户端。\nfaas这个依赖其实是只用到了queue包下面的types.go文件。这个文件是定义了异步请求的Request结构体和一个CanQueueRequests接口。如下所示：\npackage queue import \u0026#34;net/url\u0026#34; import \u0026#34;net/http\u0026#34; // Request for asynchronous processing type Request struct { Header http.Header Body []byte Method string QueryString string Function string CallbackURL *url.URL `json:\u0026#34;CallbackUrl\u0026#34;` } // CanQueueRequests can take on asynchronous requests type CanQueueRequests interface { Queue(req *Request) error } 从这里我们就可以明白作者的设计思路，只要是实现了这个CanQueueRequests接口，就可以作为一个queue-worker。\n接口实现类NatsQueue 接口的实现类NatsQueue是在handler包里。它的属性都是nats中常用到的，包括clientId，clusterId，url，连接，主题等，如下所示：\n// NatsQueue queue for work type NatsQueue struct { nc stan.Conn // nats的连接  ClientID string // nats的clientId  ClusterID string // nats的clusterId  NATSURL string // nats的URL  Topic string // 主题 } 它的queue方法也很简单，主要做了两件事儿：\n 解析传入的Request对象，并转为json对象out 将out发布到队列里\n// Queue request for processing func (q *NatsQueue) Queue(req *queue.Request) error { var err error fmt.Printf(\u0026#34;NatsQueue - submitting request: %s.\\n\u0026#34;, req.Function) out, err := json.Marshal(req) if err != nil { log.Println(err) } err = q.nc.Publish(q.Topic, out) return err }  go语言没有构造方法，所以NatsQueue还用于创建NatsQueue的实例的方法，这里就成为工厂方法。这个工厂方法主要就是从配置文件中读取环境变量的值，然后创建一个nats的连接，相当于给NatsQueue的对象的每个属性进行赋值。\nfunc CreateNatsQueue(address string, port int, clientConfig NatsConfig) (*NatsQueue, error) { queue1 := NatsQueue{} var err error natsURL := fmt.Sprintf(\u0026#34;nats://%s:%d\u0026#34;, address, port) log.Printf(\u0026#34;Opening connection to %s\\n\u0026#34;, natsURL) clientID := clientConfig.GetClientID() clusterID := \u0026#34;faas-cluster\u0026#34; nc, err := stan.Connect(clusterID, clientID, stan.NatsURL(natsURL)) queue1.nc = nc return \u0026amp;queue1, err } 这个CreateNatsQueue方法是Gateway项目中进行调用，我们可以在Gateway项目的main.go中找到，如果Gateway的配置开启了异步函数支持，就会调用该方法，创建一个NatsQueue对象，然后把函数放到队列中，这里就不深入讲解：\nif config.UseNATS() { log.Println(\u0026#34;Async enabled: Using NATS Streaming.\u0026#34;) natsQueue, queueErr := natsHandler.CreateNatsQueue(*config.NATSAddress, *config.NATSPort, natsHandler.DefaultNatsConfig{}) if queueErr != nil { log.Fatalln(queueErr) } faasHandlers.QueuedProxy = handlers.MakeQueuedProxy(metricsOptions, true, natsQueue) faasHandlers.AsyncReport = handlers.MakeAsyncReport(metricsOptions) } 到这里，我相信读者也了解到，Gateway其实就是一个发布者，将异步请求扔到队列里。接下来肯定要有一个订阅者将请求消费处理。\n订阅者处理 我们都知道，nats streaming的订阅者订阅到消息之后，会把消息扔给一个回调函数去处理。queue-worker的订阅者实现也是这样，它的实现并不复杂，所有逻辑都在main.go的中。\n我们先看回调函数mcb都做了什么：\n 首先当然是将消息体反序列化成上面说到的用于异步处理的Request对象。 构造http请求的url和querystring，url的格式如下： functionURL := fmt.Sprintf(\u0026ldquo;http://%s%s:8080/%s\u0026rdquo;, req.Function, config.FunctionSuffix, queryString) 设置http的header，并以post的形式向functionURL发起请求。 如果请求失败，设置返回状态码为http.StatusServiceUnavailable，并分别处理CallbackURL是否存在的情况。 如果请求成功，同样也是要分别处理CallbackURL是否存在的情况。  当然在这个callback中会根据一些环境变量的存在，选择是否打印日志出来。\nmcb := func(msg *stan.Msg) { i++ printMsg(msg, i) started := time.Now() req := queue.Request{} unmarshalErr := json.Unmarshal(msg.Data, \u0026amp;req) if unmarshalErr != nil { log.Printf(\u0026#34;Unmarshal error: %s with data %s\u0026#34;, unmarshalErr, msg.Data) return } fmt.Printf(\u0026#34;Request for %s.\\n\u0026#34;, req.Function) if config.DebugPrintBody { fmt.Println(string(req.Body)) } queryString := \u0026#34;\u0026#34; if len(req.QueryString) \u0026gt; 0 { queryString = fmt.Sprintf(\u0026#34;?%s\u0026#34;, strings.TrimLeft(req.QueryString, \u0026#34;?\u0026#34;)) } functionURL := fmt.Sprintf(\u0026#34;http://%s%s:8080/%s\u0026#34;, req.Function, config.FunctionSuffix, queryString) request, err := http.NewRequest(http.MethodPost, functionURL, bytes.NewReader(req.Body)) defer request.Body.Close() copyHeaders(request.Header, \u0026amp;req.Header) res, err := client.Do(request) var status int var functionResult []byte if err != nil { status = http.StatusServiceUnavailable log.Println(err) timeTaken := time.Since(started).Seconds() if req.CallbackURL != nil { log.Printf(\u0026#34;Callback to: %s\\n\u0026#34;, req.CallbackURL.String()) resultStatusCode, resultErr := postResult(\u0026amp;client, res, functionResult, req.CallbackURL.String()) if resultErr != nil { log.Println(resultErr) } else { log.Printf(\u0026#34;Posted result: %d\u0026#34;, resultStatusCode) } } statusCode, reportErr := postReport(\u0026amp;client, req.Function, status, timeTaken, config.GatewayAddress) if reportErr != nil { log.Println(reportErr) } else { log.Printf(\u0026#34;Posting report - %d\\n\u0026#34;, statusCode) } return } if res.Body != nil { defer res.Body.Close() resData, err := ioutil.ReadAll(res.Body) functionResult = resData if err != nil { log.Println(err) } if config.WriteDebug { fmt.Println(string(functionResult)) } else { fmt.Printf(\u0026#34;Wrote %d Bytes\\n\u0026#34;, len(string(functionResult))) } } timeTaken := time.Since(started).Seconds() fmt.Println(res.Status) if req.CallbackURL != nil { log.Printf(\u0026#34;Callback to: %s\\n\u0026#34;, req.CallbackURL.String()) resultStatusCode, resultErr := postResult(\u0026amp;client, res, functionResult, req.CallbackURL.String()) if resultErr != nil { log.Println(resultErr) } else { log.Printf(\u0026#34;Posted result: %d\u0026#34;, resultStatusCode) } } statusCode, reportErr := postReport(\u0026amp;client, req.Function, res.StatusCode, timeTaken, config.GatewayAddress) if reportErr != nil { log.Println(reportErr) } else { log.Printf(\u0026#34;Posting report - %d\\n\u0026#34;, statusCode) } } postResult函数是用来处理callbackURL存在的情况，在这个函数中将结果，以post请求调用callbackURL发送出去。\npostReport函数用来处理callbackURL不存在的情况，这里是将结果发到Gateway网关的\u0026quot;http://\u0026quot; + gatewayAddress + \u0026quot;:8088/system/async-report\u0026quot;中，我们之后就可以从这个url里查询异步函数的执行结果了。\n总结 本文主要分析了NATS Streaming版本的queue worker的实现，通过分析源码我们可以看到OpenFaaS在架构的设计很有考究，充分的考虑到了可扩展性，通过定义接口规范，使得开发者很容易实现自定义。\n","title":"第16期 queue-worker源码分析"},{"location":"https://bytemode.github.io/reading/other/16-2018-09-06-watchdog/","text":" 监视器\n监视器提供了一个外部世界和函数之间的非托管的通用接口。它的工作是收集从API网关来的HTTP请求，然后调用程序。监视器是一个小型的Golang服务——下图展示了它是如何工作的：\n 上图：一个小型的web服务，可以为每个传入的HTTP请求分配所需要的进程。\n 每个函数都需要嵌入这个二进制文件并将其作为ENTRYPOINT 或 CMD，实际上是把它作为容器的初始化进程。一旦你的进程被创建分支，监视器就会通过stdin 传递HTTP请求并从stdout中读取HTTP响应。这意味着你的程序无需知道web和HTTP的任何信息。\n轻松创建新函数 从CLI创建一个函数\n创建函数最简单的方法是使用FaaS CLI和模板。CLI抽象了所有Docker的知识，使得你只需要编写所支持语言的handler文件即可。\n 你的第一个使用OpenFaaS的无服务器Python函数 阅读有关FaaS CLI的教程  深入研究 Package your function打包你的函数\n如果你不想使用CLI或者现有的二进制文件或镜像，可以使用下面的方法去打包函数：\n 使用一个现有的或者一个新的Docker镜像作为基础镜像 FROM 通过curl 或 ADD https://从 Releases 页面 添加fwatchdog二进制文件 为每个你要运行的函数设置 fprocess(函数进程) 环境变量 Expose port 8080 暴露端口8080 Set the CMD to fwatchdog 设置 CMD为fwatchdog  一个echo函数的示例Dockerfile：\nFROM alpine:3.7 ADD https://github.com/openfaas/faas/releases/download/0.8.0/fwatchdog /usr/bin RUN chmod +x /usr/bin/fwatchdog # Define your binary here ENV fprocess=\u0026#34;/bin/cat\u0026#34; CMD [\u0026#34;fwatchdog\u0026#34;] Implementing a Docker healthcheck实现一个Docker健康检查\nDocke的健康检查不是必需的，但是它是最佳实践。这会确保监视器已经在API网关转发请求之前准备好接收请求。如果函数或者监视器遇到一个不可恢复的问题，Swarm也会重启容器。\nHere is an example of the echo function implementing a healthcheck with a 5-second checking interval.\n下面是实现了一个具有5秒间隔的健康检查的echo函数示例：\nFROM functions/alpine ENV fprocess=\u0026#34;cat /etc/hostname\u0026#34; HEALTHCHECK --interval=5s CMD [ -e /tmp/.lock ] || exit 1 监视器进程早启动内部Golang HTTP服务的时候会在 /tmp/下面创建一个.lock文件。[ -e file_name ]shell命令可以检查文件是否存在。在Windows容器中，这是一个不合法的路径，所以你可能需要设置suppress_lock 环境变量。\n有关健康检查，请阅读我的Docker Swarm教程：\n 10分钟内试用Docker的健康检查  环境变量重载:\n监视器可以通过环境变量来配置，你必须始终指定一个fprocess 变量\n高级/调整 (新)——子监视器和HTTP模式  部分的监视器  为每个请求创建一个新的进程分支具有进程隔离，可移植和简单的优点。任何进程都可以在没有任何附加代码的情况下变成一个函数。of-watchdog可和HTTP模式是一种优化，这样就可以在所有请求之间维护一个单一的进程。\n新版本的监视器正在openfaas-incubator/of-watchdog上测试。\n这种重写主要是生成一个可以持续维护的结构。它将会替代现有的监视器，也会有二进制的释放版。\n使用HTTP头 HTTP的头和其他请求信息以下面的格式注入到环境变量中：\nX-Forwarded-By`头变成了`Http_X_Forwarded_By   Http_Method - GET/POST etc Http_Method - GET/POST 等等 Http_Query - QueryString value Http_Query - 查询字符串的值 Http_ContentLength - gives the total content-length of the incoming HTTP request received by the watchdog. Http_ContentLength - 监视器收到的HTTP请求的内容长度。   默认情况下，通过cgi_headers 环境变量启用该行为。\n 以下是带有附加头和查询字符串的POST请求的示例：\n$ cgi_headers=true fprocess=env ./watchdog \u0026amp; 2017/06/23 17:02:58 Writing lock-file to: /tmp/.lock $ curl \u0026#34;localhost:8080?q=serverless\u0026amp;page=1\u0026#34; -X POST -H X-Forwarded-By:http://my.vpn.com 如果你再Linux系统下设置了fprocess 到 env中，会看到如下结果：\nHttp_User_Agent=curl/7.43.0 Http_Accept=*/* Http_X_Forwarded_By=http://my.vpn.com Http_Method=POST Http_Query=q=serverless\u0026amp;page=1 也可以使用GET请求：\n$ curl \u0026#34;localhost:8080?action=quote\u0026amp;qty=1\u0026amp;productId=105\u0026#34; 监视器的输出如下：\nHttp_User_Agent=curl/7.43.0 Http_Accept=*/* Http_Method=GET Http_Query=action=quote\u0026amp;qty=1\u0026amp;productId=105 现在就可以在程序中使用HTTP状态来做决策了。\nHTTP方法 监视器支持的HTTP方法有：\n带有请求体的：\n POST, PUT, DELETE, UPDATE  不带请求体的：\n GET   API网关现在支持函数的POST路由。\n 请求响应的内容类型 默认情况下，监视器会匹配客户端的\u0026rdquo;Content-Type\u0026rdquo;。\n 如果客户端发送Content-Type 为 application/json 的json形式的post请求，将会在响应的时候自动匹配。 如果客户端发送Content-Type 为 text/plain 的json形式的post请求，响应也会自动匹配。  若要重载所有响应的Content-Type ，需要设置content_type 环境变量。\nI don\u0026rsquo;t want to use the watchdog 我不想使用监视器 这种案例是OpenFaaS所不支持的，但是如果你的容器符合以下要求，那么OpenFaaS的网关和其他工具也会管理和伸缩服务。\n你需要提供一个锁文件 /tmp/.lock，以便业务流程系统可以在容器中运行健康检查。如果你正在使用swarm，那么请确保在Dockerfile中提供HEALTHCHECK指令——在 faas存储库中有示例。\n 在HTTP之上暴露TCP端口8080 创建/tmp/.lock 文件，或者在响应操作tempdir系统调用的任何位置。  调整自动伸缩 自动伸缩式从1个副本开始，以5个位一个单位进行升级：\n 1-\u0026gt;5 5-\u0026gt;10 10-\u0026gt;15 15-\u0026gt;20  你可以通过标签来覆盖一个函数minimum 和 maximum 。\n如果要在2到15之间的话，请在部署的时候配置以下标签：\ncom.openfaas.scale.min: \u0026#34;2\u0026#34; com.openfaas.scale.max: \u0026#34;15\u0026#34; 这些标签是可选的\n禁用自动伸缩\n如果要禁用某个函数的自动伸缩，将最小和最大的副本数设置为相同的值，即“1”。\n同样也可以删除AlertManager。\n","title":"第16期 监视器 - watchdog"},{"location":"https://bytemode.github.io/reading/15-2018-08-23-pool-workshop-in-go/","text":"  2018-08-23 22:00:00 分享会之后的答疑。\n 源代码地址：pool#workshop\n一个网友在分享会之后的个人理解：对是独占资源对象的复用，提升了最后的 qps，独占式方法 TestChanPool() 函数中使用了从资源池获取 worker 对象，执行完毕后再放回资源池，如果获取不到则阻塞等待，因此，100 000 请求，每个请求占用 10ms，可用 worker 对象 50 个，则最后 100 000*10/50 =20s ,视频中测试结果也显示 21s 符合预期。而 TestWorkshop() 函数中使用回调函数对 worker 进行加锁，每个线程使用的那一刻是 worker 对象是被独占的，而后续的 do{sleep(10ms)} 是并发执行的，并且根据每个 worker 同时执行的 do 的任务数，进行负载均衡，所以最后测试性能 QPS 能够有 20 倍的提升。\n workshop 中每个协程只在获得 worker 的那一刻是互斥的，且不会从池子中移除，通过状态统计达到资源的负载均衡。在业务上真正使用资源时其实是无锁状态，所以能被其他协程同时使用，进而吞吐量提升。业务逻辑耗时越长，相比独占式资源池的吞吐量优势越显著。本机测试 50 个资源 10ms 时可提升 20 倍。\n 为什么不使用轮询使用资源，代码实现会更简单？  实际场景中每次业务逻辑耗时不相同，轮询并不能保证真的负载均衡。尤其是当突发异常时，可能导致负载失衡。\n 为什么长连接异步通信不使用一条连接而是连接池？ 说到长连接异步通信，为什么不使用一条连接而是连接池，其实涉及到多条连接抢占带宽和 TCP 丢包后速率下降的问题。这对于下载场景（迅雷就是这么做的）和使用共享云主机的场景比较有用。 具体可以看这篇文章：为什么多 TCP 连接比单TCP连接传输快\n 以前在做加速的一项就是多线程下载，开启多个 tcp 连接，同时下载，比只有一个连接下载快多了。\n workshop 的使用场景 使用 workshop 的前提就是该资源可以被同时使用，比如长连接的异步IO通信。\n对于长连接异步通信时，如果使用了独占式连接池只会起到反效果，让它和同步通信没差别，还不如不用池子。workshop 就是适用于这个场景的。\n长连接：同步和异步方式。 同步方式下客户端所有请求共用同一连接，在获得连接后要对连接加锁，在读写结束后才解锁释放连接，性能低下，基本很少采用，唯一优点是实现极其简单。\n异步方式下所有请求都带有消息ID，因此可以批量发送请求，异步接收回复，所有请求和回复的消息都共享同一连接，信道得到最大化利用，因此吞吐量最大。\n这个时候接收端的处理能力也要求比较高，一般都是独立的一个（或者多个）收包线程（或者进程）防止内核缓冲区被填满影响网络吞吐量。缺点是实现复杂，需要异步状态机，需要增加负载均衡和连接健康度检测机制，等等。\nworkshop 就是实现了上述多条异步连接间的负载均衡，健康检测等。\n观看视频   参考资料  为什么多 TCP 连接比单TCP连接传输快  ","title":"第 15 期 多路复用资源池组件剖析"},{"location":"https://bytemode.github.io/reading/14-2018-08-17-sync-pool-reading/","text":" Go 标准包阅读\n观看视频   ","title":"第 14 期 sync.Pool 源码分析及适用场景"},{"location":"https://bytemode.github.io/reading/13-2018-08-09-kubernetes-guide/","text":" 观看视频   ","title":"第 13 期 Kubernetes 入门指南"},{"location":"https://bytemode.github.io/reading/12-2018-08-02-goroutine-gpm/","text":" 郑宝杨(boya) 2018-08-01 listomebao@gmail.com\n阅读源码前可以阅读的资料  Goroutine背后的系统知识 golang源码剖析-雨痕老师 go-intervals 也谈goroutine调度器  golang的调度模型概览 调度的机制用一句话描述：\nruntime准备好G,P,M，然后M绑定P，M从各种队列中获取G，切换到G的执行栈上并执行G上的任务函数，调用goexit做清理工作并回到M，如此反复。\n基本概念 M（machine）  M代表着真正的执行计算资源，可以认为它就是os thread（系统线程）。 M是真正调度系统的执行者，每个M就像一个勤劳的工作者，总是从各种队列中找到可运行的G，而且这样M的可以同时存在多个。 M在绑定有效的P后，进入调度循环，而且M并不保留G状态，这是G可以跨M调度的基础。  P（processor）  P表示逻辑processor，是线程M的执行的上下文。 P的最大作用是其拥有的各种G对象队列、链表、cache和状态。  G（goroutine）  调度系统的最基本单位goroutine，存储了goroutine的执行stack信息、goroutine状态以及goroutine的任务函数等。 在G的眼中只有P，P就是运行G的“CPU”。 相当于两级线程  线程实现模型 来自Go并发编程实战\n +-------+ +-------+ | KSE | | KSE | +-------+ +-------+ | | 内核空间 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - | | 用户空间 +-------+ +-------+ | M | | M | +-------+ +-------+ | | | | +------+ +------+ +------+ +------+ | P | | P | | P | | P | +------+ +------+ +------+ +------+ | | | | | | | | | +---+ +---+ +---+ +---+ +---+ +---+ +---+ +---+ +---+ | G | | G | | G | | G | | G | | G | | G | | G | | G | +---+ +---+ +---+ +---+ +---+ +---+ +---+ +---+ +---+   KSE（Kernel Scheduling Entity）是内核调度实体\n M与P，P与G之前的关联都是动态的，可以变的  关系示意图 来自golang源码剖析\n +-------------------- sysmon ---------------//------+ | | | | +---+ +---+-------+ +--------+ +---+---+ go func() ---\u0026gt; | G | ---\u0026gt; | P | local | \u0026lt;=== balance ===\u0026gt; | global | \u0026lt;--//--- | P | M | +---+ +---+-------+ +--------+ +---+---+ | | | | +---+ | | +----\u0026gt; | M | \u0026lt;--- findrunnable ---+--- steal \u0026lt;--//--+ +---+ | mstart | +--- execute \u0026lt;----- schedule | | | | +--\u0026gt; G.fn --\u0026gt; goexit --+ 1. go func() 语气创建G。 2. 将G放入P的本地队列（或者平衡到全局全局队列）。 3. 唤醒或新建M来执行任务。 4. 进入调度循环 5. 尽力获取可执行的G，并执行 6. 清理现场并且重新进入调度循环  GPM的来由 特殊的g0和m0 g0和m0是在proc.go文件中的两个全局变量，m0就是进程启动后的初始线程，g0也是代表着初始线程的stack\nasm_amd64.go \u0026ndash;\u0026gt; runtime·rt0_go(SB)\n// 程序刚启动的时候必定有一个线程启动（主线程） \t// 将当前的栈和资源保存在g0 \t// 将该线程保存在m0 \t// tls: Thread Local Storage \t// set the per-goroutine and per-mach \u0026#34;registers\u0026#34; \tget_tls(BX) LEAQ\truntime·g0(SB), CX MOVQ\tCX, g(BX) LEAQ\truntime·m0(SB), AX // save m-\u0026gt;g0 = g0 \tMOVQ\tCX, m_g0(AX) // save m0 to g0-\u0026gt;m \tMOVQ\tAX, g_m(CX) M的一生 M的创建 proc.go\n// Create a new m. It will start off with a call to fn, or else the scheduler. // fn needs to be static and not a heap allocated closure. // May run with m.p==nil, so write barriers are not allowed. //go:nowritebarrierrec // 创建一个新的m，它将从fn或者调度程序开始 func newm(fn func(), _p_ *p) { // 根据fn和p和绑定一个m对象 \tmp := allocm(_p_, fn) // 设置当前m的下一个p为_p_ \tmp.nextp.set(_p_) mp.sigmask = initSigmask ... // 真正的分配os thread \tnewm1(mp) }func newm1(mp *m) { // 对cgo的处理 \t... execLock.rlock() // Prevent process clone. \t// 创建一个系统线程 \tnewosproc(mp, unsafe.Pointer(mp.g0.stack.hi)) execLock.runlock() } 状态  mstart | v 找不到可执行任务，gc STW， +------+ 任务执行时间过长，系统阻塞等 +------+ | spin | ----------------------------\u0026gt; |unspin| +------+ mstop +------+ ^ | | v notewakeup \u0026lt;------------------------- notesleep  M的一些问题 https://github.com/golang/go/issues/14592\nP的一生 P的创建 proc.go\n// Change number of processors. The world is stopped, sched is locked. // gcworkbufs are not being modified by either the GC or // the write barrier code. // Returns list of Ps with local work, they need to be scheduled by the caller. // 所有的P都在这个函数分配，不管是最开始的初始化分配，还是后期调整 func procresize(nprocs int32) *p { old := gomaxprocs // 如果 gomaxprocs \u0026lt;=0 抛出异常 \tif old \u0026lt; 0 || nprocs \u0026lt;= 0 { throw(\u0026#34;procresize: invalid arg\u0026#34;) } ... // Grow allp if necessary. \tif nprocs \u0026gt; int32(len(allp)) { // Synchronize with retake, which could be running \t// concurrently since it doesn\u0026#39;t run on a P. \tlock(\u0026amp;allpLock) if nprocs \u0026lt;= int32(cap(allp)) { allp = allp[:nprocs] } else { // 分配nprocs个*p \tnallp := make([]*p, nprocs) // Copy everything up to allp\u0026#39;s cap so we \t// never lose old allocated Ps. \tcopy(nallp, allp[:cap(allp)]) allp = nallp } unlock(\u0026amp;allpLock) } // initialize new P\u0026#39;s \tfor i := int32(0); i \u0026lt; nprocs; i++ { pp := allp[i] if pp == nil { pp = new(p) pp.id = i pp.status = _Pgcstop // 更改状态 \tpp.sudogcache = pp.sudogbuf[:0] //将sudogcache指向sudogbuf的起始地址 \tfor i := range pp.deferpool { pp.deferpool[i] = pp.deferpoolbuf[i][:0] } pp.wbBuf.reset() // 将pp保存到allp数组里, allp[i] = pp \tatomicstorep(unsafe.Pointer(\u0026amp;allp[i]), unsafe.Pointer(pp)) } ... } ... _g_ := getg() // 如果当前的M已经绑定P，继续使用，否则将当前的M绑定一个P \tif _g_.m.p != 0 \u0026amp;\u0026amp; _g_.m.p.ptr().id \u0026lt; nprocs { // continue to use the current P \t_g_.m.p.ptr().status = _Prunning } else { // release the current P and acquire allp[0] \t// 获取allp[0] \tif _g_.m.p != 0 { _g_.m.p.ptr().m = 0 } _g_.m.p = 0 _g_.m.mcache = nil p := allp[0] p.m = 0 p.status = _Pidle // 将当前的m和p绑定 \tacquirep(p) if trace.enabled { traceGoStart() } } var runnablePs *p for i := nprocs - 1; i \u0026gt;= 0; i-- { p := allp[i] if _g_.m.p.ptr() == p { continue } p.status = _Pidle if runqempty(p) { // 将空闲p放入空闲链表 \tpidleput(p) } else { p.m.set(mget()) p.link.set(runnablePs) runnablePs = p } } stealOrder.reset(uint32(nprocs)) var int32p *int32 = \u0026amp;gomaxprocs // make compiler check that gomaxprocs is an int32 \tatomic.Store((*uint32)(unsafe.Pointer(int32p)), uint32(nprocs)) return runnablePs } 所有的P在程序启动的时候就设置好了，并用一个allp slice维护，可以调用runtime.GOMAXPROCS调整P的个数，虽然代价很大\n状态转换  acquirep(p) 不需要使用的P P和M绑定的时候 进入系统调用 procresize() new(p) -----+ +---------------+ +-----------+ +------------+ +----------+ | | | | | | | | | | +------------+ +---v--------+ +---v--------+ +----v-------+ +--v---------+ +--\u0026gt;| _Pgcstop | | _Pidle | | _Prunning | | _Psyscall | | _Pdead | +------^-----+ +--------^---+ +--------^---+ +------------+ +------------+ | | | | | | +------------+ +------------+ +------------+ GC结束 releasep() 退出系统调用 P和M解绑  P的数量默认等于cpu的个数，很多人认为runtime.GOMAXPROCS可以限制系统线程的数量，但这是错误的，M是按需创建的，和runtime.GOMAXPROCS没有关系。\nG的一生 G的创建 proc.go\n// Create a new g running fn with siz bytes of arguments. // Put it on the queue of g\u0026#39;s waiting to run. // The compiler turns a go statement into a call to this. // Cannot split the stack because it assumes that the arguments // are available sequentially after \u0026amp;fn; they would not be // copied if a stack split occurred. //go:nosplit // 新建一个goroutine， // 􏳄 用fn + PtrSize 获取第一个参数的地址，也就是argp // 用siz - 8 获取pc地址 func newproc(siz int32, fn *funcval) { argp := add(unsafe.Pointer(\u0026amp;fn), sys.PtrSize) pc := getcallerpc() // 用g0的栈创建G对象 \tsystemstack(func() { newproc1(fn, (*uint8)(argp), siz, pc) }) }// Create a new g running fn with narg bytes of arguments starting // at argp. callerpc is the address of the go statement that created // this. The new g is put on the queue of g\u0026#39;s waiting to run. // 根据函数参数和函数地址，创建一个新的G，然后将这个G加入队列等待运行 func newproc1(fn *funcval, argp *uint8, narg int32, callerpc uintptr) { _g_ := getg() if fn == nil { _g_.m.throwing = -1 // do not dump full stacks \tthrow(\u0026#34;go of nil func value\u0026#34;) } _g_.m.locks++ // disable preemption because it can be holding p in a local var \tsiz := narg siz = (siz + 7) \u0026amp;^ 7 // We could allocate a larger initial stack if necessary. \t// Not worth it: this is almost always an error. \t// 4*sizeof(uintreg): extra space added below \t// sizeof(uintreg): caller\u0026#39;s LR (arm) or return address (x86, in gostartcall). \t// 如果函数的参数大小比2048大的话，直接panic \tif siz \u0026gt;= _StackMin-4*sys.RegSize-sys.RegSize { throw(\u0026#34;newproc: function arguments too large for new goroutine\u0026#34;) } // 从m中获取p \t_p_ := _g_.m.p.ptr() // 从gfree list获取g \tnewg := gfget(_p_) // 如果没获取到g，则新建一个 \tif newg == nil { newg = malg(_StackMin) casgstatus(newg, _Gidle, _Gdead) //将g的状态改为_Gdead \t// 添加到allg数组，防止gc扫描清除掉 \tallgadd(newg) // publishes with a g-\u0026gt;status of Gdead so GC scanner doesn\u0026#39;t look at uninitialized stack. \t} if newg.stack.hi == 0 { throw(\u0026#34;newproc1: newg missing stack\u0026#34;) } if readgstatus(newg) != _Gdead { throw(\u0026#34;newproc1: new g is not Gdead\u0026#34;) } totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame \ttotalSize += -totalSize \u0026amp; (sys.SpAlign - 1) // align to spAlign \tsp := newg.stack.hi - totalSize spArg := sp if usesLR { // caller\u0026#39;s LR \t*(*uintptr)(unsafe.Pointer(sp)) = 0 prepGoExitFrame(sp) spArg += sys.MinFrameSize } if narg \u0026gt; 0 { // copy参数 \tmemmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg)) // This is a stack-to-stack copy. If write barriers \t// are enabled and the source stack is grey (the \t// destination is always black), then perform a \t// barrier copy. We do this *after* the memmove \t// because the destination stack may have garbage on \t// it. \tif writeBarrier.needed \u0026amp;\u0026amp; !_g_.m.curg.gcscandone { f := findfunc(fn.fn) stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps)) // We\u0026#39;re in the prologue, so it\u0026#39;s always stack map index 0. \tbv := stackmapdata(stkmap, 0) bulkBarrierBitmap(spArg, spArg, uintptr(narg), 0, bv.bytedata) } } memclrNoHeapPointers(unsafe.Pointer(\u0026amp;newg.sched), unsafe.Sizeof(newg.sched)) newg.sched.sp = sp newg.stktopsp = sp // 保存goexit的地址到sched.pc \tnewg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function \tnewg.sched.g = guintptr(unsafe.Pointer(newg)) gostartcallfn(\u0026amp;newg.sched, fn) newg.gopc = callerpc newg.startpc = fn.fn if _g_.m.curg != nil { newg.labels = _g_.m.curg.labels } if isSystemGoroutine(newg) { atomic.Xadd(\u0026amp;sched.ngsys, +1) } newg.gcscanvalid = false // 更改当前g的状态为_Grunnable \tcasgstatus(newg, _Gdead, _Grunnable) if _p_.goidcache == _p_.goidcacheend { // Sched.goidgen is the last allocated id, \t// this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch]. \t// At startup sched.goidgen=0, so main goroutine receives goid=1. \t_p_.goidcache = atomic.Xadd64(\u0026amp;sched.goidgen, _GoidCacheBatch) _p_.goidcache -= _GoidCacheBatch - 1 _p_.goidcacheend = _p_.goidcache + _GoidCacheBatch } // 生成唯一的goid \tnewg.goid = int64(_p_.goidcache) _p_.goidcache++ if raceenabled { newg.racectx = racegostart(callerpc) } if trace.enabled { traceGoCreate(newg, newg.startpc) } // 将当前新生成的g，放入队列 \trunqput(_p_, newg, true) // 如果有空闲的p 且 m没有处于自旋状态 且 main goroutine已经启动，那么唤醒某个m来执行任务 \tif atomic.Load(\u0026amp;sched.npidle) != 0 \u0026amp;\u0026amp; atomic.Load(\u0026amp;sched.nmspinning) == 0 \u0026amp;\u0026amp; mainStarted { wakep() } _g_.m.locks-- if _g_.m.locks == 0 \u0026amp;\u0026amp; _g_.preempt { // restore the preemption request in case we\u0026#39;ve cleared it in newstack \t_g_.stackguard0 = stackPreempt } } G的状态图  +------------+ ready | | +------------------ | _Gwaiting | | | | | +------------+ | ^ park_m V | +------------+ +------------+ execute +------------+ +------------+ | | newproc | | ---------\u0026gt; | | goexit | | | _Gidle | ---------\u0026gt; | _Grunnable | yield | _Grunning | ---------\u0026gt; | _Gdead | | | | | \u0026lt;--------- | | | | +------------+ +-----^------+ +------------+ +------------+ | entersyscall | ^ | V | existsyscall | +------------+ | existsyscall | | +------------------ | _Gsyscall | | | +------------+  新建的G都是_Grunnable的，新建G的时候优先从gfree list从获取G，这样可以复用G，所以上图的状态不是完整的，_Gdead通过newproc会变为_Grunnable， 通过go func()的语法新建的G，并不是直接运行，而是放入可运行的队列中，什么时候运行用于并不能决定，而是搞调度系统去自发的运行。\n观看视频   ","title":"第 12 期 golang 中 goroutine 的调度"},{"location":"https://bytemode.github.io/interview/interview-golang-language/","text":"1.select是随机的还是顺序的？\n select会随机选择一个可用通道做收发操作\n 2.Go语言局部变量分配在栈还是堆？\n Go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。\n查看资料\n 3.简述一下你对Go垃圾回收机制的理解？\n v1.1 STW\nv1.3 Mark STW, Sweep 并行\nv1.5 三色标记法\nv1.8 hybrid write barrier(混合写屏障：优化STW)\nGolang垃圾回收剖析\n 4.简述一下golang的协程调度原理?\n M(machine): 代表着真正的执行计算资源，可以认为它就是os thread（系统线程）。\nP(processor): 表示逻辑processor，是线程M的执行的上下文。\nG(goroutine): 调度系统的最基本单位goroutine，存储了goroutine的执行stack信息、goroutine状态以及goroutine的任务函数等。\n查看资料\n 5.介绍下 golang 的 runtime 机制?\n Runtime 负责管理任务调度，垃圾收集及运行环境。同时，Go提供了一些高级的功能，如goroutine, channel, 以及Garbage collection。这些高级功能需要一个runtime的支持. runtime和用户编译后的代码被linker静态链接起来，形成一个可执行文件。这个文件从操作系统角度来说是一个user space的独立的可执行文件。 从运行的角度来说，这个文件由2部分组成，一部分是用户的代码，另一部分就是runtime。runtime通过接口函数调用来管理goroutine, channel及其他一些高级的功能。从用户代码发起的调用操作系统API的调用都会被runtime拦截并处理。\nGo runtime的一个重要的组成部分是goroutine scheduler。他负责追踪，调度每个goroutine运行，实际上是从应用程序的process所属的thread pool中分配一个thread来执行这个goroutine。因此，和java虚拟机中的Java thread和OS thread映射概念类似，每个goroutine只有分配到一个OS thread才能运行。\n相关资料\n 6.如何获取 go 程序运行时的协程数量, gc 时间, 对象数, 堆栈信息?\n调用接口 runtime.ReadMemStats 可以获取以上所有信息, 注意: 调用此接口会触发 STW(Stop The World)\n参考: https://golang.org/pkg/runtime/#ReadMemStats\n如果需要打入到日志系统, 可以使用 go 封装好的包, 输出 json 格式. 参考:\n https://golang.org/pkg/expvar/ http://blog.studygolang.com/2017/06/expvar-in-action/  更深入的用法就是将得到的运行时数据导入到 ES 内部, 然后使用 Kibana 做 golang 的运行时监控, 可以实时获取到运行的信息(堆栈, 对象数, gc 时间, goroutine, 总内存使用等等), 具体信息可以看 ReadMemStats 的那个结构体\n效果大致如下:\n7.介绍下你平时都是怎么调试 golang 的 bug 以及性能问题的?\n  panic 调用栈 pprof 火焰图(配合压测) 使用go run -race 或者 go build -race 来进行竞争检测 查看系统 磁盘IO/网络IO/内存占用/CPU 占用(配合压测)   8.简单介绍下 golang 中 make 和 new 的区别\n new(T) 是为一个 T 类型的新值分配空间, 并将此空间初始化为 T 的零值, 并返回这块内存空间的地址, 也就是 T 类型的指针 *T, 该指针指向 T 类型值占用的那块内存. make(T) 返回的是初始化之后的 T, 且只能用于 slice, map, channel 三种类型. make(T, args) 返回初始化之后 T 类型的值, 且此新值并不是 T 类型的零值, 也不是 T 类型的指针 *T, 而是 T 类型值经过初始化之后的引用.\n 参考: \u0026gt; 1. https://www.cnblogs.com/ghj1976/archive/2013/02/12/2910384.html \u0026gt; 2. https://studygolang.com/articles/3496\n","title":"Golang语言"},{"location":"https://bytemode.github.io/interview/articles/interview_analysis_1/","text":" 最近在很多地方看到了golang的面试题，看到了很多人对Golang的面试题心存恐惧，也是为了复习基础，我把解题的过程总结下来。\n面试题 1. 写出下面代码输出内容。 package main import ( \u0026#34;fmt\u0026#34; ) func main() { defer_call() } func defer_call() { defer func() { fmt.Println(\u0026#34;打印前\u0026#34;) }() defer func() { fmt.Println(\u0026#34;打印中\u0026#34;) }() defer func() { fmt.Println(\u0026#34;打印后\u0026#34;) }() panic(\u0026#34;触发异常\u0026#34;) } 考点：defer执行顺序 解答： defer 是后进先出。 协程遇到panic时，遍历本协程的defer链表，并执行defer。在执行defer过程中，遇到recover则停止panic，返回recover处继续往下执行。如果没有遇到recover，遍历完本协程的defer链表后，向stderr抛出panic信息。从执行顺序上来看，实际上是按照先进后出的顺序执行defer\n打印后 打印中 打印前 panic: 触发异常 注意：请用独立终端运行，排查某些IDE对stderr和stdout处理问题导致输出顺序不一致。\n2. 以下代码有什么问题，说明原因。 type student struct { Name string Age int } func pase_student() { m := make(map[string]*student) stus := []student{ {Name: \u0026#34;zhou\u0026#34;, Age: 24}, {Name: \u0026#34;li\u0026#34;, Age: 23}, {Name: \u0026#34;wang\u0026#34;, Age: 22}, } for _, stu := range stus { m[stu.Name] = \u0026amp;stu } } 考点：foreach 解答： 这样的写法初学者经常会遇到的，很危险！ 与Java的foreach一样，都是使用副本的方式。所以m[stu.Name]=\u0026amp;stu实际上一致指向同一个指针， 最终该指针的值为遍历的最后一个struct的值拷贝。 就像想修改切片元素的属性：\nfor _, stu := range stus { stu.Age = stu.Age+10 } 也是不可行的。 大家可以试试打印出来：\nfunc pase_student() { m := make(map[string]*student) stus := []student{ {Name: \u0026quot;zhou\u0026quot;, Age: 24}, {Name: \u0026quot;li\u0026quot;, Age: 23}, {Name: \u0026quot;wang\u0026quot;, Age: 22}, } // 错误写法 for _, stu := range stus { m[stu.Name] = \u0026amp;stu } for k,v:=range m{ println(k,\u0026quot;=\u0026gt;\u0026quot;,v.Name) } // 正确 for i:=0;i\u0026lt;len(stus);i++ { m[stus[i].Name] = \u0026amp;stus[i] } for k,v:=range m{ println(k,\u0026quot;=\u0026gt;\u0026quot;,v.Name) } }  3. 下面的代码会输出什么，并说明原因 func main() { runtime.GOMAXPROCS(1) wg := sync.WaitGroup{} wg.Add(20) for i := 0; i \u0026lt; 10; i++ { go func() { fmt.Println(\u0026#34;A: \u0026#34;, i) wg.Done() }() } for i := 0; i \u0026lt; 10; i++ { go func(i int) { fmt.Println(\u0026#34;B: \u0026#34;, i) wg.Done() }(i) } wg.Wait() } 考点：go执行的随机性和闭包 解答： 谁也不知道执行后打印的顺序是什么样的，所以只能说是随机数字。\n其中A:输出完全随机，取决于goroutine执行时i的值是多少；\n而B:一定输出为0~9，但顺序不定。\n第一个go func中i是外部for的一个变量，地址不变化，但是值都在改变。\n第二个go func中i是函数参数，与外部for中的i完全是两个变量。\n尾部(i)将发生值拷贝，go func内部指向值拷贝地址。\n所以在使用goroutine在处理闭包的时候，避免发生类似第一个go func中的问题。\n4. 下面代码会输出什么？ type People struct{} func (p *People) ShowA() { fmt.Println(\u0026#34;showA\u0026#34;) p.ShowB() } func (p *People) ShowB() { fmt.Println(\u0026#34;showB\u0026#34;) } type Teacher struct { People } func (t *Teacher) ShowB() { fmt.Println(\u0026#34;teacher showB\u0026#34;) } func main() { t := Teacher{} t.ShowA() } 考点：go的组合继承 解答： 这是Golang的组合模式，可以实现OOP的继承。 被组合的类型People所包含的方法虽然升级成了外部类型Teacher这个组合类型的方法（一定要是匿名字段），但它们的方法(ShowA())调用时接受者并没有发生变化。 此时People类型并不知道自己会被什么类型组合，当然也就无法调用方法时去使用未知的组合者Teacher类型的功能。\nshowA showB 5. 下面代码会触发异常吗？请详细说明 func main() { runtime.GOMAXPROCS(1) int_chan := make(chan int, 1) string_chan := make(chan string, 1) int_chan \u0026lt;- 1 string_chan \u0026lt;- \u0026#34;hello\u0026#34; select { case value := \u0026lt;-int_chan: fmt.Println(value) case value := \u0026lt;-string_chan: panic(value) } } 考点：select随机性 解答： select会随机选择一个可用通用做收发操作。 所以代码是有肯触发异常，也有可能不会。 单个chan如果无缓冲时，将会阻塞。但结合 select可以在多个chan间等待执行。有三点原则： * select 中只要有一个case能return，则立刻执行。 * 当如果同一时间有多个case均能return则伪随机方式抽取任意一个执行。 * 如果没有一个case能return则可以执行”default”块。\n6. 下面代码输出什么？ func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret } func main() { a := 1 b := 2 defer calc(\u0026#34;1\u0026#34;, a, calc(\u0026#34;10\u0026#34;, a, b)) a = 0 defer calc(\u0026#34;2\u0026#34;, a, calc(\u0026#34;20\u0026#34;, a, b)) b = 1 } 考点：defer执行顺序 解答： 这道题类似第1题 需要注意到defer执行顺序和值传递 index:1肯定是最后执行的，但是index:1的第三个参数是一个函数，所以最先被调用calc(\u0026ldquo;10\u0026rdquo;,1,2)==\u0026gt;10,1,2,3 执行index:2时,与之前一样，需要先调用calc(\u0026ldquo;20\u0026rdquo;,0,2)==\u0026gt;20,0,2,2 执行到b=1时候开始调用，index:2==\u0026gt;calc(\u0026ldquo;2\u0026rdquo;,0,2)==\u0026gt;2,0,2,2 最后执行index:1==\u0026gt;calc(\u0026ldquo;1\u0026rdquo;,1,3)==\u0026gt;1,1,3,4\n10 1 2 3 20 0 2 2 2 0 2 2 1 1 3 4 7. 请写出以下输入内容 func main() { s := make([]int, 5) s = append(s, 1, 2, 3) fmt.Println(s) } 考点：make默认值和append 解答： make初始化是由默认值的哦，此处默认值为0\n[0 0 0 0 0 1 2 3] 大家试试改为:\ns := make([]int, 0) s = append(s, 1, 2, 3) fmt.Println(s)//[1 2 3]  8. 下面的代码有什么问题? type UserAges struct { ages map[string]int sync.Mutex } func (ua *UserAges) Add(name string, age int) { ua.Lock() defer ua.Unlock() ua.ages[name] = age } func (ua *UserAges) Get(name string) int { if age, ok := ua.ages[name]; ok { return age } return -1 } 考点：map线程安全 解答： 可能会出现fatal error: concurrent map read and map write. 修改一下看看效果\nfunc (ua *UserAges) Get(name string) int { ua.Lock() defer ua.Unlock() if age, ok := ua.ages[name]; ok { return age } return -1 } 9. 下面的迭代会有什么问题？ func (set *threadSafeSet) Iter() \u0026lt;-chan interface{} { ch := make(chan interface{}) go func() { set.RLock() for elem := range set.s { ch \u0026lt;- elem } close(ch) set.RUnlock() }() return ch } 考点：chan缓存池 解答： 看到这道题，我也在猜想出题者的意图在哪里。 chan?sync.RWMutex?go?chan缓存池?迭代? 所以只能再读一次题目，就从迭代入手看看。 既然是迭代就会要求set.s全部可以遍历一次。但是chan是为缓存的，那就代表这写入一次就会阻塞。 我们把代码恢复为可以运行的方式，看看效果\npackage main import ( \u0026#34;sync\u0026#34; \u0026#34;fmt\u0026#34; ) //下面的迭代会有什么问题？  type threadSafeSet struct { sync.RWMutex s []interface{} } func (set *threadSafeSet) Iter() \u0026lt;-chan interface{} { // ch := make(chan interface{}) // 解除注释看看！  ch := make(chan interface{},len(set.s)) go func() { set.RLock() for elem,value := range set.s { ch \u0026lt;- elem println(\u0026#34;Iter:\u0026#34;,elem,value) } close(ch) set.RUnlock() }() return ch } func main() { th:=threadSafeSet{ s:[]interface{}{\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;}, } v:=\u0026lt;-th.Iter() fmt.Sprintf(\u0026#34;%s%v\u0026#34;,\u0026#34;ch\u0026#34;,v) } 10. 以下代码能编译过去吗？为什么？ package main import ( \u0026#34;fmt\u0026#34; ) type People interface { Speak(string) string } type Stduent struct{} func (stu *Stduent) Speak(think string) (talk string) { if think == \u0026#34;bitch\u0026#34; { talk = \u0026#34;You are a good boy\u0026#34; } else { talk = \u0026#34;hi\u0026#34; } return } func main() { var peo People = Stduent{} think := \u0026#34;bitch\u0026#34; fmt.Println(peo.Speak(think)) } 考点：golang的方法集 解答： 编译不通过！ 做错了！？说明你对golang的方法集还有一些疑问。 一句话：golang的方法集仅仅影响接口实现和方法表达式转化，与通过实例或者指针调用方法无关。\n11. 以下代码打印出来什么内容，说出为什么。 package main import ( \u0026#34;fmt\u0026#34; ) type People interface { Show() } type Student struct{} func (stu *Student) Show() { } func live() People { var stu *Student return stu } func main() { if live() == nil { fmt.Println(\u0026#34;AAAAAAA\u0026#34;) } else { fmt.Println(\u0026#34;BBBBBBB\u0026#34;) } } 考点：interface内部结构 解答： 很经典的题！ 这个考点是很多人忽略的interface内部结构。 go中的接口分为两种一种是空的接口类似这样：\nvar in interface{}  另一种如题目：\ntype People interface { Show() }  他们的底层结构如下：\ntype eface struct { //空接口 _type *_type //类型信息 data unsafe.Pointer //指向数据的指针(go语言中特殊的指针类型unsafe.Pointer类似于c语言中的void*) } type iface struct { //带有方法的接口 tab *itab //存储type信息还有结构实现方法的集合 data unsafe.Pointer //指向数据的指针(go语言中特殊的指针类型unsafe.Pointer类似于c语言中的void*) } type _type struct { size uintptr //类型大小 ptrdata uintptr //前缀持有所有指针的内存大小 hash uint32 //数据hash值 tflag tflag align uint8 //对齐 fieldalign uint8 //嵌入结构体时的对齐 kind uint8 //kind 有些枚举值kind等于0是无效的 alg *typeAlg //函数指针数组，类型实现的所有方法 gcdata *byte str nameOff ptrToThis typeOff } type itab struct { inter *interfacetype //接口类型 _type *_type //结构类型 link *itab bad int32 inhash int32 fun [1]uintptr //可变大小 方法集合 }  可以看出iface比eface 中间多了一层itab结构。 itab 存储_type信息和[]fun方法集，从上面的结构我们就可得出，因为data指向了nil 并不代表interface 是nil， 所以返回值并不为空，这里的fun(方法集)定义了接口的接收规则，在编译的过程中需要验证是否实现接口 结果：\nBBBBBBB","title":"Golang面试题解析（一）"},{"location":"https://bytemode.github.io/interview/articles/interview_analysis_3/","text":" 21.编译执行下面代码会出现什么? package main var( size :=1024 max_size = size*2 ) func main() { println(size,max_size) } 解析 考点:变量简短模式\n变量简短模式限制： - 定义变量同时显式初始化 - 不能提供数据类型 - 只能在函数内部使用\n结果：\nsyntax error: unexpected :=  22.下面函数有什么问题？ package main const cl = 100 var bl = 123 func main() { println(\u0026amp;bl,bl) println(\u0026amp;cl,cl) }  解析 考点:常量\n常量不同于变量的在运行期分配内存，常量通常会被编译器在预处理阶段直接展开，作为指令数据使用，\ncannot take the address of cl  23.编译执行下面代码会出现什么? package main func main() { for i:=0;i\u0026lt;10 ;i++ { loop: println(i) } goto loop }  解析 考点：goto\ngoto不能跳转到其他函数或者内层代码\ngoto loop jumps into block starting at  24.编译执行下面代码会出现什么? package main import \u0026quot;fmt\u0026quot; func main() { type MyInt1 int type MyInt2 = int var i int =9 var i1 MyInt1 = i var i2 MyInt2 = i fmt.Println(i1,i2) }  解析 考点：**Go 1.9 新特性 Type Alias **\n基于一个类型创建一个新类型，称之为defintion；基于一个类型创建一个别名，称之为alias。 MyInt1为称之为defintion，虽然底层类型为int类型，但是不能直接赋值，需要强转； MyInt2称之为alias，可以直接赋值。\n结果:\ncannot use i (type int) as type MyInt1 in assignment  25.编译执行下面代码会出现什么? package main import \u0026quot;fmt\u0026quot; type User struct { } type MyUser1 User type MyUser2 = User func (i MyUser1) m1(){ fmt.Println(\u0026quot;MyUser1.m1\u0026quot;) } func (i User) m2(){ fmt.Println(\u0026quot;User.m2\u0026quot;) } func main() { var i1 MyUser1 var i2 MyUser2 i1.m1() i2.m2() }  解析 考点：**Go 1.9 新特性 Type Alias **\n因为MyUser2完全等价于User，所以具有其所有的方法，并且其中一个新增了方法，另外一个也会有。 但是\ni1.m2()  是不能执行的，因为MyUser1没有定义该方法。 结果:\nMyUser1.m1 User.m2  26.编译执行下面代码会出现什么? package main import \u0026quot;fmt\u0026quot; type T1 struct { } func (t T1) m1(){ fmt.Println(\u0026quot;T1.m1\u0026quot;) } type T2 = T1 type MyStruct struct { T1 T2 } func main() { my:=MyStruct{} my.m1() }  解析 考点：**Go 1.9 新特性 Type Alias **\n是不能正常编译的,异常：\nambiguous selector my.m1  结果不限于方法，字段也也一样；也不限于type alias，type defintion也是一样的，只要有重复的方法、字段，就会有这种提示，因为不知道该选择哪个。 改为:\nmy.T1.m1() my.T2.m1()  type alias的定义，本质上是一样的类型，只是起了一个别名，源类型怎么用，别名类型也怎么用，保留源类型的所有方法、字段等。\n27.编译执行下面代码会出现什么? package main import ( \u0026quot;errors\u0026quot; \u0026quot;fmt\u0026quot; ) var ErrDidNotWork = errors.New(\u0026quot;did not work\u0026quot;) func DoTheThing(reallyDoIt bool) (err error) { if reallyDoIt { result, err := tryTheThing() if err != nil || result != \u0026quot;it worked\u0026quot; { err = ErrDidNotWork } } return err } func tryTheThing() (string,error) { return \u0026quot;\u0026quot;,ErrDidNotWork } func main() { fmt.Println(DoTheThing(true)) fmt.Println(DoTheThing(false)) }  解析 考点：变量作用域\n因为 if 语句块内的 err 变量会遮罩函数作用域内的 err 变量，结果：\n\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;  改为：\nfunc DoTheThing(reallyDoIt bool) (err error) { var result string if reallyDoIt { result, err = tryTheThing() if err != nil || result != \u0026quot;it worked\u0026quot; { err = ErrDidNotWork } } return err }  28.编译执行下面代码会出现什么? package main func test() []func() { var funs []func() for i:=0;i\u0026lt;2 ;i++ { funs = append(funs, func() { println(\u0026amp;i,i) }) } return funs } func main(){ funs:=test() for _,f:=range funs{ f() } }  解析 考点：闭包延迟求值\nfor循环复用局部变量i，每一次放入匿名函数的应用都是想一个变量。 结果：\n0xc042046000 2 0xc042046000 2  如果想不一样可以改为：\nfunc test() []func() { var funs []func() for i:=0;i\u0026lt;2 ;i++ { x:=i funs = append(funs, func() { println(\u0026amp;x,x) }) } return funs }  29.编译执行下面代码会出现什么? package main func test(x int) (func(),func()) { return func() { println(x) x+=10 }, func() { println(x) } } func main() { a,b:=test(100) a() b() }  解析 考点：闭包引用相同变量*\n结果：\n100 110  30.编译执行下面代码会出现什么? package main import ( \u0026quot;fmt\u0026quot; \u0026quot;reflect\u0026quot; ) func main1() { defer func() { if err:=recover();err!=nil{ fmt.Println(err) }else { fmt.Println(\u0026quot;fatal\u0026quot;) } }() defer func() { panic(\u0026quot;defer panic\u0026quot;) }() panic(\u0026quot;panic\u0026quot;) } func main() { defer func() { if err:=recover();err!=nil{ fmt.Println(\u0026quot;++++\u0026quot;) f:=err.(func()string) fmt.Println(err,f(),reflect.TypeOf(err).Kind().String()) }else { fmt.Println(\u0026quot;fatal\u0026quot;) } }() defer func() { panic(func() string { return \u0026quot;defer panic\u0026quot; }) }() panic(\u0026quot;panic\u0026quot;) }  解析 考点：panic仅有最后一个可以被revover捕获\n触发panic(\u0026quot;panic\u0026quot;)后顺序执行defer，但是defer中还有一个panic，所以覆盖了之前的panic(\u0026quot;panic\u0026quot;)\ndefer panic  ","title":"Golang面试题解析（三）"},{"location":"https://bytemode.github.io/interview/articles/interview_analysis_2/","text":" 12.是否可以编译通过？如果通过，输出什么？ func main() { i := GetValue() switch i.(type) { case int: println(\u0026#34;int\u0026#34;) case string: println(\u0026#34;string\u0026#34;) case interface{}: println(\u0026#34;interface\u0026#34;) default: println(\u0026#34;unknown\u0026#34;) } } func GetValue() int { return 1 } 解析 考点：type\n编译失败，因为type只能使用在interface\n13.下面函数有什么问题？ func funcMui(x,y int)(sum int,error){ return x+y,nil } 解析 考点：函数返回值命名 在函数有多个返回值时，只要有一个返回值有指定命名，其他的也必须有命名。 如果返回值有有多个返回值必须加上括号； 如果只有一个返回值并且有命名也需要加上括号； 此处函数第一个返回值有sum名称，第二个未命名，所以错误。\n14.是否可以编译通过？如果通过，输出什么？ package main func main() { println(DeferFunc1(1)) println(DeferFunc2(1)) println(DeferFunc3(1)) } func DeferFunc1(i int) (t int) { t = i defer func() { t += 3 }() return t } func DeferFunc2(i int) int { t := i defer func() { t += 3 }() return t } func DeferFunc3(i int) (t int) { defer func() { t += i }() return 2 } 解析 考点:defer和函数返回值 需要明确一点是defer需要在函数结束前执行。 函数返回值名字会在函数起始处被初始化为对应类型的零值并且作用域为整个函数 DeferFunc1有函数返回值t作用域为整个函数，在return之前defer会被执行，所以t会被修改，返回4; DeferFunc2函数中t的作用域为函数，返回1; DeferFunc3返回3\n15.是否可以编译通过？如果通过，输出什么？ func main() { list := new([]int) list = append(list, 1) fmt.Println(list) } 解析 考点：new list:=make([]int,0)\n16.是否可以编译通过？如果通过，输出什么？ package main import \u0026#34;fmt\u0026#34; func main() { s1 := []int{1, 2, 3} s2 := []int{4, 5} s1 = append(s1, s2) fmt.Println(s1) } 解析 考点：append append切片时候别漏了\u0026rsquo;\u0026hellip;\u0026rsquo;\n17.是否可以编译通过？如果通过，输出什么？ func main() { sn1 := struct { age int name string }{age: 11, name: \u0026#34;qq\u0026#34;} sn2 := struct { age int name string }{age: 11, name: \u0026#34;qq\u0026#34;} if sn1 == sn2 { fmt.Println(\u0026#34;sn1 == sn2\u0026#34;) } sm1 := struct { age int m map[string]string }{age: 11, m: map[string]string{\u0026#34;a\u0026#34;: \u0026#34;1\u0026#34;}} sm2 := struct { age int m map[string]string }{age: 11, m: map[string]string{\u0026#34;a\u0026#34;: \u0026#34;1\u0026#34;}} if sm1 == sm2 { fmt.Println(\u0026#34;sm1 == sm2\u0026#34;) } } 解析 考点:结构体比较 进行结构体比较时候，只有相同类型的结构体才可以比较，结构体是否相同不但与属性类型个数有关，还与属性顺序相关。\nsn3:= struct { name string age int }{age:11,name:\u0026quot;qq\u0026quot;}  sn3与sn1就不是相同的结构体了，不能比较。 还有一点需要注意的是结构体是相同的，但是结构体属性中有不可以比较的类型，如map,slice。 如果该结构属性都是可以比较的，那么就可以使用“==”进行比较操作。\n可以使用reflect.DeepEqual进行比较\nif reflect.DeepEqual(sn1, sm) { fmt.Println(\u0026quot;sn1 ==sm\u0026quot;) }else { fmt.Println(\u0026quot;sn1 !=sm\u0026quot;) }  所以编译不通过： invalid operation: sm1 == sm2\n18.是否可以编译通过？如果通过，输出什么？ func Foo(x interface{}) { if x == nil { fmt.Println(\u0026#34;empty interface\u0026#34;) return } fmt.Println(\u0026#34;non-empty interface\u0026#34;) } func main() { var x *int = nil Foo(x) } 解析 考点：interface内部结构\nnon-empty interface  19.是否可以编译通过？如果通过，输出什么？ func GetValue(m map[int]string, id int) (string, bool) { if _, exist := m[id]; exist { return \u0026#34;存在数据\u0026#34;, true } return nil, false } func main() { intmap:=map[int]string{ 1:\u0026#34;a\u0026#34;, 2:\u0026#34;bb\u0026#34;, 3:\u0026#34;ccc\u0026#34;, } v,err:=GetValue(intmap,3) fmt.Println(v,err) } 解析 考点：函数返回值类型 nil 可以用作 interface、function、pointer、map、slice 和 channel 的“空值”。但是如果不特别指定的话，Go 语言不能识别类型，所以会报错。通常编译的时候不会报错，但是运行是时候会报:cannot use nil as type string in return argument.\n20.是否可以编译通过？如果通过，输出什么？ const ( x = iota y z = \u0026#34;zz\u0026#34; k p = iota ) func main() { fmt.Println(x,y,z,k,p) } 解析 考点：iota 结果:\n0 1 zz zz 4  ","title":"Golang面试题解析（二）"},{"location":"https://bytemode.github.io/interview/articles/interview_analysis_4/","text":" 31. 算法 在utf8字符串判断是否包含指定字符串，并返回下标。 \u0026ldquo;北京天安门最美丽\u0026rdquo; , \u0026ldquo;天安门\u0026rdquo; 结果：2\n解答：\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main(){ fmt.Println(Utf8Index(\u0026#34;北京天安门最美丽\u0026#34;, \u0026#34;天安门\u0026#34;)) fmt.Println(strings.Index(\u0026#34;北京天安门最美丽\u0026#34;, \u0026#34;男\u0026#34;)) fmt.Println(strings.Index(\u0026#34;\u0026#34;, \u0026#34;男\u0026#34;)) fmt.Println(Utf8Index(\u0026#34;12ws北京天安门最美丽\u0026#34;, \u0026#34;天安门\u0026#34;)) } func Utf8Index(str, substr string) int { asciiPos := strings.Index(str, substr) if asciiPos == -1 || asciiPos == 0 { return asciiPos } pos := 0 totalSize := 0 reader := strings.NewReader(str) for _, size, err := reader.ReadRune(); err == nil; _, size, err = reader.ReadRune() { totalSize += size pos++ // 匹配到 \tif totalSize == asciiPos { return pos } } return pos } 32，编程 实现一个单例\n解答：\npackage main import \u0026#34;sync\u0026#34; // 实现一个单例  type singleton struct{} var ins *singleton var mu sync.Mutex //懒汉加锁:虽然解决并发的问题，但每次加锁是要付出代价的 func GetIns() *singleton { mu.Lock() defer mu.Unlock() if ins == nil { ins = \u0026amp;singleton{} } return ins } //双重锁:避免了每次加锁，提高代码效率 func GetIns1() *singleton { if ins == nil { mu.Lock() defer mu.Unlock() if ins == nil { ins = \u0026amp;singleton{} } } return ins } //sync.Once实现 var once sync.Once func GetIns2() *singleton { once.Do(func() { ins = \u0026amp;singleton{} }) return ins } 33,执行下面的代码发生什么？ package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ch := make(chan int, 1000) go func() { for i := 0; i \u0026lt; 10; i++ { ch \u0026lt;- i } }() go func() { for { a, ok := \u0026lt;-ch if !ok { fmt.Println(\u0026#34;close\u0026#34;) return } fmt.Println(\u0026#34;a: \u0026#34;, a) } }() close(ch) fmt.Println(\u0026#34;ok\u0026#34;) time.Sleep(time.Second * 100) } 考点:channel 往已经关闭的channel写入数据会panic的。 结果：\npanic: send on closed channel  34,执行下面的代码发生什么？ import \u0026quot;fmt\u0026quot; type ConfigOne struct { Daemon string } func (c *ConfigOne) String() string { return fmt.Sprintf(\u0026quot;print: %v\u0026quot;, p) } func main() { c := \u0026amp;ConfigOne{} c.String() }  考点:fmt.Sprintf 如果类型实现String()，％v和％v格式将使用String()的值。因此，对该类型的String()函数内的类型使用％v会导致无限递归。 编译报错：\nruntime: goroutine stack exceeds 1000000000-byte limit fatal error: stack overflow  35，编程题 反转整数 反转一个整数，例如：\n例子1: x = 123, return 321\n例子2: x = -123, return -321\n输入的整数要求是一个 32bit 有符号数，如果反转后溢出，则输出 0\nfunc reverse(x int) (num int) { for x != 0 { num = num*10 + x%10 x = x / 10 } // 使用 math 包中定义好的最大最小值 if num \u0026gt; math.MaxInt32 || num \u0026lt; math.MinInt32 { return 0 } return }  36，编程题 合并重叠区间 给定一组 区间，合并所有重叠的 区间。\n例如： 给定：[1,3],[2,6],[8,10],[15,18] 返回：[1,6],[8,10],[15,18]\ntype Interval struct { Start int End int } func merge(intervals []Interval) []Interval { if len(intervals) \u0026lt;= 1 { return intervals } sort.Slice(intervals, func(i, j int) bool { return intervals[i].Start \u0026lt; intervals[j].Start }) res := make([]Interval, 0) swap := Interval{} for k, v := range intervals { if k == 0 { swap = v continue } if v.Start \u0026lt;= swap.End { swap.End = v.End } else { res = append(res, swap) swap = v } } res = append(res, swap) return res }  37.输出什么？ package main import ( \u0026quot;fmt\u0026quot; ) func main() { fmt.Println(len(\u0026quot;你好bj!\u0026quot;)) }  考点:编码长度 输出9\n38.编译并运行如下代码会发生什么？ package main import \u0026quot;fmt\u0026quot; type Test struct { Name string } var list map[string]Test func main() { list = make(map[string]Test) name := Test{\u0026quot;xiaoming\u0026quot;} list[\u0026quot;name\u0026quot;] = name list[\u0026quot;name\u0026quot;].Name = \u0026quot;Hello\u0026quot; fmt.Println(list[\u0026quot;name\u0026quot;]) }  考点:map 编程报错cannot assign to struct field list[\u0026quot;name\u0026quot;].Name in map。 因为list[\u0026ldquo;name\u0026rdquo;]不是一个普通的指针值，map的value本身是不可寻址的，因为map中的值会在内存中移动，并且旧的指针地址在map改变时会变得无效。 定义的是var list map[string]Test，注意哦Test不是指针，而且map我们都知道是可以自动扩容的，那么原来的存储name的Test可能在地址A，但是如果map扩容了地址A就不是原来的Test了，所以go就不允许我们写数据。你改为var list map[string]*Test试试看。\n39.ABCD中哪一行存在错误？ type S struct { } func f(x interface{}) { } func g(x *interface{}) { } func main() { s := S{} p := \u0026amp;s f(s) //A \tg(s) //B \tf(p) //C \tg(p) //D  } 考点:interface 看到这道题需要第一时间想到的是Golang是强类型语言，interface是所有golang类型的父类，类似Java的Object。 函数中func f(x interface{})的interface{}可以支持传入golang的任何类型，包括指针，但是函数func g(x *interface{})只能接受*interface{}.\n40.编译并运行如下代码会发生什么？ package main import ( \u0026#34;sync\u0026#34; //\u0026#34;time\u0026#34; ) const N = 10 var wg = \u0026amp;sync.WaitGroup{} func main() { for i := 0; i \u0026lt; N; i++ { go func(i int) { wg.Add(1) println(i) defer wg.Done() }(i) } wg.Wait() } 考点:WaitGroup 这是使用WaitGroup经常犯下的错误！请各位同学多次运行就会发现输出都会不同甚至又出现报错的问题。 这是因为go执行太快了，导致wg.Add(1)还没有执行main函数就执行完毕了。 改为如下试试\nfor i := 0; i \u0026lt; N; i++ { wg.Add(1) go func(i int) { println(i) defer wg.Done() }(i) } wg.Wait()  附录 https://zhuanlan.zhihu.com/p/35058068?hmsr=toutiao.io\u0026amp;utm_medium=toutiao.io\u0026amp;utm_source=toutiao.io\nhttps://stackoverflow.com/questions/42600920/runtime-goroutine-stack-exceeds-1000000000-byte-limit-fatal-error-stack-overf\nhttps://studygolang.com/topics/3853\n","title":"Golang面试题解析（四）"},{"location":"https://bytemode.github.io/articles/sony-gobreaker/readme/","text":" 最近看了一下go-kit，发现这个微服务框架的熔断器，也是使用sony开源的作为基础。 sony开源在 github 的熔断器 在源代头注释中发现，原来sony实现的是微软2015时公布的CircuitBreaker标准，果然微软才开源界的大神。\n1）微软定义的 Circuit breaker 微软的原文件在此：https://msdn.microsoft.com/en-us/library/dn589784.aspx 名不知道怎么正确翻译，直观翻译，可能叫：环形熔断器（或叫：循环状态自动切换中断器）。 因为它是在下面3个状态循环切换 ：\n Closed / \\ Half-Open \u0026lt;--\u0026gt; Open 初始状态是：Closed，指熔断器放行所有请求。 达到一定数量的错误计数，进入Open 状态，指熔断发生，下游出现错误，不能再放行请求。 经过一段Interval时间后，自动进入Half-Open状态，然后开始尝试对成功请求计数。 进入Half-Open后，根据成功/失败计数情况，会自动进入Closed或Open。  2）sony开源的go实现 // 从定义的错误来看，sony的应该增加了对连接数进行了限制 。  var ( // ErrTooManyRequests is returned when the CB state is half open and the requests count is over the cb maxRequests \tErrTooManyRequests = errors.New(\u0026#34;too many requests\u0026#34;) // ErrOpenState is returned when the CB state is open \tErrOpenState = errors.New(\u0026#34;circuit breaker is open\u0026#34;) ) 2.1） 通过Settings的实现，了解可配置功能： type Settings struct { Name string MaxRequests uint32 // 半开状态期最大允许放行请求：即进入Half-Open状态时，一个时间周期内允许最大同时请求数（如果还达不到切回closed状态条件，则不能再放行请求）。 \tInterval time.Duration // closed状态时，重置计数的时间周期；如果配为0，切入Open后永不切回Closed--有点暴力。 \tTimeout time.Duration // 进入Open状态后，多长时间会自动切成 Half-open，默认60s，不能配为0。  // ReadyToTrip回调函数：进入Open状态的条件，比如默认是连接5次出错，即进入Open状态，即可对熔断条件进行配置。在fail计数发生后，回调一次。 \tReadyToTrip func(counts Counts) bool // 状态切换时的熔断器 \tOnStateChange func(name string, from State, to State) } 2.2）核心的*执行函数*实现 要把熔断器使用到工程中，只需要，实例化一个gobreaker，再使用这个Execute包一下原来的请求函数。\nfunc (cb *CircuitBreaker) Execute(req func() (interface{}, error)) (interface{}, error) { generation, err := cb.beforeRequest() // \tif err != nil { return nil, err } defer func() { e := recover() if e != nil { cb.afterRequest(generation, false) panic(e) // 如果代码发生了panic，继续panic给上层调用者去recover。 \t} }() result, err := req() cb.afterRequest(generation, err == nil) return result, err } 2.2 关键 func beforeRequest() 函数做了几件事：\n 函数的核心功能：判断是否放行请求，计数或达到切换新条件刚切换。 判断是否Closed，如是，放行所有请求。  并且判断时间是否达到Interval周期，从而清空计数，进入新周期，调用toNewGeneration()\n  如果是Open状态，返回ErrOpenState，\u0026mdash;不放行所有请求。  同样判断周期时间，到达则 同样调用 toNewGeneration(){清空计数}  如果是half-open状态，则判断是否已放行MaxRequests个请求，如未达到刚放行；否则返回:ErrTooManyRequests。 此函数一旦放行请求，就会对请求计数加1（conut.onRequest())，请求后到另一个关键函数 : afterRequest()。  2.3 关键 func afterRequest()  函数核心内容很简单，就对成功/失败进行计数，达到条件则切换状态。 与beforeRequest一样，会调用公共函数 currentState(now)  currentState(now) 先判断是否进入一个先的计数时间周期(Interval), 是则重置计数，改变熔断器状态，并返回新一代。 如果request耗时大于Interval, 几本每次都会进入新的计数周期，熔断器就没什么意义了。   代码的核心内容  使用了一个generation的概念，每一个时间周期(Interval)的计数(count)状态称为一个generation。 在before/after的两个函数中，实现了两个状态自动切换的机制：  在同一个generation(即时间）周期内，计数满足状态切换条件，即自动切换； 超过一个generation时间周期的也会自动切换；  没有使用定时器，只在请求调用时，去检测当时状态与时间间隔。  ","title":"Sony gobreaker熔断器源码分析"},{"location":"https://bytemode.github.io/interview/interview-os/","text":"1.Select，Poll，Epoll的区别？\n select，poll，epoll都是IO多路复用的机制，具体区别请查阅资料\n查看资料\n 2.什么叫虚拟内存？\n 虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的 可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内 存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。\n 3.什么叫桥接？\n 桥接是指依据OSI网络模型的链路层的地址，对网络数据包进行转发的过程，工作 在OSI的第二层；一般的交换机，网桥就有桥接作用。\n 4.Linux什么命令可以查看cpu和内存？怎么查看每个核的cpu呢？\n top命令\n在top查看界面按数字1即可查看每个核的数据\n 5.给一个PID=100你觉得它是后台程序还是前台程序？\n 进程号0-299保留给daemon进程\n 6.怎么查看一个端口的TCP连接情况？\n netstat\n 7.Docker的网络模式有哪几种？\n bridge网络\nhost网络\nnone网络\ncontainer模式\n 8.介绍一下Tcpdump？\n tcpdump网络数据包截获分析工具。支持针对网络层、协议、主机、网络或端口 的过滤。并提供and、or、not等逻辑语句帮助去除无用的信息。\n查看资料\n 9. 什么叫大端和小端？\n 说明 \u0026gt; 1.Little-Endian（小端）就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端\n\u0026gt; 2.Big-Endian（大端）就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。\n使用场景\n 一般操作系统都是小端的，而通信协议是大端的\n查看资料\n  10. 介绍下 docker 底层原理\n  查看资料 左耳朵耗子 Docker 基础技术介绍(有例程)   11.介绍些僵尸进程和孤儿进程的区别, 怎么产生的, 怎么避免?\n 查看资料\n 12.CPU 使用率和 CPU 负载有什么区别? \u0026gt; 查看资料\n","title":"操作系统"},{"location":"https://bytemode.github.io/interview/interview-database/","text":"1.Mysql事物的隔离级别?\n   事务隔离级别 脏读 不可重复读 幻读     读未提交（read-uncommitted） 是 是 是   读已提交（read-committed） 否 是 是   可重复读（repeatable-read） 否 否 是   串行化（serializable） 否 否 否     相关资料\n 2.Innodb和Myisam的区别？\n Innodb支持事务，而Myisam不支持事务\nInnodb支持行级锁，而Myisam支持表级锁\nInnodb支持外键，而Myisam不支持\nInnodb不支持全文索引，而Myisam支持\nInnodb是索引组织表， Myisam是堆表\n相关资料\n 3.Mysql慢响应默认时间?\n 10s\n 4.Explain的含义?\n explain显示了mysql如何使用索引来处理select语句以及连接表。可以帮助 选择更好的索引和写出更优化的查询语句。\n 5.Profile的意义以及使用场景?\n Profile用来分析SQL性能的消耗分布情况。当用explain无法解决慢SQL的时 候，需要用profile来对SQL进行更细致的分析，找出SQL所花的时间大部分消耗在 哪个部分，确认SQL的性能瓶颈。\n 6.Redis的过期失效机制？\n scan扫描+给每个key存储过期时间戳\n 7.Redis持久化方案aof的默认fsync时间是多长？\n 1s\n 8.Redis持久化方案rdb和aof的区别？\n 查看资料\n 9.Redis怎么查看延迟数据?（非业务操作）\n 可以用redis-cli工具加\u0026ndash;latency参数可以查看延迟时间\n redis-cli --latency -h 127.0.0.1 -p 6379\n 使用slowlog查出引发延迟的慢命令\n slowlog get\n  10.Redis的集群怎么搭建？\n 查看资料\n 11.简单介绍下什么是缓存击穿, 缓存穿透, 缓存雪崩? 能否介绍些应对办法?\n 查看资料\n 12.关系型数据库 MySQL/PostgreSQL的索引类型? 其他数据库优化方法?\n  https://segmentfault.com/a/1190000003072424 https://tech.meituan.com/performance_tunning.html   13.介绍下数据库分库分表以及读写分离?\n 分库分表主要解决写的问题, 读写分离主要解决读的问题. 分库分表的策略有很多种: 平均分配, 按权重分配, 按业务分配, 一致性 hash\u0026hellip;..\n读写分离的原理大致是一台主、多台从。主提供写操作，从提供读操作.\n方案可以根据以下几个因素来综合考虑:\n\u0026gt; 1.数据实时性要求？\n\u0026gt; 2.查询复杂度是否比较高？\n\u0026gt; 3.读和写的比例即侧重点是哪一个？\n方案有很多, 大家可以自行搜索, 学习总结. 这题源自微博的平台技术专家一条微博: https://m.weibo.cn/status/4265027340366901\n ","title":"数据库"},{"location":"https://bytemode.github.io/interview/interview-data-structure/","text":"1.什么是跳跃表?\n 跳跃表是基于有序链表的一种扩展\n查看资料\n 2. 介绍下 RESTFull API 方式下, 怎么做到快速路由?\n 一般使用前缀树/字典树, 来提高查找速度.\n开源的路由模块里, httprouter 是比较快的, 参考: https://github.com/julienschmidt/httprouter\n他使用了一种改进版的前缀树算法. 这个树的应用非常广泛, 除了做路由, 还有 linux 内核里使用, 在数据库里也有用到.\n参考文章:\n1. 路由查找之Radix Tree\n2. 图文详解Radix树\n3. radix tree在数据库PostgreSQL中的一些应用举例\n ","title":"数据结构"},{"location":"https://bytemode.github.io/interview/interview-architecture/","text":"1.Etcd满足了CAP原理中哪两个特性？\n etcd是高可用的键值存储系统。满足CP原理\n 2.Etcd V2和V3版本的区别？\n V2和V3接口不一致，存储不一样，数据互相隔离\n  A.V2是纯内存实现，并未实时将数据写入到磁盘；V3是内存索引(kvindex btree) + 后端数据库存储(boltdb: 单机的支持事务的kv存储)\nB.V2过期时间只能设置到每个key上，如果多个key要保证生命周期一致则比 较困难；V3过期时间通过lease，可以给每个key设置相同的过期id\nC.V2 Watch只能watch某一个key以及子节点(通过参数recursive)，不能 进行多个watch；V3 watch机制支持watch某个固定的key，也支持watch一个范围\nD.V2提供http接口；V3通过grpc提供rpc接口\n  查看资料\n  3.当时选型etcd的考量是啥？和ZK有哪些区别？\n 相同点\n 1.应用场景类似: 配置管理，服务注册发现，选主，应用调度，分布式队列，分布式锁。\n 不同点\n 1.Etcd使用raft协议;Zk使用paxos协议，前者易于理解，方便工程实现。\n2.Etcd相对来说部署方便；Zk的部署、维护、使用比较复杂，需要安装客户端。\n3.Etcd提供http+json，grpc接口，跨平台语言; Zk则需要使用其客户端。\n4.Etcd支持https访问; Zk在这方面缺失。\n  4.服务治理包含哪些？\n 服务注册和发现\n服务监控\n集群容错 负载均衡\n 5.负载均衡分类？\n 1.DNS负载均衡(地理负载均衡)\n2.硬件负载均衡(F5和A10,能支撑200万-800万/秒并发，价格昂贵)\n3.软件负载均衡(Nginx和Lvs,nginx支撑5万/秒，LVS支撑80万/秒，价格便宜， 扩展方便)\n并发访问量大于1000万时可以考虑配合使用\n 6.Nginx和Lvs的区别？\n 1.Nginx 大多工作在第7层，网络的依赖比较小，可以对HTTP应用实施分流策略，比如域名、结构等（也可以工作在第4层网络层，例如对mysql做反向代理，做授权和负载均衡等）；Lvs工作在第4层，比较依赖网络环境，可以对几乎所有应用进行负载均衡，包括Web、数据库等\n2.Nginx负载能力强，因为其工作方式逻辑非常简单，仅进行请求分发，没有流量；Lvs负载能力较差，受限于机器的I/O配置(处理流量)\n3.Nginx安装，配置及测试相对简单；Lvs的安装、配置及测试所花的时间比较长\n参考资料\n 7. 你们是怎么解决微服务之间调用优化与问题排查的?\n 关键词: 链路监控, Google Dapper 论文\n搭建以链路追踪技术为核心的监控系统，通过收集、存储、分析、分布式系统中的调用事件数据，协助开发运营人员进行故障诊断、容量预估、性能瓶颈定位, 调用链路梳理以及优化服务依赖\n实施时需要注意埋点导致的性能问题, 使用异步队列的方式和调整采样率来减少对服务本身造成的性能影响\n常用开源方案: zipkin, jaeger, cat,Skywalking\u0026hellip;..\nJaeger 是 Uber 开源的分布式追踪方案, 已加入 CNCF, 基于 Golang 开发, 部署方便, 支持 Docker, 唯一不足是只支持 Cassandra 和 Elasticsearch\u0026hellip; 更多可自行搜索, 可参考:\n1. https://myslide.cn/slides/8297 2. https://opentalk-blog.b0.upaiyun.com/prod/2017-10-31/9ef338ba14ccca39ce45709b59d70c64.pdf 3. https://github.com/jaegertracing/jaeger 4. Dapper中文版: https://bigbully.github.io/Dapper-translation/\n 8. 介绍下 API 网关的作用和应用架构?\n API网关，它负责在上层抽象出各业务系统需要的通用功能，例如：鉴权、限流、ACL、降级等。\n随着微服务的流行，API网关已经成为一个微服务架构中的标配组件。\n查看资料:\n1. http://www.cnblogs.com/savorboard/p/api-gateway.html 2. https://tech.youzan.com/api-gateway-in-practice/\n ","title":"架构"},{"location":"https://bytemode.github.io/interview/interview-pen/","text":" Golang笔试题解析  查看资料\n ","title":"笔试题"},{"location":"https://bytemode.github.io/reading/11-2018-07-26-golang-jenkins-sonarqube/","text":" 观看视频   ","title":"第 11 期 Golang 代码质量持续检测实践"},{"location":"https://bytemode.github.io/interview/interview-algorithm/","text":" 如何在一个给定有序数组中找两个和为某个定值的数，要求时间复杂度为O(n), 比如给｛1，2，4，5，8，11，15｝和15？_\nfunc Lookup(meta []int32, target int32) { left := 0 right := len(meta) - 1 for i := 0; i \u0026lt; len(meta); i++ { if meta[left]+meta[right] \u0026gt; target { right-- } else if meta[left]+meta[right] \u0026lt; target { left++ } else { fmt.Println(fmt.Sprintf(\u0026#34;%d, %d\u0026#34;, meta[left], meta[right])) return } } fmt.Println(\u0026#34;未找到匹配数据\u0026#34;) } 2.给定一个数组代表股票每天的价格，请问只能买卖一次的情况下，最大化利润是多少？日期不重叠的情况下，可以买卖多次呢？输入：{100,80,120,130,70,60,100,125}，只能买一次：65(60买进，125卖出)；可以买卖多次：115(80买进，130卖出；60买进，125卖出)？\nfunc main() { a := []int{100, 80, 120, 130, 70, 60, 100, 125} // a := []int{68, 0, 1, 67} \tvar buyPrice, salePrice = 1\u0026lt;\u0026lt;31 - 1, -1 \u0026lt;\u0026lt; 31 var buyDay, saleDay = -1, -1 type Op struct { BuyDay, SaleDay int BuyPrice, SalePrice int Earnings int } var opList = []Op{} // 遇到的第一个波谷买入，下一个波峰卖出，可以获取最大收益 \tfor k, todayPrice := range a { if buyDay == -1 { // 寻找买入点 \tif todayPrice \u0026lt; buyPrice { buyPrice = todayPrice continue } // 买入 \tbuyDay = k - 1 continue } // 寻找卖出点 \tif todayPrice \u0026gt; salePrice { salePrice = todayPrice if k \u0026lt; len(a)-1 { continue } } // 卖出 \tif k \u0026lt; len(a)-1 { saleDay = k - 1 } else { saleDay = k } opList = append(opList, Op{ BuyDay: buyDay, SaleDay: saleDay, BuyPrice: buyPrice, SalePrice: salePrice, Earnings: salePrice - buyPrice, }) // 重复下一轮操作 \tbuyPrice, salePrice = 1\u0026lt;\u0026lt;31-1, -1\u0026lt;\u0026lt;31 buyDay, saleDay = -1, -1 } fmt.Printf(\u0026#34;%+v\u0026#34;, opList) } 3.给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？\n 在这里只分享思路\n\t首先，40亿个unsigned int的整数，如果放到内存，那就是大约16G的空间， 那么直接放到内存空间进行排序然后二分查找的方式是行不通的。  方案一\n\t在这里可以考虑使用bitmap，需要4*10^9bit内存， 大约500MB就可一把40 亿的数全部进行hash，时间复杂度是O（n），然后可以在O(1)的时间内进行判断此 数是否在40亿中；此过程在内存中完成。  方案二\n\t考虑在磁盘中操作。 因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；这里我们把40亿 个数中的每一个用32位的二进制来表示，假设这40亿个数开始放在一个文件中。 然后将这40亿个数分成两类: 1.最高位为0 2.最高位为1 并将这两类分别写入到两个文件中； 再然后把这两个文件为又分成两类: 1.次最高位为0 2.次最高位为1 ... 以此类推就可以找到了,而且时间复杂度为O(logn)   ","title":"算法题"},{"location":"https://bytemode.github.io/interview/interview-network/","text":"1.tcp三次握手和四次挥手流程示意图？在黑板上画出\n 查看资料\n 2.客户端在建立异常中发现很多connect reset by peer,你觉得问题出在哪？\n 三次握手维护的半连接队列或者全连接队列溢出导致\n查看资料\n 3.https建立连接的过程?\n 1.客户端发送请求到服务器端\n2.服务器端返回证书和公开密钥，公开密钥作为证书的一部分而存在\n3.客户端验证证书和公开密钥的有效性，如果有效，则生成对称密钥并使用公开密钥加密发送到服务器端\n4.服务器端使用私有密钥解密数据，并使用收到的对称密钥加密数据，发送到客户端\n5.客户端使用对称密钥解密数据\n6.SSL加密建立………\n 4.tcp和udp的区别?\n 1.TCP面向连接(如打电话要先拨号建立连接);UDP是无连接的，即发送数据之前 不需要建立连接\n2.TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失， 不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付\n3.TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向 报文的，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低\n4.每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的 交互通信\n5.TCP首部开销20字节;UDP的首部开销小，只有8个字节\n6.TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道\n 5.http，tcp，ip分别处于OSI哪一层？\n 传输层协议：TCP、UDP、SCTP\n网络层协议：IP、ARP、RARP、ICMP、IGMP、OSPF\n应用层协议：http，FTP、SMTP、RIP、DNS\n ","title":"网络"},{"location":"https://bytemode.github.io/interview/interview-design/","text":"1.要设计一个秒杀系统要注意什么？\n 前端秒杀页面\n 页面静态化：将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态 元素。通过CDN来抗峰值。\n禁止重复提交：用户提交之后按钮置灰，禁止重复提交。\n用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取IP限流。\n 服务端控制器(网关)\n 限制uid访问频率：我们上面拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问uid，限制访问频率。\n 服务层\n 采用消息队列缓存请求：既然服务层知道库存只有100台手机，那完全没有必要把100W个请求都传递到数据库啊，那么可以先把这些请求都写到消息队列缓存一下，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。\n利用缓存应对读请求：对类似于12306等购票业务，是典型的读多写少业务，大部分请求是查询请求，所以可以利用缓存分担数据库压力。\n利用缓存应对写请求：缓存也是可以应对写请求的，比如我们就可以把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。\n 数据库层\n 数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。所以，上面通过在服务层引入队列和缓存，让最底层的数据库高枕无忧。\n  2.要设计一个类似微信红包架构系统要注意什么？\n 南北分区\n快慢分离\nHash负载均衡\nCache屏蔽DB\n双维度分库表\n查看资料\n ","title":"设计题"},{"location":"https://bytemode.github.io/articles/sonarqube-for-golang/","text":"  Author: Kenny Allen\nEmail: kennyallen0520@gmail.com\n 前言 在软件开发过程中，人工检查项目代码中的漏洞和潜在的 BUG 是一件让人十分费神费力的事情，为了解决这一痛点，SonarQube诞生了，它实现了一系列代码自动检测过程，包括命名规范，代码漏洞，代码重复量等。\n但是光有 SonarQube 还不能发挥出应有的高效率，一个完整的代码质量持续检测应配合代码仓库(如 gitlab) 和 Jenkins 来共同构建一个自动化过程。\n环境  Gitlab、Jenkins、SonarQube 服务都在一台物理机上的Docker中运行\n 网络 (局域网IP：192.168.1.100)\n   主机科学上网代理  192.168.1.100:1087\n 模拟外网访问\n# 修改 hosts 文件，模拟外网访问 sudo sh -c \u0026#34;echo \u0026#39;192.168.1.100 jenkins.kenny.com\\n192.168.1.100 gitlab.kenny.com\\n192.168.1.100 sonarqube.kenny.com\u0026#39; \u0026gt;\u0026gt; /etc/hosts\u0026#34;   工具集     名称 版本     golang go1.10.3   docker 18.03.1-ce    搭建 接下来，我以一个完整的案例来介绍搭建过程。\nJenkins 启动服务 # $jenkins_home 宿主机目录，挂载容器 /var/jenkins_home # 我的数据卷目录是 ~/.jenkins export JENKINS_HOME=~/.jenkins docker run -d --restart=always -p 8080:8080 -p 50000:50000 -v $JENKINS_HOME:/var/jenkins_home --name jenkins jenkins:2.60.3 # 查看 jenkins 日志 docker logs -f jenkins 初始化  打开浏览器，访问 http://jenkins.kenny.com:8080  # 在日志中找到管理员密码 docker logs -f jenkins # 或者在 $JENKINS_HOME/secrets/initialAdminPassword 文件中找到管理员密码 cat $JENKINS_HOME/secrets/initialAdminPassword  安装推荐插件 (如果你想自定义安装插件，点击 Select plugins to Install)   创建管理员账号   初始化完成  Gitlab 启动服务 (gitlab 集成的服务比较多，因此需要占用较大的内存，官方推荐4GB以上) # $gitlab_home 宿主机目录 # 我的数据卷目录是 ~/.gitlab export GITLAB_HOME=~/.gitlab docker run -d --restart=always -e \u0026#39;GITLAB_HOST=gitlab.kenny.com\u0026#39; -p 443:443 -p 80:80 -p 22:22 -v $GITLAB_HOME/conf:/etc/gitlab -v $GITLAB_HOME:/var/opt/gitlab -v $GITLAB_HOME/log:/var/log/gitlab --name gitlab gitlab/gitlab-ce:11.1.0-ce.0 # 查看 gitlab 日志 docker logs -f gitlab 初始化  打开浏览器，访问 http://gitlab.kenny.com   设置新密码后，使用 root 用户登录   新建 sonarqube 项目组   在 sonarqube 项目组下新建 demo 项目   添加主机公钥到 Gitlab\n# 生成 rsa 公钥和密钥 ssh-keygen -t rsa # 查看并复制公钥 cat ~/.ssh/id_rsa.pub  访问 http://gitlab.kenny.com/profile/keys ，将公钥添加至 Gitlab\n 将 sonarqube/demo 项目拉至主机的 $GOPATH 下\n# 在 $GOPATH 下创建 gitlab.kenny.com 文件夹 mkdir -p $GOPATH/src/gitlab.kenny.com \u0026amp;\u0026amp; cd $GOPATH/src/gitlab.kenny.com # clone code git clone git@gitlab.kenny.com:sonarqube/demo.git  SonarQube 启动服务 # 由于目前 sonarqube 官方的 Docker images 只有 7.1 版本，不满足 SonarGO 所需 7.2+ 版本，所以我参考7.1 的 Dockerfile 制作了一个 sonarqube 7.2.1 的镜像 # $sonarqube_home 宿主机目录 # 我的数据卷目录是 ~/.sonarqube export SONARQUBE_HOME=~/.sonarqube # 正式环境中应启用外部数据库服务来存储必要数据，在启动容器时设置如下JDBC相关参数: # -e SONARQUBE_JDBC_USERNAME=sonar # -e SONARQUBE_JDBC_PASSWORD=sonar # -e SONARQUBE_JDBC_URL=jdbc:postgresql://localhost/sonar docker run -d --restart=always -p 9000:9000 -v $SONARQUBE_HOME:/opt/sonarqube/data --name sonarqube kennyallen/sonarqube:7.2.1 # 查看 sonarqube 日志 docker logs -f sonarqube 文件：Dockerfile、run.sh\n初始化  打开浏览器，访问 http://sonarqube.kenny.com:9000   使用管理员账号登录\n 账号 admin 密码 admin    生成 token (作为远程连接 SonarQube 的标识，只生成一次，记得备份哦)  admin_token: 74439d5bc557dcc206fa8b1f2f5516e65680bdc8\n 安装插件 (进入 Administration -\u0026gt; Marketplace)  安装完成后点击重启 SonarQube 服务就OK了\n集成  将 Jenkins、Gitlab 和 SonarQube 有机整合  Jenkins 安装插件  点击进入 系统管理 -\u0026gt; 插件管理 -\u0026gt; 可选插件   过滤选中 Gitlab、SonarQube Scanner，点击下载待重启后安装  Jenkins 配置  安装 SonarQube \u0026amp; JDK  进入 系统管理 -\u0026gt; Global Tool Configuration\nJDK 安装\n​ 勾选我同意 Java SE Development Kit 的许可协议\n​ 点击 Please enter your username/password\n输入你的 oracle 账号密码\nSonarQube Scanner 安装点击保存。\n SonarQube Server  进入 系统管理 -\u0026gt; 系统设置\nAdd SonarQube servers\nName 随便填写\nServer URL: http://sonarqube.kenny.com:9000\nServer version: 5.3 or higher\nServer authentication token: 填 SonarQube 初始化时生成的 token\n 取消 Gitlab 授权  取消选中 Enable authentication for \u0026lsquo;/project\u0026rsquo; end-point，保存\n 在 jenkins 容器中安装 golang 环境及工具\n# 在 Jenkins 容器中执行命令 docker exec -it jenkins /bin/bash # 临时设置环境变量 export GOROOT=$JENKINS_HOME/go export GOPATH=$JENKINS_HOME/workspace/go export PATH=$PATH:$GOROOT/bin:$GOPATH/bin export http_proxy=http://192.168.1.100:1087;export https_proxy=http://192.168.1.100:1087; # 进入 jenkins 主目录 cd $JENKINS_HOME # 下载 golang wget https://dl.google.com/go/go1.10.3.linux-amd64.tar.gz # 解压 golang 包 tar -xvf go1.10.3.linux-amd64.tar.gz # 删除 golang 包 rm go1.10.3.linux-amd64.tar.gz # 安装必要工具 # vgo go get -u -v golang.org/x/vgo # gometalinter go get -u -v github.com/alecthomas/gometalinter gometalinter --install 配置邮件通知\n  进入 系统管理 -\u0026gt; 系统设置\nJenkins Location\n系统管理员邮件地址修改为你自己的邮箱地址，如 wyh3265@163.com\nExtend E-mail Notification\nSMTP Server 填写对应的SMTP服务地址，如 smtp.163.com\n点击高级，勾选使用SMTP认证\n用户名 注意不需要加 @xxx.xxx\n密码 填写自己的邮箱密码或授权码\nDefault Triggers 选中 Always\n新建 Jenkins 构建任务  新构建一个自由风格的软件项目   使用自定义的工作空间  点击高级，勾选使用自定义的工作空间\n目录：$JENKINS_HOME/workspace/go/src/gitlab.kenny.com/demo\n 源码管理  Repository URL：http://gitlab.kenny.com/sonarqube/demo\nCredentials：点击Add ，添加凭据 (Gitlab 用户名密码或 SSH登录等方式都可以) 构建触发器，选中  Build when a change is pushed to GitLab. GitLab webhook URL: http://jenkins.kenny.com:8080/project/demo\nEnabled GitLab triggers 选中 Push Events 和 Accepted Merge Request Events ，表示当 Gitlab 有 push 或 merge 操作发生时触发构建。\n 新建 webhook  在浏览器中打开 http://gitlab.kenny.com/admin/application_settings (请使用 root 登录)，找到 Outbound requests ，点击 Expand 后，选中 Allow requests to the local network from hooks and services 并保存更改。 (允许本地网络的 githook)\n进入 http://gitlab.kenny.com/sonarqube/demo/settings/integrations\nURL: http://jenkins.kenny.com:8080/project/demo\nSecretToken: 不填\n选中 Push events、Merge request events\n取消选中 Enable SSL verification\n点击 Add web hook\n 增加构建步骤，选中 Execute Shell\n#!/bin/bash # 环境变量 export GOROOT=$JENKINS_HOME/go export GOPATH=$JENKINS_HOME/workspace/go export PATH=$PATH:$GOROOT/bin:$GOPATH/bin export http_proxy=http://192.168.1.100:1087;export https_proxy=http://192.168.1.100:1087; # 安装依赖 vgo mod -vendor # coverage go test ./... -coverprofile=coverage.out # test go test ./... -json \u0026gt; report.json # vet go vet ./... 2\u0026gt; govet-report.out # golint golint ./... \u0026gt; golint-report.out # gometalinter # 执行 gometalinter 会失败,因此加了 || true gometalinter ./... \u0026gt; gometalinter-report.out || true 增加构建步骤，选中 Execute SonarQube Scanner\n  Analysis properties\nsonar.projectKey=gitlab.kenny.com sonar.projectName=demo sonar.sources=. sonar.exclusions=**/*_test.go,**/vendor/** sonar.tests=. sonar.test.inclusions=**/*_test.go sonar.test.exclusions=**/vendor/** sonar.go.coverage.reportPaths=coverage.out sonar.go.tests.reportPaths=report.json sonar.go.govet.reportPaths=govet-report.out sonar.go.golint.reportPaths=golint-report.out sonar.go.gometalinter.reportPaths=gometalinter-report.out  增加构建后操作，选中 Editable Email Notification  Project Recipient List 填写接收邮件的Email地址，或使用默认配置\nDefault Content 加上 SonarQube URL: http://sonarqube.kenny.com:9000\n测试 # clone demo 代码 cd $GOPATH/src/gitlab.kenny.com \u0026amp;\u0026amp; git clone git@github.com:yuhao5/sonarqube-golang.git \u0026amp;\u0026amp; rm -rf demo \u0026amp;\u0026amp; mv sonarqube-golang demo \u0026amp;\u0026amp; cd demo # push 代码，触发 Jenkins 任务进行自动构建 git remote add gitlab git@gitlab.kenny.com:sonarqube/demo.git git push -u gitlab master # 若 gitlab 仓库地址不是 git@gitlab.kenny.com:sonarqube/demo.git ，请根据以下步骤修改： docker exec -it gitlab /bin/bash vim /etc/gitlab/gitlab.rb # 找到 external_url，修改为 external_url \u0026#39;http://gitlab.kenny.com\u0026#39; # 然后执行 gitlab-ctl reconfigure TODO  解决执行 gometalinter 失败问题 Golang 质量标准，规则自定义 \u0026hellip;  ","title":"Golang 代码质量持续检测"},{"location":"https://bytemode.github.io/reading/10-2018-06-28-net-http-part4/","text":"  参与人数: 10 人\n Go 标准包阅读  Go版本：go 1.10.2  net包  http/server.go http/request.go textproto/reader.go  读取位置  textproto/reader.go(140行)  问题  1.各个系统的回车换行符区别\n  注意:10.13及其以上是macOS系统   2.URI，URL和URN的区别\n  查看详情   3.HTTP CONNECT方法介绍\n 会议讨论小结\n\t可以建立一个代理服务器到目标服务器的透明通道（tcp连接通道），中间完全不会对数据做任何处理，直接转发（支持https，一种翻墙的手段，专线独享）   HTTP代理协议 HTTP/1.1的CONNECT方法   4.peek读取字节内部实现\n  这里先peek获取流数据(注意：这里没有对Peek的错误进行处理，而是根据是否Buffered读取到数据来判断错误) 为什么没有对Peek的错误进行处理呢？主要是因Peek失败了也有可能不会返回错误\n\tgolang读取字节表现形式是阻塞式的，但其实底层是用了非阻塞式的NIO，如果没有读取到数据会定时轮询读取    5.http header尾部的符号什么情况下会存在\\n\\n的情况？(待解决，欢迎在下面评论)\n 看源码发现hearder结尾会存在\\r\\n\\r\\n和\\n\\n两种字符情况\n网络上查资料发现只会存在\\r\\n\\r\\n\n观看视频    TODO\n  相关链接  uri和url的详细规范 扒一扒HTTP的构成 20180628直播视频  ","title":"第 10 期 2018-06-28 线下活动"},{"location":"https://bytemode.github.io/reading/9-2018-06-14-net-http-part3/","text":"  参与人数: 12 人\n Go 标准包阅读\nGo 版本：go 1.10.2\nnet/http  server.go h2_bundle.go  问题  WriteHeader(statusCode int)   要先调用 header.set() 再调用 WriteHeader() 然后调用 Write()  如果在调用 Write() 之后，还有比较多的逻辑要处理，则一定要紧跟着马上调一下 Flush()  然后调用 Flush()   HTTP2 不支持 Hijacker\n 使用了 Hijacker 之后不能再使用 Request.Body\ntype Hijacker interface { // After a call to Hijack, the original Request.Body must not be used. \tHijack() (net.Conn, *bufio.ReadWriter, error) } The returned bufio.Reader may contain unprocessed buffered data from the client.\n CloseNotifier 主要用于 HTTP2\n CloseNotify may wait to notify until Request.Body has been fully read.\n HTTP2 中是如何在 net/http/server.go 中调用 serve() 触发的呢？\nif proto := c.tlsState.NegotiatedProtocol; validNPN(proto) { if fn := c.server.TLSNextProto[proto]; fn != nil { h := initNPNRequest{tlsConn, serverHandler{c.server}} fn(c.server, tlsConn, h) } return }  主要是 TLSNextProto ，然后查询得到 onceSetNextProtoDefaults() 调用。\n// onceSetNextProtoDefaults configures HTTP/2, if the user hasn\u0026#39;t // configured otherwise. (by setting srv.TLSNextProto non-nil) // It must only be called via srv.nextProtoOnce (use srv.setupHTTP2_*). func (srv *Server) onceSetNextProtoDefaults() { if strings.Contains(os.Getenv(\u0026#34;GODEBUG\u0026#34;), \u0026#34;http2server=0\u0026#34;) { return } // Enable HTTP/2 by default if the user hasn\u0026#39;t otherwise \t// configured their TLSNextProto map. \tif srv.TLSNextProto == nil { conf := \u0026amp;http2Server{ NewWriteScheduler: func() http2WriteScheduler { return http2NewPriorityWriteScheduler(nil) }, } srv.nextProtoErr = http2ConfigureServer(srv, conf) } } 然后是调用如下代码：\n#h2_bundle.go ... // ConfigureServer adds HTTP/2 support to a net/http Server. // // The configuration conf may be nil. // // ConfigureServer must be called before s begins serving. func http2ConfigureServer(s *Server, conf *http2Server) error { ... }  HTTP1 流水线，一条连接一个并发；HTTP2 是每个连接一个并发，每处理一个请求又是一个并发。  延伸阅读  HTTP2 协议 多路复用  ","title":"第 9 期 2018-06-14 线下活动"},{"location":"https://bytemode.github.io/reading/8-2018-05-31-net-http-part2/","text":"  参与人数: 10 人\n Go 标准包阅读\nGo 版本：go 1.10.2\nnet/http  server.go  问题  func (s *Server) doKeepAlives() bool { return atomic.LoadInt32(\u0026amp;s.disableKeepAlives) == 0 \u0026amp;\u0026amp; !s.shuttingDown() }  为什么要用 atomic.LoadInt32(\u0026amp;s.disableKeepAlives) == 0 ？\n原子操作比用锁更节约一点性能。\n server.go#Shutdown 不保险\n panicChan := make(chan interface{}, 1)\npanicChan := make(chan interface{}, 1) go func() { defer func() { if p := recover(); p != nil { panicChan \u0026lt;- p } }() h.handler.ServeHTTP(tw, r) close(done) }() select { case p := \u0026lt;-panicChan: panic(p) ...  外部处理就不能按照你的意愿去处理了，如果不拿出来，那么进程就挂掉了。\n // Deprecated: ErrWriteAfterFlush is no longer used. ErrWriteAfterFlush = errors.New(\u0026ldquo;unused\u0026rdquo;)\n Header() Header 注释引发的Trailer的思考？\n  观看视频   延伸阅读  HTTP Chunked Body/Trailer编码 example_ResponseWriter_trailers HTTP Header Trailer  ","title":"第 8 期 2018-05-31 线下活动 - Go 标准包阅读"},{"location":"https://bytemode.github.io/articles/2018-05-31-batch-del-redis-key/","text":" 1.首先看图    1.我创建了三个以go:read开头的key 2.通过keys go:read:*可以全部找出来 3.接下来退出redis-cli,使用redis-cli -p 6379 keys \u0026quot;go:read*\u0026quot; | xargs redis-cli -p 6379 del可以批量删除    2.查看原理    1.执行redis-cli -p 6379 keys \u0026quot;go:read*\u0026quot;控制台输出了需要的key 2.执行redis-cli -p 6379 keys \u0026quot;go:read*\u0026quot; | xargs -0 echo,可以看到输出了需要的key，但是有点不一样，双引号被去掉了,这说明数据通过管道传递给了xargs作了相应处理 3.执行redis-cli -p 6379 keys \u0026quot;go:read*\u0026quot; | xargs redis-cli -p 6379 del删除了输出的key,这说明xargs对接收到数据分别进行了redis-cli -p 6379 del操作    3.遇到的问题    1.同样的原理，我设置了三个key，但是这三个key里面包含了双引号,双引号前得加上\\转义符 2.使用redis-cli -p 6379 keys \u0026quot;go:read*\u0026quot; | xargs redis-cli -p 6379 del,发现没删除 3.通过redis-cli -p 6379 keys \u0026quot;go:read*\u0026quot; | xargs -0 echo,发现传输到xargs时把\\转义符删掉了，去执行redis del操作的时候key不配，导致删除失败 TODO 采用xargs我没找到解决方案，希望各位大神求助,有方法了可以写在下面@～@     4.另一种解决方案    for i in $(redis-cli -p 6379 keys \u0026quot;go:read:*\u0026quot;);do redis-cli -p 6379 del \u0026quot;$i\u0026quot;;done 采用shell脚本格式 -\u0026gt; for循环读取key去删除   ","title":"批量删除redis中的key"},{"location":"https://bytemode.github.io/reading/7-2018-05-24-net-http-part1/","text":"  参与人数: 10 人\n Go 标准包阅读\nGo 版本：go 1.10.1\nnet/http  server.go  问题  Next Protocol Negotiation = NPN Expect 100 Continue support   见参考资料\n  header提到了：Expect和host 判断了 header里面的HOST，但是后面又删除，为什么？  server.go#L980\ndelete(req.Header, \u0026#34;Host\u0026#34;)  判断是否支持 HTTP2 （isH2Upgrade）\n// isH2Upgrade reports whether r represents the http2 \u0026#34;client preface\u0026#34; // magic string. func (r *Request) isH2Upgrade() bool { return r.Method == \u0026#34;PRI\u0026#34; \u0026amp;\u0026amp; len(r.Header) == 0 \u0026amp;\u0026amp; r.URL.Path == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; r.Proto == \u0026#34;HTTP/2.0\u0026#34; }调用：ProtoAtLeast(1, 1) ... // ProtoAtLeast reports whether the HTTP protocol used // in the request is at least major.minor. func (r *Request) ProtoAtLeast(major, minor int) bool { return r.ProtoMajor \u0026gt; major || r.ProtoMajor == major \u0026amp;\u0026amp; r.ProtoMinor \u0026gt;= minor }  会议讨论 20:07:45 From 永京 李 : ok 20:07:46 From 斯 艾 : 可以 20:07:50 From joe sean : ok 20:07:51 From 洪范 郝 : 可以 20:07:54 From 力宁 关 : 可以 20:08:01 From 洪范 郝 : 可以 20:08:05 From 力宁 关 : ok 20:08:09 From joe sean : 有杂音 20:08:46 From 斯 艾 : 有声音 20:08:51 From joe sean : 有的 20:08:54 From Jayden Yang : 有 20:08:59 From 永京 李 : you 20:09:17 From Jayden Yang : 回声 20:09:17 From 洪范 郝 : 噪音太大 20:10:28 From caigaoxing : 2343 20:12:43 From 洪范 郝 : 屏幕卡了? 20:12:49 From joe sean : 1 20:12:53 From Jayden Yang : 1 20:13:57 From 迪 麦 : 屏幕是卡主了 20:14:26 From joe sean : 能看到鼠标动，看不到屏幕动 20:16:18 From caigaoxing : ok 20:17:25 From caigaoxing : 是不是不动了 20:17:45 From 和宽 熊 : 动了 20:17:47 From joe sean : activeConn是连接池吧 20:19:03 From joe sean : 又卡了 20:19:43 From 斯 艾 : 屏幕不动了 20:20:38 From kas li : 不行哦， 卡屏，只有鼠标能显示 20:20:43 From caigaoxing : 1 20:20:44 From caigaoxing : 1 20:20:44 From caigaoxing : 1 20:20:44 From caigaoxing : 1 20:20:44 From caigaoxing : 1 20:20:45 From caigaoxing : 1 20:20:45 From caigaoxing : 1 20:20:45 From caigaoxing : 1 20:20:45 From caigaoxing : 1 20:20:46 From caigaoxing : 1 20:20:46 From caigaoxing : 1 20:20:46 From caigaoxing : 1 20:20:46 From caigaoxing : 1 20:20:46 From caigaoxing : 1 20:20:46 From caigaoxing : 1 20:20:47 From caigaoxing : 1 20:20:48 From caigaoxing : 1 20:20:51 From caigaoxing : 卡了 20:20:55 From caigaoxing : 卡了 20:20:58 From joe sean : 1 20:21:04 From 建雷 张 : hi 20:21:07 From kas li : 卡屏，只有鼠标能显示 20:21:08 From caigaoxing : 不动了屏幕 20:21:09 From 叶 思杰 : 只能看到屏幕 20:21:14 From 叶 思杰 : 只能看到鼠标 20:21:19 From joe sean : ok 20:21:28 From brile ho : ok 20:21:31 From 叶 思杰 : ok 20:22:18 From kas li : 多余的视频关了，减少带宽使用 20:25:52 From caigaoxing : ok 20:25:56 From joe sean : 可以 20:26:01 From 夜 暗 : 先整体，再细节？ 20:26:02 From 龙 周 : ok 20:26:04 From kas li : 跳进去有思路，也是不错的 20:26:31 From yi zhang : 听到声音了 20:29:20 From 洪范 郝 : setupHTTP2_Serve 这命名不规范呀 20:30:09 From DW : 跟踪 listener 主要是做什么的？ 20:30:59 From ksir : 用goland不是很爽？ 20:31:09 From yi zhang : 用goland啊 20:31:12 From Jayden Yang : goland呢 20:31:19 From Jayden Yang : vscode呢 20:31:27 From DW : sublime 跳转也很好用 20:32:05 From 建雷 张 : emacs 20:32:53 From mai yang : 现在直播正常了吧。 20:33:07 From DW : 临时错误 20:36:18 From DW : 我还以为是动然规划算法 。。。 20:36:43 From 永京 李 : backoff 算法设置重试间隔 20:37:40 From DW : 协程数量有没有限制的？ 20:37:54 From 洪范 郝 : 可以 20:39:08 From Jayden Yang : 直接深入吧 20:39:12 From yi zhang : srv.trackListener(l, true) defer srv.trackListener(l, false) 20:39:21 From yi zhang : 这两个函数是在干嘛啊？ 20:39:46 From DW : 每连接一个连接，就 go 一个，会不会出现资源耗尽？ 20:42:38 From yi zhang : srv.trackListener(l, true) defer srv.trackListener(l, false) 这两个函数是在干嘛啊？ 20:43:29 From yi zhang : 嗯 好 20:43:37 From yi zhang : 谢谢 20:44:14 From 洪范 郝 : 代码为啥不一样呢 20:44:41 From 大 猫 : @DW 我感觉创建上百万个协程没事，而且一个连接处理完了，资源就会回收 20:47:02 From mai yang : go1.10 20:47:05 From DW : 也就是说还没有一个安全机制进行控制是吧 @大猫 20:49:54 From 大 猫 : 有没有机制我也不知道，如果系统实在没法继续处理的话，应该表现的会卡，然后超时 20:50:45 From DW : 单机应该支持不了那么多的 20:51:12 From jinleileiking : 提问的人说的话听不清楚 20:51:19 From DW : 这里的 context 主要作用是什么？ 20:52:18 From yi zhang : 控制其他goroutine的 取消、停止 等一些操作吧 20:53:05 From DW : 嗯，对应该是与其他 goroutine 交互的 20:54:08 From yi zhang : 哈哈 真的应该早点用用goland，没法跟踪函数，看interface的实现，简直就没法看代码啊 20:54:44 From jinleileiking : vim-go 跳转无压力 20:56:54 From DW : vs 无压力 20:58:51 From yi zhang : infinite 20:58:58 From yi zhang : 时间吧 20:59:01 From jinleileiking : { cr.remain = maxInt64 } 20:59:03 From yi zhang : 无穷 21:01:12 From yi zhang : 950 21:01:17 From yi zhang : :950 21:04:22 From DW : 主次版本 21:04:29 From Jayden Yang : \u0026amp;\u0026amp; 优先级高么 21:04:46 From cym : major.minor 21:04:47 From DW : || 最高 21:08:36 From yi zhang : // ValidHostHeader reports whether h is a valid host header. func ValidHostHeader(h string) bool { // The latest spec is actually this: // // http://tools.ietf.org/html/rfc7230#section-5.4 // Host = uri-host [ \u0026ldquo;:\u0026rdquo; port ] // // Where uri-host is: // http://tools.ietf.org/html/rfc3986#section-3.2.2 // // But we\u0026rsquo;re going to be much more lenient for now and just // search for any byte that\u0026rsquo;s not a valid byte in any of those // expressions. for i := 0; i \u0026lt; len(h); i++ { if !validHostByte[h[i]] { return false } } return true } 21:09:43 From 建雷 张 : godef: no declaration found for httplex.ValidHostHeader 21:09:57 From Jayden Yang : httplex.go 21:10:29 From jinleileiking : - var validHostByte = [256]bool{ | \u0026lsquo;0\u0026rsquo;: true, \u0026lsquo;1\u0026rsquo;: true, \u0026lsquo;2\u0026rsquo;: true, \u0026lsquo;3\u0026rsquo;: true, \u0026lsquo;4\u0026rsquo;: true, \u0026lsquo;5\u0026rsquo;: true, \u0026lsquo;6\u0026rsquo;: true, \u0026lsquo;7\u0026rsquo;: true, | \u0026lsquo;8\u0026rsquo;: true, \u0026lsquo;9\u0026rsquo;: true, | | \u0026lsquo;a\u0026rsquo;: true, \u0026lsquo;b\u0026rsquo;: true, \u0026lsquo;c\u0026rsquo;: true, \u0026rsquo;d\u0026rsquo;: true, \u0026lsquo;e\u0026rsquo;: true, \u0026lsquo;f\u0026rsquo;: true, \u0026lsquo;g\u0026rsquo;: true, \u0026lsquo;h\u0026rsquo;: true, 21:10:55 From Jayden Yang : /usr/local/go/src/vendor/golang_org/x/net/lex/httplex/httplex.go 21:12:06 From jinleileiking : [256]bool 下标是 ‘0’ 21:13:41 From 协 崔 : if deleteHostHeader { delete(req.Header, \u0026ldquo;Host\u0026rdquo;) }卧槽，我看到的是这样的 21:14:40 From joe sean : 1 21:15:17 From mai yang : go1.10.1 21:15:20 From Jayden Yang : deleteHostHeader 这个又是啥 21:15:22 From mai yang : 我们基于这个版本的。 21:16:03 From Jayden Yang : // whether Close should stop early 21:19:15 From 协 崔 : 有个 叫chunked的编码 21:28:40 From 马嘉 : 再来把 21:29:25 From 建雷 张 : \u0026hellip; 21:29:28 From mai yang to Henry Lee (Privately) : 刚刚网络问题中断了。现在继续。 21:29:38 From mai yang : 刚刚网络问题中断了。现在继续。 21:29:45 From 大 猫 : 屏幕没共享 21:30:54 From 马嘉 : ok 21:31:01 From 建雷 张 : ok 21:32:19 From Jayden Yang : 你们只能开一个 21:32:24 From Jayden Yang : 现场只开一个 21:32:34 From Jayden Yang : 音中音了 21:38:52 From DW : 什么样的客户端会使用 100-continue 协议呢？ 21:39:21 From Core Code : 这个是询问服务端是否支持大的包吧 21:39:48 From DW : 浏览器是不是自动实现了这种协议 21:52:15 From 洪范 郝 : // Buffered returns the number of bytes that can be read from the current buffer. func (b *Reader) Buffered() int { return b.w - b.r } 21:57:59 From Jayden Yang : closeNotifyCh is the channel returned by CloseNotify. 21:59:06 From Jayden Yang : 发送关闭信号给所有的goroutune 21:59:41 From Jayden Yang : // closeNotifyCh是由CloseNotify返回的频道。 // TODO（bradfitz）：目前（对于Go 1.8）总是这样 //非零。 让这个懒洋洋地再创造一次，因为它曾经是？ 22:12:04 From Jayden Yang : 看不到屏幕 22:12:37 From jinleileiking : 看不到屏幕\n延伸阅读  https://github.com/golang/go/issues/22128 https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-26#section-6.2.1 https://www.cnblogs.com/tekkaman/archive/2013/04/03/2997781.html https://benramsey.com/blog/2008/04/http-status-100-continue/ http://www.ituring.com.cn/article/130844  观看视频   ","title":"第 7 期 2018-05-24 线下活动 - Go 标准包阅读"},{"location":"https://bytemode.github.io/reading/other/2-2018-04-11_voice/","text":"在开始前的话，我就先闻着大概介绍一下。我我叫李亚春。李亚坤。那个网名就是亨利出实验，然后嗯13年开始写go，嗯写过几个开盘项目，然后主要有一个爬虫用猪，这个还有这个嗯开炮。今天我们要要介绍的一个然后还有就是一个黑狗，这就是一个外部框架。我叫吴良肖，然后我啊我毕业两年，然后我是从毕业的时候开始写够的，然后到现在没有开源项目，所以我的目标就是有一个开源项目。我叫武帝陵一个比较低的，然后我是整体来说，去年年底是开始觉得自己也写两个小工具放到D卡上面，因为现在我们公司要搬到S上面，学习架构云的与。BW好，我叫朱静涛，嗯够的话，我十年吧是对就接触这个语言，然后看他语法就特别特有吸引力，跟我之前是写开心嘛自己自己看，然后写一些小工具。啊因为我觉得作用呢没有开发。啊就是写小同学啊在做自动化U这一块。所以后面经常去去写的，嘛但是还是挺崇拜构造的内心就是可以这种进行动力。然后我我自己也是有写一些工具吧以前写进去。来来讲。啊大家我要睡觉前取的名字叫麦克。我也是13年开始学go，不是还没还没开始就是学的时候，然后剩下也没什么看一下。希望正在的专业开始这么说，好。我叫杨文，然后是了解够的话，应该是个刚出来的时候就知道，但是当时没有写对，然后过了几年之后才开始写了。然后现在的话也是在学习，学习吧那我们开始了。就是今天和大家分享一个微服务框架。那这个微服务框架的话，嗯其实是分为三主要是三个相关的库，一个就是那个暗室，这个案子是在小A公司的，那个然后嗯她主要是放在这个微服私访网关，还有配置中心以及一个一个脚手架工具。按那这个她恢复的框架是这个pp gun麦克。对，他是封装的这个开放的电影。实际上在写服务的时候都是用开炮。那这个提高MAC这个就是实现了一个呃就是服务，发现治理这一块的一些一些功能，实际上对业务代码没有没有影响。我们了解他的话，可以先先从那个案子生成一个项目，嗯这个是我是我那个安装好的一个案子，赢利。先看一下。这个命令，行，呢两个命令，一个是按指定，一个按摩院，这个店就是生成项目干嘛的，然后便是一个热编译的工具。我们可以先生成一个项目看一下，就就剩被告。啊这个是之前生成过，所以他那个先删一下。这个这个是这个好像看不到那个车。介绍。这个目的就是这样的。就是施工项目之后，这是一个任命，为动力里面就是只是把这个项目名称写到这里来。然后还有一个面，啊这个就是使用的那个et基因，做的那个注册中心。然后还有一个太太不是就是一些就是经历了一些类型，像刚刚我生存的话，他使用的是默认的一个模板，这个模板文件自己可以改。可以可以指定的。然后刚默认的就是这个问题。那这个这个代表就是说要注册一个嗯拉的一个物流，就是请求响应。所以这里面这是一个直接注册函数的那种方式，就是接受一个参数，返回一个结果，然后也可以嗯里边再套一个接口。这个接口就是在下面的定义，实际上它就是一个呃生出来之后，它就是一个结构体，然后里面的方法就是他的一个方法。然后还有这个这是一个朴实，朴实的话就是嗯推嘛他就没有返回值，所以他只接受一个参数，我们看它它生出来的这这个是他的那个类型。那个参数和结果。这个定义到这里，它会升到那个txt里面去。就是在那个开幕式目录下面。这里面就是刚申请的。没带。那么ATS这个后续的这个这个都是那里生成。那这一块呃态度是这里就是放那些定义的一些一些结构体的，啊通用的一些嗯结构体都可以在这里定义。然后嗯还有一个就是APA这一块，刚刚看到的那个max啊home和。S这两个就是后后面就会变成变成直接变成一个函数，嘛然后S这里边只有一个除法的，就是它的一个方法。刚刚这个定义的接口，然后这是那个推送。这个参数。嗯就是推送的话，他就会有那个前辈，这是一个上下文。铺然后如果是嗯推送的，就是这个刚刚是那个说出错这个是拉的，然后这个是推送的。像这这里面生成的文件，有的是带着这个点击，一恩典够，这个就是代表着生成的，是不允许修改的，因为在这个案子跟这个命令行工具会可以覆盖。重新生成的。就是你可以修改模板，修改完了之后，然后再运行，按它就会把这些带的这个后缀的全部都重新生成一遍，然后不带后背的这些，你可以自己。这是一个路由注册的地方。啊这个就是做一个分组。分组都有。然后下面这个就是在这个分组下，嗯注册一个拉个函数，然后这是一个拉的结构体验，就是把它当那个注册上来。然后这个是推的。像这个它只是一个自定义，就是说让我们在这个资金里面，这样的话就会影响这个视频的代码。然后它还会自动生成sk，就是我们调用的时候就不用再去写，直接就已经在这里生。在服务之间调用就可以。可以调，这个然后像这个态度为什么会单独独立出来就是就是这个sd T这一块它会用到哪些类型？啊这个类型。如果说把它放到其他其他位置的话，比如说放到放到这个逻辑层这个这里，边的话，他就会有很多的其他不必要的光导入进来。所以对SDK来讲的话，它是不必要的会有很多的依赖。所以把这些类型放一起。然后这个老者就是那个逻辑层的一些代码。这个他是身为一个呃临时文件，它就是建议你嗯照着那个去把把这些函数实现类型，实现这个函数之后，我们整个服务就已经写好，然后把这个名字改一下，就不要用那个名字，因为这个名字会在你重新申请项目的时候会会覆盖掉。这个文件是每次就如果新加一个类型的什么之类的，做一个自己的一个方法，就是都是覆盖到这个那个文件里面去。嗯他就是你可以随时去改这个模板，改这个模板之后，它会在在生成的，我我我们可以在这里再写一个，写一个。啊是这样的对吧？然后我再同意。然后回来再看。有了。然后在这里边写的一些故事，它也会自动往你家过去的。这里是没有注释的，对吧？然后如果给它加个故事，然后就是ap I叫憨豆。API下面的看到连这个都在这里。就是说你可以去重复，嗯像这个case这里的话，它只是生成的，都是空的，因为没那么智能，说你这些参数到底应该是什么？所以这块都是空的，到后期自己在写的时候，可以把这个把这些地方都可以给他真正的给它写出来。到底到底它应该是哪个字段是什么？你敢稍微改一下就可以了，整个整个价值都在这里。是改的话这个阶层。对。就是这种。所以这里边就是就是购买是吧？go代码就是go文件，然后我是通过那个呃购的那个语法树，也提出来，啊然后根据他的一些东西去去生产够像这些注释，啊然后包括嗯后面这些标签，你只要写在这里生成的时候，它会自动带到这边，然后还有就是txt里面，它会自动加。这个节省，它自动帮你加解释。这个标签。然后这里这里是有有一个标签叫胖，是吧？这个标签的话是绑自动绑定参数，并且校验的一个一个标签。这个就是方便我们嗯去做大量的那些参数校验。嗯其实这个有很很多的一些呃一些功能在这里，比如说嗯这个参数，它就代表说他是从包里来的一个一个一个一个阶段，然后它的范围是要在0:01到一万。啊10万。就是这一个范围，然后比如说嗯我如果加一个I参数，加油快累彪记啊就是表示这个不是来自于包的，而是来自于UI的。就是url。还有啥？然后还有一个教室唉这个参数，这个是表示它来自于嗯上传插件，写到了一个缓存区的，就是我们是支持插件在上层，可能把它寄到了一个上下文当中，吗啊然后通过这个时代交换区，这个含义可以拿到对应这个T的做绑定，然后也可以做校验。还有就是你可以指定他的名字，比如说我不叫我不叫比尔的bb，就这样子。如果说我希望他呃错误返回的错误，比如说它校验失败的，啊他不是那个范围的，那我我这里可以有个错误给他抽，嘛然后在错误码就是一千，然后再给他一个什么什么错误。随随便写。随便写，就是你写好之后，这个东西就是会把它作为一个错误码，还有吗？C嗯一起。发过去。然后其实还有一项是DKLDKL就是那个错误，因为这个错误是是框架自己定义的，就是通用的整个的从底层到上层的服务全部都是一个错误，这个错误就是有一个call的，有一个mic有一个底TL那这里的话你定义在后面这一段定义的只是他的max，就是你告诉用户给用户呈现的应该是怎么告诉她？比如我们经常说的是网络不给力的，那实际上它是什么错误？就是在tt L当中，他们校验的时候，比如他不在这个范围，其实它会自动帮你生成一个呃他是大还是小了。这样一个一一个具体的错误出来。还还要讲的。你那个参数是定义在哪个库里面？三个三。唉对，那个参数是定义在说那个错误，嘛就说这是拍卖这个弟弟，就是我要用什么规则去就是哦是吧，说在在哪里有介绍的，或者这里面有它的源码不是在不是在这里，是在EST扩展包里面的。扩展不。扩展库里边有一个单个人绑定，就是它实现就是他的他的介绍。他刚刚讲的这两个都有，然后其实还有一个描述是吧？啊这个这个描述就是你写了之后，然后会就是你你这个参数是增加一个描述。但这个的话其实呃目前来讲还没有用。实际上你如果要做就是自动化文档的时候会有用。API的一个介绍，啊这个只是一个宝贝参数。啊这个这个是一个长度，就是说比如你是一个字符串，或者是一个切片类型，那你可以指定它是多长，这个就是3到6。那后面这个例子，3到6，院子就是一个数数字的范围。然后这个是它是非零的表示不允许为零只。啊这个就是挣得，你可以自己写个正则。啊这个就是定义的错误。向这些前面出现的这些东西，都是都是在监控号的前部前半部分。都是在前面的。说比如说这个话，他他因为他没有值，你就这样写就好了，对吧？如果是峰值的话，你就要跟别的一样的，后面就开始写，啊往后面就写写你的这个啊，注意注意，这个这个不用引号和单引号。转义吗？原来？涉及到这个别的没有。他还会生成一个这个忽略文件这个是go的呃默认的第二行，它也会帮你摸人家这个这个所以他也会帮你加上。这是一个R一RS这个就是呃给的一个规范。你这个项目里边有一些什么错误啊就都在这里定义，一定遇到一个位置，这样就就方便看，因为所有的错误，它的它你看它的返回值吗？他的反馈都是两个。对吧？因为一个结果一个错误。这个错误是我们定义的，就在这里，然后加像这些字段这个这个这个长度一般都是自自己定义，吧嗯建议都是四位数以上。三位数以内的在网关那里会有的会帮你自动处理状态。就是网络上那个HTTP网关也发现这这个就介绍到这里吧啊，有没有疑问？或者我们想想讨论一下。在重庆没有。这个大一呃你生成了之后没有这个嘛反正是没有更新。啊你你重新更新一下，就是装这一套东西的化妆。这一套东西只要一个秘密好，主要这个这个他就会把相关的全部都拿下来，然后将那个案子命令的话要在那里再住一次到一下。这块没有问题。就是因为大家也没带电脑。大众在这个可以在U盘啊都可以，啊对，因为购物员本身是跨平台的，嘛不是不是它是跨平台的。如果这块没有问题的话，我们就介绍一些呃它的一些设计啊一些一些细节的东西，就这个我就给给大家一个感知，吗就是大概它是一个这样的一个东西。然后到底它是怎么实现的，给大家了解了解，然后也可以探讨。在讲这个之前的话，我大概说一下这个网关吧那个网关跟那个项目是相关的。这个呃微服务项目它自动生成的，这个是使用tcp都说使用的。服务发现的。然后嗯你外部访问的话，就要通过这个KTV去对外访问，然后这个DV的话它是嗯双网关支持长链接和http两两个的啊这个可以这个正好可以做一下演示。啊有啊三的。那个你你找那个武器。就是小A5系内饰。有个那个VIP的，连VIP吧也可以。你那个密码就不要去做一点。电流。就是在这个KTV项目里边有一个sample，有仓库里边有一个呃C口，最后就是说呃我给了一个简单的示例。简单的事例，就是这个是网关的实现代码，因为那个刚那个网关库实际上它不是不是面包，然后因为你需要去定义一些自己的业务流，它是整个设计是工作流内容去设计的。然后它的各种环节都是要通过一个叫fat is这样一个结构体去去设置。这个的话我们是一个默认的，因为它里面提供的默认的啊这个是最简单的。我们先看一下它境内的一个一个用法。我先把这个文件编译了，肯定只是就是模拟的客户端，然后server是内部服务。然后嗯这个是模拟的浏览器，还有这个嗯你能看到我打开这个，喂我刚刚是意识到啊这里头，这这这个你看它会打印一些东西是吧？这是他跟为自己做的一些请求，因为KTV本身是一个分布式，就是你这个月可以有，N个啊不管有几个，你请求谁都一样，它中间是自动做负载均衡的。嗯然后像像这个它是呃相互之间，它要更新一下他的一个嗯KTV的一个列表，就是嗯因为要做长两句的话，你要告诉他我的地址是是多少，对吧？所以它会有一个定时不定期，就是它它会定时不断的去相互之间去更新一下他的一个一个列表状态。可以吗？就是就是太到位。多，而且味道它们是不是通过自身的这种网络连接。橡胶不是不是直接通过网络链接，它是通过et CDEC基金是有配置中心，然后每个每个网关他都会把自己的信息放在EDCD然后通过ETCT它有一个事件监控，当有这个值发生变化的时候会通知他。比如说裤子或者是DS他会他会收到这个事件通知，收到之后会更新本地的列表，然后呢它不仅仅只是说一个列表，他会嗯做一个简单的一个呃测速，把速度较快的放前边，然后在短链接这里只有一个简单测速，但是在长链接那里的话还有一项权重都是当前的链接数，啊链接数较少的放在前面。你你的每一个请求就是给了网关之后，他会转发到其他网吧，不会转发其他网站，嗯就是好几个网吧，那那你是怎么在他们之间做个负载的是前面再放一个，就是实际上它就是你使用这个网关的话，它就不会帮你转到前往和。他是因为这要跟客户端去配合，你客户端，只要定期轮巡的到我这里去去拿列表，前几项优先，第一项，啊第一第一个如果木没联系成功，你就使用第二个，但基本上你每每隔一段时间更新下列表，使用前面就没有问题。那客户端自己去选择，对吧？客户端下载这个列表让他选择，对。他会控制在嗯是十个吧啊就是最大不超过十个，但是一般情况下，你只要拿第一个就对了。除非就是特殊情况，第一个没连上，那就拿第二个。那你这里那个ETETCT室打了一个。啊对。啊像这个他就是打印出来的，嘛就是这个框架开发的，也是使用配套的开发，就是所有的微服务也好，还是往观也好，都是开炮。它的写法日志，啊所有的都是他们一块。像像这个就是他支持打赢了他一个呃日志，就是这是APP的一个网络地址列表。然后这个是长链接的一个网络地址列表，现在我只开了一个，所以他就只有这一个。然后像这些的话都是S级别的，就是他他就是一T的试验中心，啊这个是保国，每隔五秒钟，宝宝一次，然后嗯把这个服务内部服务开起来。我们在使用客户端请求，把这个这条日志就代表他接收到了一个一个请求。这是这个日志它的含义，云英日韩一就是它代表是使用了一个嗯啦的方法，然后这个箭头指向这个铺是代表说他是进来的，他是写进来的一个请求。然后如果是发出去的，它就是反方向的意见。这个就跟那个购得很有钱。是一样的。嗯这个就是它的ip地址。然后这次喜剧的耗时，如果他很耗时多于某多余你设置的一个法制的话，它会使人忘记点，然后后面会会加一个思路一个标记，这是其中的那个APA然后最后这一个是你快速的ID啊实际上这个快速AD的实现就是呃开炮的通信包里边有一个circle，这是一个序列号，因为他是读写双工的一部分，嗯他所以说他需要一个对应机制，保证它并发读写的这个并发获取到的一个响应是自己想要的一条。然后这个的话它是使使用的死讯，所以说你可以就可以把它作为ss了，你自己去定义这个格式，只要保证唯一就可以。然后嗯配置里边我选择的是可以要打印包的，所以说他会把这个包的这些东西写到这里来。像这个是接收到的那个包长度多少，然后包的也是是什么样子的？这个是发出去的，那个吧然后嗯看一下这边对应的。这边是服务吗？对吧？服务队的这个请求。看他这里就变了是吧？不仅仅只是一了，刚刚看到的那个是一。是吧，有还有13是吧？这些啊他是把这个嗯这个东西是客户端客户端给的一个东西，就是嗯相当于一个session ID它这个筛选AB就是当你建立了长远D之后，呃你可以告诉对方我我的这个ID是多少，然后这里的话它会把它的鳃呈AB加上一个分隔符为A的服务，然后再加上他这个赛事里面，因为一次对话里面都是唯一的这个序号是唯一的，嘛唉加上那个就作为内部的一个SAT如果说没有设置那个赛城，A3是A地的那这个地方就是它的ip地址。那这边像这边的话，就就是那个客户端的一些一些返回的结果，在这里展示。然后像刚刚那个浏览器啊我们使用，只是做了两个两特市，啊这个就是测试成功返回的结果是啊因为短链低，嘛它就没有三婶，AB这个说法，所以他使用的就是他的ip地址。然后后面就是嗯我指定给他的一个一个一个excel，这个实物拍摄参数，可以给他的。然后你说客户端不是，他有一个嗯我要知道网关列表，嘛然后选择使用水的，像这个就是请了他一个接口，通过网站可以拿到。这个可能小，但是它不能放大。就是就是看到的那个解释，跟我们刚在里面看到的只是一样的。知道。这网官就就了解到这里。然后大概就介绍一下他这个这个框架是大概是个什么样子的？有哪些功能？找到重点。特性都列到这里了。一个是服务的自动发现，然后是定义服务的连接器。就是服务链接选择器，就是我们用et，CD其实它就是一个选择性。嗯默认的也有一个叫就是一个呃CAT就是静态。你可以指定静态，反正都是一个接口，这个选择性就是一个接口，你实现了那个方法之后，可以任意的去去设计自己的一个选择器，然后就是负载均衡，这个负载均衡就体现在客户端客户端上。嗯就是使用刚那个ks点够那个嗯这个单不先先不细讲，因为展开比较多。上次是给你介绍过我我我少。然后他是多付用的L还有连接池，可以自定义协议。这个协议就是说，我们的包协议这个数据包它是使用的一个什么格式？去去分包的这样的东西，它其实是一个接口，你可以自定义的。然后就是自定义包的。也就是嗯相当于ATPP协议里面的那个包被，或者说rpc调用的时候那个参数，他是有一个编码类型，这个编码类型也是可以自己定义的。嗯现在就提供了几个呃现成的一个一个是节省，一个是泡吧和，还有一个嗯就是原始就是那个普遍case。就跟那个http协议里面那个量子态就是原始数据。然后还有一个嗯UL copy那种编码格式，这个就是嗯提供这个就是为了兼容http。因为有时候你你需要它它的客户端，可能你没办法控制的时候，就是浏览器电话控制的话，就需要这样一个编码类型，然后就是一个插件的扩展这个插件也是有有很多的，也也提供了很独罩成的，像这里面你看这几个就差一点像像刚刚那个绑定，判标签就是他然后心跳包，还有忽略大小写，就是UA路径，忽略大小写，然后这个是加密，这是你的传输数据。可以做加密。啊这心跳说了。然后日志刚刚我们也看到了，漫山林阀值这个还没看，但是知道有这个就好了。就是在配置里面拷贝个配，配置文件就可以。然后嗯支持自定义的日志，就是说这个日志是一个接口，你可以自己传传上自己的，比如说你自己要加一个一个日志上报的功能，那你就可以自己定义，或者说我不希望输出到控制台，我只希望输出到某个啊队列呀或者是文件，啊对吧？反正自己实现还是然后平滑关闭和更新。这个就是说嗯服务都是支持平滑关闭以及嗯频繁重启的，就是平滑升级，不影响你的任何一次请求的。然后是支持推送，这个这个刚刚也也看到了。然后它支持的网络类型，基本上都是pp类的。就这几个。不支持，那个UTP啊嗯客户端是支持断线重连的。也就是你只需要一般我们写写项目，你看这个SDK里面的话，它其实就只只帮你生成了一个可怜者，就搞定了，因为断线重连那些东西它是内部框架支持的，你不用担心他会呃你你断信了会怎么样。然后再一个这里的客户端它也是有一个嗯客户端的链接迟的，不是一条链接，它是可以配置有多条。至至于有多少条的话，就是一个配置文件，选一下那个池子大小都可以。然后最后一个是过载保护。啊这个就是当嗯服务器状态，就是就是当前这个节点如果不太好的话，他就会嗯暂时屏蔽掉。哪一个？这个其实也是客户端的。像这些这些功能的话，嗯基本上像比如说嗯这个多路复用L然后自定义协议，然后剥一边密码，那个然后插件，然后慢享应还有日志，然后平滑关闭。推送网络类型，然后断线重连，这些功能其实都是开炮。在这这一块，其实嗯这个包封的非常的兴。整个代码我统计了一下，应该是不超过900行代码。他只做了一个啊这个是断路器的，然后增加了一个单子，像核电特稍微多一点，他就是这是一个配置文件，就是做一些自定义的配置。然后像实际上这个念头就是封了一下开part的一个P然后给他默认添加了添加了细胞。然后如果是服务端默认添加的心跳包和那个班的，然后他还有一个插件，就是Nike耐克其实是一个插件，但是实际上是这个插件。嗯啊就是这个这个包里面其实很简单，就是刚刚点开的这几个文件，就是基本上就是所有的然后大部分功能其实都在开在pop里面去。这个这个的话它是一个骚体的框架，然后像像刚看到的一些嗯APA的写法，那些东西其实都是他的，包括路由注册这些。这个的话因为比较多，我先大概说一下它。这个其实介绍框架基本上就介绍这个东西，吧然后嗯这个都是客户端或者是服务端，其实都是他一个东西。他的API是一样的。然后嗯这一块是插件，它是贯穿始终的，整个整个P的生命周期里边，每一个环节基本上都都有一个插件可以让你去定义的。啊这个是一个模特，然后对应了一个汉字，然后是C婶，她室友say声管理，然后塞上，你也可以设置它的生命周期，你要求一个赛程，比如说你在配置里面设置的，它只有一分钟，那么一分钟之后，不管垂帘上他他都会把这个删掉，它断掉。你不设置的话，它就是无限极的。然后嗯再讲下这个这个是上下文。上下文其实是属于塞车，再塞车里边建立链接了吗一条链接是一个cs，然后赛事里面每一次通信在接收方会创建一个上下的去做处理。然后这一部分是一个嗯其实就相当于一个呃骚体的高真正的一个商品。它是封装的那个嗯net点CON那个接口，然后嗯实现了一些功能。首先呢就是它是支持自定义协议的，这是一个协议接口，提供了几个默认的协议。比如说这里面默认的有一个是嗯嗯发就是发色协议，就是我我自己认为最快的一种方式，然后也提供了比较通用的，比如说嗯嗯阶层的。还有Top8克。这两个。嗯至于还有一种其实就是那种分割的啊分隔符分割的这个的话，我们一起但是这个也是很简单可以。做分割是最简单的。然后这个是那个call C就是那个包里的编解码，他也是一个借口。你这个接口就是你实现了之后，要注册上去，其实它内部就是一个mic，注册给他之后，然后整个整个框架都就可以使用它。这个就类似于那个标准高的一个给他ps。一包，它里面不是就是注册引擎，嘛注册引擎是可以用用对应的某一个数据库，嘛其实跟那个是类似的。然后这个是嗯传输的一个管道。其实就是他会对你已经封盘包了，或者说你封封包当中一部分，比如说包的一部分，或者说黑自家包的东西，它会生成一个字，节流，嘛把这个字节流，在这个管道里面做一下处理。比如说做md5的一个校验，或者是做TGAP的那个压缩，甚至是你给他加个密之类的都是可以的。这个也是。嗯跟跟这个是一样的。就是注册上来之后你就可以使用。使用的时候就是指定他的，ID好，这是一个内容。然后其实还剩下一个X拍摄的是一个抽象，他他是抽象了。一个数据包里面应该有哪些信息。然后因为有这个抽象，之后你才能够去嗯把这个协议做活，就是你可以制定协议，因为你百变不离其宗，总之你这包里面至少要有这个PAD里面的东西，嘛这里边比如说像刚刚说的一个序列号，一次请求的一个序列号，然后有包的还有开着，还有他这里边，就是比如说那个原信息吗还有一些错误，这些东西都是在这里面。其实这个协议实现就是把这个txt从资金流去嗯就是解析成txt，或者是从拍片子去编码成自己留。他的操作其实就是协协议的操作就是就是她嗯这个我们这整个的这个图有没有疑问？没有的话我们就去看。仔细看一下。这个后面的就是可以大家看一下它的一个测试数据。这个就是这个整个框架的测试数据，嗯测试环境。在这里是在内地一边侧的内存是16题，这个16和2.5克合资的，然后嗯他的测试结果，这是并发数。我感觉是不是我们应该看重，你看可能大家还得转换一下，还不太习惯。嗯这个是一个并发并发一百的时候，然后变化500是吧？然后这个是一个平平均值。然后嗯中位数就是取得那个就是那个最大最小的一个空间的。啊就是那个ts吞吐量。这是75000多。大概大概了解一下这个这个数据。因为这一块它是有三盛管理还有上下文的，所以说它的性能相比下面纯这个骚皮包。如果单独只是使用那个骚包的话，22万。就是那个368是这个其实外部的一些东西，都是基于他这个这是一个核心，基于它做的架构，让他更加用比如三盛管理啊插件啊全部是全部是基于他去做，他他就是一个东西。分包解包，然后这是它的火焰图。CPU的样子，然后内存的回来，基本上它是很平的嘛是吧？没有没有太多的那种非常明显的那种那种那种梯度是吧？这其实就是说明那个它的内部耗时是很小的，基本上都等于它的IO因为这这面这一层系统交易，这个这个其实就是IO了，那从这一层到最下面的一层，其实他差得很小。一小点。所以它的性能损耗是很小。啊这是内存。内存这一块你看到基本上都是刨土挖出来。这里看到的是吧？我测测的时候跑到八分，所以就是他的嗯就是那个解码的时候，它要战略筹码，其他地方也没有没有没有太明显的消耗。啊这一块是常规的一些一些数据，这是它的一些特特点。大概大概了解一下，吧刚刚其实跟那个收费服务那一块都差不多。啊这里有一个特别的就是可以对文件链链接文件的描述，进行操作，做一些性能优化。然后那这个也是做优化的。可以是他还通过这个呀这个他就有一个这个环湖的一个工具，就是结合那个go的一个够处死。你的ui pps，看这个图。啊你优化技术。嗯对。基本上一般我不会看他，因为这个感觉有时候也没必要那么那么复杂。就是简单一点的话，就是使用GPOF那个我基本上把他Top一列，我就可以定位问题在哪里了。然后如果那个不太好找问题，想直观一点的话，就可以那个好像是1.0，吧说是嗯计划要把它加进来，但是看到发布版里面还没有，但他计划里面是有的。就是说啊直接支持，这个下面这个都是一些示例代码。其实其实我不太会讲，不知道怎么去去技术。啊这些名名词解释刚刚其实在那个图上也都有。都讲过了。你们你们想了解想想了解哪一部分，可以说。其实要说的东西，如果我自己去说的话，可能会说很多，但是也有可能不是你想了解的。应用瓶颈啊效率，啊其实性能的话一般不会有问题。对。基本上你你在这个数据上，你可以大概可以可以看到它的数量就是在这里。然后他又是可以做多节点。分布式。所以这一块是不嗯可能在用的时候，有人提过的，其实就是说他希望能够加一点其他语言的客户端，然后使得客户的开发。唉对。嗯现在其实就有一个网友做了一个GS那个是GS的他是使用的max的一个包，因为我们也也提供了一个X的方，就是他支持那个高点，然后他就他就写了一个对应的客户端，嘛像其他语言的，我还不是不是很清楚别人有没有错，因为我我之所以没写，最主要原因自己能力有限，写别的语言也写不好，然后另外一个呢它不是非常必须的，因为嗯它是支持自定义协议的，嘛你的数据包协议可以自定义。所以说你可以在你的服务端就跟客户端协商好，你的心是什么，如果他不改那自己就改善型，其实也不是实现实现一个结合。所以这一块的话虽然不是很方便，但是也不会成为一个瓶颈的问题。我想问一下，记得那个tp的两个节点之间，如果这个通讯通信的话，我需要断掉其中一个，说要升级成一个东西，这个时候可能嗯其实这个问题，啊就是如果你只是使用tp纯TP这样子，用的话就两个两个节点，其实它不存在一个就是他没有分布式的这个这个概念了吗？或者说你就是你在客户端直接连了两个节点，那一个节点挂掉之后，你这个客户端一定是法律错误的。这两个节点之间，两个节点之间他不会丢数据，但是他一定会报错，如果一个节点挂掉，这个时间如果发还失败了，直接告诉了。对，啊报错是一定的，但是不会数据，因为它是平滑关闭。这一块怎么处理？嗯苹果关闭。它是它是利用了那个零六是那个紫禁城去接负极的那个围巾，那个对对对。那如果利多数据的话是没有断掉，他们那个就是这两个竞争，我现在仔细听起了，进入那个起个新的。旧的竞争会有的嘛不会啊不会啊不会，啊他不应该把那个没有处理完的他会处理完了。那那个东西如果我特别好奇的，这个他他有一个超时，就是如果你你是治他他给你设置超时时间，你也可以说我设置几个小时，这个是随你。啊反正你超时了，他会父亲他们会关掉。对，你你或者是处理完它会自然地关掉。又有一些数据的一些事情话的话，这框架支持，数据持久化，要写数据库。啊他是不管这事。噢就是从一个清纯一个恢复好像就就不管，但是我写数据库的话为什么不写？啊写数据库我可以推荐一下。我们现在现在用的是在这里边有一个。首先有一个专业知道，这个包的话是封装的一个write，但是他嗯把那个集群和单击点两个是疯疯到一起的，就是可以通过一个接口，没有差异的去使用，只需要配置文件不一样就行。然后呃我们其实还有一个就是我们内部用的就是基于这个外力是还有一个嗯那个说px那个那个吧分了一个带有VS缓存的一个一个方案，然后也有工具去生产它，这个可能我们将来会开元出来，就是把它集成到岸上，就可以，比如通过暗纯毛的去把毛泽东所有代码生成，其实我们内部有，但是我们现在还没有把它整合起来。没错。因为我觉得这些东西其实要做的话，就是我在暗室里面就在这个这个里面去做的，它不属于开炮开炮的，它就是一个纯消费的框架，啊给你便捷的一个使使用这个这个传感器通信的一个一个游戏。然后向微服务这一块的话，他就是给你提供你的分布式负载均衡这些问题。他不解决你数据库问题，然后解决数据问题的话，可以在这里去做，这也是我们的计划。这个跟单位是独立出来的，呢还是说放在一起？前面我们开通的。并列的事，他是一个包这个包是一个工作流，它会它就是抽象出来了，你的网关正常会有哪些环节去做，然后哪一个环节唉有一些必要的东西，他会要求你去去用，吧比如说嗯长链接一般都会要做授权吗？对吧？然后也也要去写一下他的那个呃又到了根子。像这些这些东西他会抽象出一个结果来，通过接口已经把这个包整个流程已经走好了。然后还有一些自定义的一些一些地方，都已经留好了，然后你只需要去实现里面的环节就可以了。比如说你的授权，你需要简单一点，你就是需要一个SO那你就可以实现这个接口的时候，通过采购呢去内部校验一下，然后交流完了之后，你返回一个错误，那他就失败了。返回没有那就是成功。就这样一个问题去写的。就它相当于是在那个tp或者说就是我们分布式的节点到外面的一层。南极，然后就是验证呢就是在网上做拦截，做校验，嘛这个的话其实可以大概给你看一下。内部用的一个写了一个简单的，这个就是我们内部中的根据我们的需求定制，像就是那个密码命当中，主要是这个这是配置。对吧？就是这个方法就是那个包里面的软方法，给它喂那个包里面就只有这个这个软方法启动它就可以了，然后他接收的参数就是一个配置，配置这样的一些东西。然后再一个就是变脸，变得呢就是你的业务。业务的话，你看我们实现了在讲这个参这个参数是协议，本地网关我我可以跟客户端去协商要哪个协议，然后这个就是实现这个协议。这个就是我们实现了一个业务，业务它是一个结构体，这是一个结构体，然后结合体里面有一个字段，我们这里都是。其余部分全部都是用的。默认的。然后只把那个授权自定义时间来的。这个授权是一个函数，嗯看一下我们资金实现的函数，模块，内部代码。不是。返回一个，那个这是这也是他那个get里面给的一个类型叫三通的。这个的话就是看一下它的定义，就是在这看着。是这个跟这个也跳过来了，啊搁在里面，这是刚刚我要实现这个这个函数就行了。那这个函数它反复这个类型，吗这个接口这个接口要有两个方法，一个是右ID，一个是嗯就是一个字符串这个事故快，其实就是一个头疼，嘛然后嗯像我这里的话就是做了一些处理啊是吧？做一些处理之后，我这是实现了一个这是我这是我们内部的实现了一个这样一个采购的一个东西。然后这里面就有一些字段，这个我定义的，反正我们内部要用，吗然后我主要是向这两个就可以了。这两个就是实现的接口。这样就实现的结果。然后嗯这这这个东西的话，这一块就是把那个函数写写写好了吗？对吧？然后我还其实定义了一下一个嗯短链接的时候，那当然请出来了之后，我要做做一些处理工作，这个就是自定义的完全自定义，默认里面也是空的。然后这里呢我就做了一些授权啊校验，啊签名啊什么，追加一些什么信息，到到UA啊就这我们简单看一下就好。的url是怎么？类API。我我想要增加一个一个API是怎么视频？网网关的话，其实它是利用了利用了一个我们看它的代码，如果是长链接的话，它是使用了一个代理他建的。这是对，这是在那个用一个solo，嘛对吧？这个思路实际上就是网关里面的对外的一个接口的在这个dota24号对外的这个服务。这个服务的话它就定义了几个插件，一个是校验查询，就是授权校验台面，然后一个是嗯就是你看到的就是我们前面说那个列表，就是我所有的那个网关列表都能列出来吗？那个插件。然后这个就是一个代理插件。然后最后这是一个嗯啊这个是做啥用来的？这个还这个可能是那个做事放。这个试运行的一个一个工整。数字是这个就是一个公式忘了，到现在我一下子想不起来做什么用是有用的。然后讲这个这个就是在tp杠EXT杆包里面。一个通用通用的一个一个插件，这个插件的实现。可以大概。嗯插件它首先是有一个监听地址，因为他要做代理，是监听地址，然后漫想应的一个阀值。然后是不是要统计时间，一般情况下都会同一时间，但要求性能的时候可能不统一时，统一时间是有系统调用，然后这个插件里面就是加了一个心跳包，然后他会把把代理的一个，因为它要代理的话，就需要有一个那个一个接口，嘛他就会把一个代理接口注册到你的路由上。这个这个ISI这个是它流出来的一个东西。然后来讲，然后呃重点就看一下他，这个还是一个初始化的一个就是当建立练习之后，做的一些事情。这里就是这个其实就是刷新了一下筛选，然后嗯把他的ID设置一下。这个是接收。比如说他就是有两个，这两个方法应该是。用跳错了。这个不是那个看了有点问题。直接打开了。这个还有两个袋里面，它跳到跳到那边去。那这个代理文件是做做那个网站的。嗯这个就是两个两个方法，就是说你这个代理是希望希望是做一个付的代理，还是一个护士的代理。然后这个的话就是一个护士和护都有个代理，就是全部的代理，然后它出现了一个接口，就是这个是为了兼容链接池，就是带电劫持的客户端和不带电电池的客户端，它都会有这两个方法不可忽视。然后就是这也是抽象的，重点看这个在铺和护士这两个东西就是嗯当代理的时候，就是他会这是一个an中是吧？他认为是代表为之。就是意思就是说当我找不到路由的时候，我就会到这个里面来。找不到路由的，他就是相当于是代理了。然后这一块的话，像我们刚刚看到网站不是会有一个touch ID吗就是在这里设置，它把三乘AB加上ICQ设置上，然后它是一个sad，sun就是一个管道函数，管道函数就是呃pet它是不对外公开接口的，你只能通过这个管道函数去给他做设置。然后所以说做之前会有会有一个管道函数的一个切片做准备，向这个就是说给他类似请求代理请求，给他设置一个sq sq传递传递那个收据，就传传递开cad吗？传递下去的话，每一集都会有，它就可以做跟踪了。然后这个的话就是便利它所有的源源信息，奇缘信息，你就理解成就是拍的是GDP里面的黑的信息，就是原信息它的编码方式试试UL考点。啊这里就把那些便利了之后，就把所有元气集全部copy一次，然后设置上。然后这是一个6IP就是有时候我们会需要你嗯知道客户端真实客户端是谁吗？因为有多层代理或者多层转发，这就是一个UIP的一个设置。内部提供了一个固定的一个一个mac P涉及到这里边，然后框架就可以很方便地获取到了。然后这个的话，就是坐井桥的铺放就是你传进来了一个客户端，然后它是涉及到这里边来了吗？其实就是外部定义的，刚看到这里。啊这个靠着定义过来的。其实就是就是一个客户端。一个P请求完了之后，他会把请求也有一些元数据吗？把那些原数据在散步回来，现在过来，就是因为它是一个交替的就是请求请求和响应，它是一个转发的机制，嘛所以它有一个复制的过程，会把原数据再复制给当前的这一个请求，然后如果有错误的话，会对对错误做的一些一些处理。像这一块就是因为你是做代理，所以说有一些错误，就就要把它处理成是网关错误。啊最后是返回了，这个结果这个结果的话是一个资金，就是嗯你你你的就是接收接收的这个流出来，如果是一个资金流切片的话，他就不会做任何的解码，就原封不动的把资金流就转发出去。所以这里边做的做的处理仅仅只是那个原数据，护士跟他是是一样的一样的逻辑。这就是那个网上做代理的一个核心代码。现在的话那个还还没有做爱。其他的其实很很多都是我们还是一直在在讲这个广告这一块。啊网络这一块他有一些定义的一些一些规范的东西。像这个P网关的话，如果带着这个拍摄参数，那我就会把它认为是快速AD然后内部的请求的icq，就会就会就是加上她，然后再加上那个ip，然后http状态码的映射关系，这个这块嗯，其实嗯如果是返回错误的话，这个错误是跟状态码是相关的，在APP这一块有映射。这一块。也了解一下。这是http网关的。嗯还是http的，它的服务端，对外服务端用的是发回tt，然后他做了一些一些转板，啊包括像这个site，其实他就是说支持支持这个编码协议的编码协商的，你希望要什么编码，那么这个框架会给你提供的一个对应的对应的编码类型，如果你你不要求的话，你用的什么编码给我，我就用什么编码给你。这就是黑的，嘛在黑客里设置了，这个他就会按照这个来。然后向向这个类型的话content，这个它也是有心事的，你要是这个你还的是这个的话，它就使用超过八分的。这就是ps的。然后6IP就是gm http协议的，然后那个状态码刚刚说的在这里，错误的时候，如果返回的，那个这是那个我们统一的内部错误，嘛如果他的cold小于200，因为在内部嗯一百多的状态码，它都是客户端错误，然后嗯400多的还有500个，它都是属于请求啊服务端的错误。所以这里如果小于200的话，我就会给他返回500，就证明是内部肯定是有内部某一个环节请求失败的。客户端请求失败的，所以它也是属于内部服务错误。就改成给它改成一个状态，码量就是500。如果它小于600的，对吧？如果他这个就是说先判断不是小于200，如果不小于200就200多。那么它又是小于600的，那它就是我们正常的http状态码，那我就把它直接就作为状态码出现。如果是大于600的，那我就用299。299就是说实际上它是业务错误，就是你返回的状态码，所以这就是一个约定，嘛就是你如果说希望它是一个业务错误的状态码，而不是而不是说通信级别的状态，码的话，那你就不要去设置的，它小于600。其实你一千以上的就是最好的。自己去订那些都是属于内部错误，然后客户端去处理的时候，或者浏览器在处理的时候，吗就是你发现是个两二九九，那就证明他是有错误的，但是是属于业务错误，没有通信错误。那这个时候你就包在里面，就是那个错误就就是这个结构体，body就是它的一个结构体，就可以做解析，如果是200，那它就是对的。那那玻璃里面的东西就是你想要的那个结果。我也不知道讲啥。对。现在点。9:20。那还有什么问题没有？今天我感觉也不太适合深入，然后我们先大概先整体的可能都了解了一下，然后我们可能要下次再分享，就具体可以讲一些代码级别的，就是说设计级别的一些东西。啊现在我们可能大概知道唉我这个孕妇是个什么样子的东西，然后用是大概是怎么去用的。可以说一下，你当时是想要写这样。嗯就应该还要很懂很多，STP原理吧看，就是从你试用商品那个库去拓展那些是什么？呀嗯对，就是其实它的核心最核心的就是那个骚P图。扫K包它封装的就是标准包里面的net点。connet点C接口让那个接口。就是你那个接口做嗯嗯其实它这个包实现的其实实现了功能。最大的问题就是把那个协议层抽离出来，可以做定义了，再不投资定义的，这是它最最大的功能。就是你的数据包怎么去组织这一块，就是我支持定协议制定协议就是那个商务包去做的，然后我嗯发消息收消息都是通过这个消费者去做。然后她就靠这其实就是在他的基础上去扩展我扩展插件，然后会话管理上下文，然后嗯还有什么日志，或者还有其他的一些一些东西，其实都是拓展东西。然后嗯其实做这个一开始，我我一开始其实写的是115年的时候嗯写了一个1.1个版本，那个时候他就是一个点对点通信的一个一个set，然后用在我写的这个爬虫路上，嗯那个幽灵蛛分布式的时候，然后嗯然后去年的时候，因为公司也要做为服务，那个时候就先把公司用公司为服务，当时是用的。嗯啊PC。那个标准包去其实是改的，我把它代码全部copy copy出来，基于它的代码去改，但是实际上其实是留有遗憾的，他那个架构后面我是不认可的，因为我觉得他那个架构不适合做大项目。然后后面我就想因为积累的一些想法一些一些一些感想，然后就就想着要重写一个东西，然后后面就结合我当时写的那个开放的1.0的一个思路，去去写的，现在这个现在这个已经是3.0版本。嗯然后他他的最主要的思路就是什么？嗯我希望它的客户端和嗯服务端是完全一致的。点对点。对的通信。不管你是推还是拉，都是完全一样的。就是基于这个思路去做的，首先是疯了骚气的包，然后再基于他去分了很多的一些一些东西。其实我就是建立链接之后，对于TPP来讲，先练习之后，其实它没有区别。是吧？所以说刚刚刚那个质量为服务里面是有思路和可信的概念，那个概念仅仅只是对P2的封装，封装就是给了他不同的插件，插件插件的不同，它的角色就不一样，实际上本质它都是相同的。所以像你你说我可可以用客户端去作为服务端，就是我我我也注册一个路由，然后让服务端请求我。是可以。怎么去用的话，其实就在于业务去设计。嗯像其他的一些这里边用到最多的东西，其实就是接口一个项目，不管是开炮者，还是嗯那个mic一起装MAC，然后还是网关，其实都是基于接口去写的，然后所有的东西都是可以自定义，自己去实现的。可以举一些例子。举例子的话，比如说嗯这个协议是不是可以自定义这个接口？其实没有一个很好看的东西，就是说你可以下能够看到他的一些一些定义的一些东西。嗯像这个呢是一个接口，这个也是一个接口，这是借口的欺骗。嗯啊这是这是一个借口。他就是就就是他们只是多个多个这个set组成的这个管道，然后插件肯定是借口。say是虽然赛事它不它不是一个接口，但是他分了很多的借口。因为插件在不同的位置，你你需要去可以去控制的东西是不一样的，所以说有些地方你需要用到这个塞车的某个方法，有些不需要用，所以它就分了很多的接口去对应你在当前这个位置能够用的那些方法列表，给你列出来就一个接口。其实这就是涉及到接口，它是有一个作用，它可以限制一个结构体的。呃方法及你希望给谁用哪些方法，那么你就定义这样一个接口给她。康泰斯其实也是一样的，跟赛程是一样的，它底层其实这个结构体，但是我给他分了很多得很很多的这个空txt，其实就是对应不同的场景，使用不同的方法，然后这个猪者视频都不是借口。就这个工程不是理解，这个都是一个借口。骗也是一个接口，然后向着里面微服务里边的话X是一个接口，因为这里面只有一个单子，对吧？可见这个思路他都是封的P只有两可，他还是一个接口。就是这样。所以嗯每个环节都是可以自定义的。像刚刚说的那个杯子例子，就是在网关着里的那个那个就是你要自定义网关，其实就是实现一下这个结构体，它这个结构体这是一个类型函数，嘛这是一个阶段，这是一个介绍，这是一个借口。都是借口。所以他就是方法就是一个工作由所有的东西都是跑空的，我给给了一套默认的，你可以把它覆盖掉，用自己然后写这一套项目。感觉用的最最拿手的一个东西其实就是借口。唉这个东西确实确实挺好用。写的这个这个最麻烦。写的时候觉得最麻烦。最麻烦的是哪一块？是吗？就马上的实际上是。嗯30。33。那一块的逻辑其实超复杂。最最复杂的是什么？呢断线重连，啊然后清华关闭，啊因为你要做一些就是那些测试。对，测试，然后。其实是关键是他的场景很多，比如说它断了线了，那你这个三婶实际上他是对的，他没有觉得区分的，但是你内部处理的时候，他肯定是不一样的，因为一个链接总有一个发起者，是吧？然后断的时候是谁先断的？那这些这些他报的错误都是不一样的，然后你就要去接你那些。然后你要让他能够平滑的对外表现完全一样。其实这一块是很复杂的，然后包括一个链接，你是不是得不能说一个请求卡死到那里不动，吧所以说你要有一个超时，所以就做了30的生命中心。然后还有一个康txt的生命周期，像这些它它也是需要需要很很就是很很很细致的一些一些设计。其实总的来讲的话，其实就是一些状态，关啊那个错误那个场景上。你怎么知道？是测试的情况下，就是就是自己自己可以把侧面遇到的。基本上是侧靠次就是就是自己就知道有这种场景，你去对想那个场景，然后看一下会不会有问题。这样这样去测。还是要经验。这个肯定离不开过，你要是立场，你要是这个至少应该把他所有的一些一些细节的东西肯定是知道的，就是我们验证的仅仅是你的逻辑，你的逻辑是不是能够符合？处理那些事情没有问题。有没有bug？嗯可以我们可以大概的看一下这里面的一个代码，我们再再搞半个小时最多不超过十点，不然的话可能大家喝下一碗，像这个就是刚说的那个接口很好，诠释方法进行。这些还有相互相互包涵，做定义基础的呀什么之类。像这种方法就是验证这个我这个cs就是一个结构体。这里就是有一个原则，我不对外公开的东西，我一定不会大声。嗯就是你在我这个项目里面，凡是看到你能够外部调用的东西，一定是可以给你用用的。然后你给你的接口里面有这些方法，你在这个特定位置一定是可以用的，不会有问题。不会有看着。我就是验证了他实现了。实现的这个接口没有问题。嗯像这个就是三婶她的一些资料，嗯项复杂的一些地方，那这个就比较复杂。铺的话因为它涉及到了两端封信，沪市A点的初始你发过去，成功不成功，就不管了是吧？但是库你要两边都要坚固。就是像这一块的话，比如说失败了，也失败了，它是有错误的，啊这是错误的，你空了啊啊内部的话也是re啊re，啊我这里边就是简写就是那个结构体错误这个问题，所有的错误基本上都是这个内部和外部都是统一。然后他就会有一个从严，啊这都是座重檐的。这个方法是做出来的，虫源这一块，那个绕了很多圈子在这一块。套了套了几层，然后这个就是说嗯他要是断断开的错误，啊我这里有个判断，这个错误，如果是链接断开的错误，那么并且我这个重联是成功的。我就从这个沟通我就重新去写一下，否则的话，就是他就把这个这个嗯CMD这个就是那个酷的结果它是一个控制，其实就是说它上面盖的一个方法，返回的返回的东西，不是说就是只有一个结果，其实他是带着一些方法的，就给他标记为完成。这里面封的是一个是两个管道，石油管道的。因为她要支持一步的，就是说这个库你可以支持一部，七条也可以支持。同步请求。那不管是徒步一步，其实他内部都是一步的。同步就是为了就是在某个位置阻塞给他，让他投入，然后就是那个推送，然后还有一个他这个那个是断开了。先看。啊这个这就是一个毒的携程。每建立一个链接，不管客户端还是服务端，反正两端都会有一个独字写成。这个写成里边的话，就在这里做了一些处理。啊这些都是这这里边是分的是一个是一个一个一个数字标记，他是一个原子操作，就是标记他状态，看它是不是能够继续继续。其实能不能继续读，就是看他是不是断开链接啊什么之类的一些东西。然后这一块，这一块就是独，嘛然后如果有一些问题，啊然后它会返回。像这个这是技术。这个技术这是个这是一个微波炉。唉都是苦的。他是为了实现频发关闭，因为你要去统计内部的状态，才能够知道是不是把事故处理完了。然后我的并发内部的并发全部都是封的。协同迟。没有直接用go，因为你要做大象大象的话，你的量大了，他有可能为什么封掉？但是你内存疯了，绝对会有大量的速度，那那后面的事情就处理起来很麻烦了，所以说我们要控制内存。在你建项目就是你这个呃启动项目之前，你就已经就想好你的服务器内存是多大的，然后你在这个形成时大概一个携程是不超过8K对吧？然后你就大概计算一下，你这个服务器到底能够承担多少并发量，都可以计算出来，然后你这个go的携程设置不大，所以这里使用的都是携程迟。这个就是在携程里面运行的一个函数。嗯这个函数的话像这个就是处理函数的。就是一个你读过来一个包，你怎样去处理它，不管是接收的响应，还是接收的请求，接接收的推送，它都是需要去做处理的。都这些处理都叫hello。在内部都是很low。就在这里面做的处理，这就属于上下文的。这是上下文的。先生就到这一部分就是结束了。然后像有一些错误啊断开链接的那些东西，这个东西会退出吗？这个东西推出来之后，推出之前李凤会掉，这个这就是毒发生了断开链接的问题。在这里面它会尝试做重联，然后包括一些嗯如果是客户端的话，它会有它会有一些等待响应，嘛你链接都断了，Sarah都不是那个财产了。所以说这些东西这些你等待想要的结果，一定要给他返回错误的，要给它关掉。飚这边已经处理完了，但是有问题。所以就是在这一块做个处理，然后把这个筛选资源释放掉。如果他是支持重连的，对吧？你退了，可以让他出面，那他就在这里做充电，充电了之后，然后嗯这里有一个就是就是说你看他初恋失败，就是它它会长成一个cool，如果是处的话就成功了就就不用管了，如果失败的话，他会调一个接口，内部的这个插件，这是一个插件的容器，它就是一个插件管理。这一块就调了一个接口，就是当你的掉线了，嘛对吧？你又没春联，这个时候如果你比如说是在网端掉线了，我就要去去更新他的呃OK的信息，嘛这个时候你就可以在插件里面去做，就可以释放掉它的这条这个客户端的信息。像这些的话都是因为这一块重连的比较复杂，它会涉及到一些状态，像这里都是一些状态，状态标记他是哪些状态？怎么去处理？因为有可能，因为这里是支持并发操作的。就是你你正在观也正在段，那在你关的时候他也断了两个逻辑同时跑。就会有问题，所以说这里就会有状态状态管理，去保证并发正常。这个就其实我觉得大概大概的说一下，因为那个讲代码，估计大家也根本看不进去的。或者因为我我在这里讲，然后大家也没看，嘛你看我肯定是跟跟不了这个思路，只能说我讲的只是一个大概思路，你可能知道我的实现思路就够了。啊代码逻辑有兴趣的可以读一读。这个塞塞车后果。就是所有的赛事都存存储在这里。嗯赛事通过IP进行，所以赛事ip默认的是远程的，就是对端的那个地址。ip地址。但是你如果做长链接，你肯定要把它重新塞提一下赛程，你你希望设置的右ID啊之类的。然后你像做推送，我就可以通过这个赛事后果，我去可以拿到我想要的我给谁？推动型。通过UIDR就是那个带上ID，拿到C婶就可以给他推。也可以。广播直接用RAM赛事，每一个look做。其他。其实这一块讲得也可能差不多。但是有上下文，上下文也比较复杂，但比赛是要简单一些，这里面提供的都是用户可以用的一个对外的事，就是呃给客户的一些接口，然后向里边主要有两个方法，一个是班里，一个是hello。这两个方法就是对接的稍稍品，单点就是商品的内部要调一个因为你读到了包之后，你要怎么样才能够知道包得用哪个结构去做解码？对吧？这个映射关系是用班里。就是嗯在在那个协议里面读了UAUA之后，不到UI之后，就可以通过这个UI去找到你那个路由里面去定义的，当时你定义的那个路由hello是是是谁，然后通过反射去new一个接收体去解码。他那个就是做处理，当你当你把整个包完整的已经解码完成的以后就做hello处理。这个的话也是分了分了三类，包有三类，一类是响应，一类是推送，一类是请求，就是三类。三一般有三类的处理方式。后面呢就是一些具体的某一每一类的实现，每一类的视线其实都都是拆开的。这些这些东西。然后后面这个一个小东西，就是铺的一个一个接收体积，就是掉了客户端调的那个护方法之后，它会返回这个这个接口。那这个接口的话，它会有一些实实现了一些一些方法，你可以拿到拿到它列出来的这些东西，比如说你掉了之后，我直接就我不需要，因为我们正常如果做性能测试，我想知道我调这个接口用了多长时间，你还得用那个炭包去搞，其实没有必要的。这个都已经内部做了统计了。这个就是统计，你只要拿到结果，直接把它打印出来，就这就是一次请求的耗时。然后这是input，其实这里边有两个概念，因为他没有请求响应的概念，这里面全部都是铺铺是input凹透镜，就是输入输出啦推这些东西。输入就是说相对我这一端，把我这一段写东西就叫输入，然后我这一段写出去就叫输出。它端的概念这里边也没有没有别的。没有客户端服务端的概念，就是说我在这一端，我的输入就是在这里，这个音库的其实就是响应了。响应的元数据就是说它的那个黑色的部分，我可以拿到看看都有什么东西。然后它返回给我的包，这部分的编码类型是什么？反而给我的结果是什么？这个站当你做一部请求的时候，并发请求做这里边有一个方法就是嗯一步的一个库，那个时候你就可以调这个，但就是在携程里边教，这个但等待他结束。结束了你就可以拿到苹果了。如果是阻塞的直接调用库的，就不需要管这个蛋。这个蛋在内部已经掉了，这就是错误。所以我们正常用的时候都会直接，你看我们用的都很这里。我们正常用的时候都是这样的，我直接就那个除了cm地调查，我只需要看这个结果。这个错误是不是内容可以。都是这样的，因为你其他信息一般情况下也不用，就用这个信息最关键的，然后美菲克拉当你不做一步的时候，实际上啊那个美造成那个伪造的方法实际上是没有用的。你你不会去掉了，你造之后再去断言它是什么类型。因为这里的话是做这样船坞作船坞指针绑定的，你直接拿它就是结果，但是你做义工的时候就行。衣服的时候，你你这些结果你不可能去一开始就就知道的，或者说你你就知道什么时候它就结束了，也值了。这个东西你要靠主色的，嘛所以说就不太方便，就可以用道去去直接去用的。然后别的。还有就是它支持上下文，它这个对抗态势是不是上吊的？你可以规定你这个是请求。那个嗯他的一个一个一个条件。上下的那个包，你们了解过？看到过。他可以控制时间，是吧？也可以。主动取消，这个的话就便于你一次请求去怎么去控制它，它可以穿过空txt，它这个传入这种方式，这里再开炮的也是一些势力，也是在配置的生命周期这一块，啊生命周期这一块，首先我这里再配置的呀我都推了。服务端这边我可以的，啊作为服务端这边K的超时时间，过了这个时间断开链接了，然后呃客户端这边的话，应该是能到这。这是一个康泰克剥吗是吧？标准班。然后设定了一下三秒时间，然后我用pp VC炕txt，因为这些它是管道管道函数，嘛他是嗯这样定义的。就是这样的。后面这个你就可以配你这个包，各种设置，比如说我去指定他的icq，然后嗯指定是不是要嗯比如说那个管道，那个那个管道过滤，那个我可以设置它，GJIP压缩。其实有有很多一些方法都已经都都是这种TP可以直接掉到PPVC开头的就是这里边的一些管道函数，这里边这是其中一个。和case这样设置之后，你看我下面，如果这个康X超时，啊就是这样完成了就会说他是已经超时了，嘛对吧？如果没有的话，这是正常返回的，吧我就把这个取消掉，这个把它取消掉。那这里我也是用到了一个义务，这就是义务教育。这一块我看这个是专门的用户调用，就专门写的一段的。他一步调用的时候，这里是批量。啊批量的。批量的时候我会先给他一个券，然后他会把结果写到颤动，就在提案当中去接收，接收每一个都是这个然后伪造的，啊这就是一硬物的时候，基本上会这样。再说点啥，呀还有十分钟就要！就不要那么计较不计较。这个我觉得这次已经很多支持了。啊对，很多知识点。那就可以闲聊一下，然后嗯有些技术对技术。对。就可以抛开这些。可以随便聊一些东西。一些业务啊也有嗯业务上的话，实际上如果你是纯A市GDP的，嗯其实不太好的。因为他在做网页处理的时候，html的时候，方便呈现那一块，呢教给大家一个做一篇是没有问题的。然后嗯目前我我实现了一套方案就是为服务，但实际上我们还可以做一些嗯比如说其实微服务，其实也包含这个就是说推送推送服务，因为它事关就是那个那个对的通信的。然后嗯也可以做去考量。金钱比较火的。漂亮那个研究一下端对端。基本上其实他怎么讲，呢就是说基于tcp去就是tp这个框架，你做KTV出现的一些一些服务其实都可以用的。cs。线。啊就是这些。嗯它是它是对等的。嗯就是你怎么用？其实看这个业务吗？其实你看接口是相同的，他就是一个P浏览一下他的API的一个这个主要就是建立一个长连接，这是它的一些方法。他们都是一样的。就是只有一个只有一个。PMP它只是一个牛P这这个角色那你说他是服务端客户端看不出来的，对吧？然后它的方法，这个P它有一个戴尔，对吧？这样方法，还有一个cs。这两个方法是唯一区别，它是客户端服务端的概念。但实际上当你掉了这个方案以后，他没有任何区别。这个的话，就是你给他个链接，他不管你是客户端还是服务端，得给他个链接，它就能使用这套框架。在我我们这边首先要要主动开一个单子，客户在那边的话，嗯网关的话就是微服务。微服务微服务那是是开炮的一个使用方向，应用方向。就是你如果用微服务那一套的话，你只需要在你的鸡群对外开放一个开放两个端口，一个是http的，一个是tcp的，两个对外端口，其余的都是内部。然后所有的都是可以任任意多个节点，网关内部服务都是可以任意一个节点，但是这个就涉及到你们那服务设计原则，你不能够在微服里去做状态，做了状态之后，因为他每次请求都是做的负载平衡的。那你就状态就有问题，啊我们用的时候，凡是简单一点就推荐你用vs。对吧？最简单的。共享内存就共享它就好。然后接着说那个他用到哪些地方，其实也可以用游戏。看你如果你如果觉得够可以做游戏的话，那他就可以做游戏。很多优秀公司。对。但是还有一些极客，他就就就抓了C加加一起放，觉得不想用这些带着积极的东西。但其实现在用的很多，其实游戏要求不是很高的，都够都都是可以做的。嗯因为他可以，它它是带财政管理，就是做游戏的话，有30，然后就基本上是没有问题的，但是你像标准包里面带的啊PC啊或者是嗯啊PCXIPS它也是作作为服务，这个嗯不要只知道嗯但是他那些就没有开始没有猜中的话，你去做游戏方面，这个的话他可以控制到链接，就是够能够拿到的底层的东西，他都可以给你。比如说描述符的操作，在互联网，啊互联网可以啊就是有一个事例，啊这个实际是物联网。算算。是的。他是做做那个KTV的做KTV的，然后我还见到一个做做那个什么汽车上的每个东西啊导航，对汽车导航，两个水，但是但是好像我这里只写了一个这个这是一个空间的。他们用的用的那个北京的公司的方式，做KTV那种就是你嗯通过它的APP或者什么微信啊可以控制控制你那个呃放在房间的点拨那些东西，这种事跟那个GRC呃对。是艺术嗯跟他GABC其实跟他不一样，他是只是专注于它，它等于什么？呢顶多他是等于3，那个我这个手提包。是吧？你用G2PC能够轻松时间没服务嘛时限和服务吗？他还是比较底层的。它只是一个通讯组件，稍微的。对吧？你你你你说像这种刚刚这种铺啊故事，啊然后然后定义路由啊这些东西它有嘛对不对？所以它不是一个东西。你如果想用他那套功能，可以直接用消费者，召开本身就是看到有些现在介绍就是说客户端写的东西跟我就在桌上。写的标准差不多。就是这样写他的介绍。他介绍什么？其实就是说客户端跟服务端之间，直接啊是啊那那肯定是客户端服务端通信。他那个就是怎么说，呢他他是应该是嗯首先它支持支持那个http2，对吧？然后这个就有一个优势，你可以不同语言之间都遵循http协议，就可以方便通信了。这是他其实他我觉得他最大的优优势是这一点，你看网上对他的信誉，对比评价，跟其他语言的他是最低的最慢的，为什么？因为它它是用ftp协议，嘛但是据说啊可能是我了解的信息有点故事。啊听别人说你也可以定一别的协议，也可以自己定一别的协议。但总归来讲，它只是一个烧饼吧通信组件，它不能算过一个框架，你不能轻唤去实现你的业务。就最后一点时间我们就聊一下。那个以后这些分享怎么搞，然后我们今天搞了一场，然后总结一下，吧然后看看下一次怎么样怎么样搞会更好一些。我就标准把我的腿啊因为可能不同的人就一定不一样的，你这个东西可能你是研究这个让我们就是全部做数据库那一块。但是标准吧我现在用到这个的话，我就不用性就更强。其实我们我们去年公司内部就组织过，够阅读就是也是这个样子，但是我们学的是标准包。也看了一些，但是其实我已经看完，我个人已经看了，只把常用的都看。其实看标准包的话也可以，但是我的一个我我们的一个经验就是看标准包可能会看好久，大家必须都得每个人拿电脑，因为他因为里面的东西，啊我们现在讲的这些框架要什么东西，说实话，没有多少技术，都是一个逻辑的东西。没有算法。是吧？很简单。但是标准高，很多东西，全是算法模型，数据模型的东西。那些东西你可能连这个模型都没了解过的话，看着东西都看不懂，他为什么要这样子，做一下加减乘除唉出来一个结果，这个结果就是想要。为什么？像这些东西我们看的时候是什么？好开心。如果说有谁看过这个标准包，这个东西都很溜。可以在这里主角。然后给大家讲，我觉得这样解释一下，对，如果没有一个人带的话，就是大家谁都没看过这东西，上来一看，我觉得卡特的概率非常高。因为需要时间去查资料的。给我讲讲。到涉及到代码，尽量在之前。要不让大家看一下，像比如有的时候代码没有提前看过，然后讲的时候会议事阁的表演，然后看到时候看不清楚，然后具体内容能没有提前了解过，会有这样的感觉。对，其实今天咱们讲这个变故，并并不是让大家能够理解代码，因为这个节奏这个代码量也不可能去毕业。对吧？就是嗯其实这个东西今天的目的就是嗯可以可以说就是分享一个思路，分享一个项目，这样一个思路。我们学习源码的话，可能我们要提前抽出时间，我们提前会说我们要学一下这个这个源码，然后哪一部分确定好之后，可能我们提前看一看，有个了解，然后至少要有一个人，绝对至少要有一个人。完全通的。带着大家去看。有没有我们以后还是这样的吗？就是一个人主讲这样子吗？这两个小时就这个还好。这样对刚才说的。我一个人读一个人做主角，呢要有一些讨论。我自己的身份。要不然啊愿意就是带着大家跟导游要带大家走访沟通，啊对，这个这个确实确实是，对，要要要有讨论，今天是是是跟我个人有关系，那我我每次讲你知道吗？都形成不了讨论，我也不知道为啥，可能我不会讲。讲到最后一个，看大家对这个不熟，说实话我也不清楚。但是因为我我没去过过。是谁的？啊所有的可能你可以跟我有有有空给我们讲一些标准包的东西，其实你要是你你你不是要是你懂google语法的话，应该也差不多相底曾那些东西可能我们不太清楚，我觉得我。没有，我我主要是以以诚为主的，嘛我是做嵌入式的。因为我们做互联网，对接互联网，了解。啊所以我我觉得都不能在互联网上可以做一些那个那我我不太熟悉，所以我不不懂。她也爱你们怎么玩的。我们。对，通过，这个然后在这里偷偷在学校的时候，下次再可能会涨停一点，cc申购其实很像的。也是最接近的。你们都是做互联网，我我这一块基本上也是钻研服务端这一块的东西，然后向我感觉比较差的就是这种那个图形这一块。有时候觉得做图形处理的那些东西很有意思，但是是。你没学过。如果通过水桶的话，你可以介绍一下。嗯那我们就其实我觉得一个人讲也是可以的，然后就是可能要抛出点多问题来。在之前确定的范围，它在布置几道题目，然后然后比如说我们讲一个小时或者讲一个半小时，然后剩余的时间我们就去讨论，啊啊对这个可能会比较好，如果如果最好能提前先那个这样的话可以准备准备。对你的议题，比如说你甚至可以提前一个月把这个抛出来。然后有有兴趣的人可能会先去看一下，然后再到时候再再深入一点的，他们聊得更久更有意思。那么大家都在上面听，你在上面讲都是做完了，对，啊其实这种状态是不好的。所以我觉得他这个项目可以在自己或者去去去实践一下，拿来用，然后再交流一下，再更好一点。嗯反正这个它的生态会越来越完善。现在插件向那个扩展包里面写了好多东西，这里边的东西都是扩展班的，就是插件这个协议类的。然后这个是md5校验的那个管道过滤，然后模块的模块类的，这是一个。这是一个客户端筛选，其实它就是一个链接池，客户端的一个是这个就是应用到的那个微服务的客户端的，因为服务的客户端，因为他不需要逆向的去做推送吗，它要求的是多多条链接保证这个通信量。所以有这个池子可以保证这个这个这个通信的吞吐量，这是max。有些做http的推送啊之类的。可以用这个，吧然后后面其实也会慢慢加一个东西，然后遇到的，然后我想到的可能都会加到这里面来，然后嗯也有可能有其他方向，前两天尝试用这个写了一个嗯P to P的还是没成功。P to P的对环境要求也比较苛刻一些，我想做P to P直联嗯要能做能做出来的话，那座聊天其实挺爽。其实东西都有了，但是就是那个他最后那个拨号不成功，他会拒绝，也不知道是为啥？我也没时间再去深究了，因为我当时搞这个东西搞了，搞了一整天嗯搞了一整天，然后写的什么就最后一步为啥不成功，我也不知道。有空再再去研究一下，或者有谁帮忙。看一看。唉嗯，下一次。我们定义题吗？然后还是说那个在区里面在讲，因为有的人今天比较倾向于然后在群里面说吧今天今天到这儿可以。谢谢他，这个这样好吧，希望下次大家还有时间过来。会有。我在抄都抄出来。呀\n","title":"第2期 2018-04-11 线下分享内容语音实录（文字版本 by 录音宝）"},{"location":"https://bytemode.github.io/categories/","text":"","title":"Categories"},{"location":"https://bytemode.github.io/tags/","text":"","title":"Tags"},{"location":"https://bytemode.github.io/articles/sync/readme/","text":"内容均来自OSC_梦朝思夕博客,51CTO_梦朝思夕博客\n","title":"说明"}]